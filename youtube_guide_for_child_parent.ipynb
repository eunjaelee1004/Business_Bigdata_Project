{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9d334574",
      "metadata": {},
      "source": [
        "# ê²½ì˜ ë¹…ë°ì´í„° ë¶„ì„ ê°œë¡  íŒ€ í”„ë¡œì íŠ¸"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f886505",
      "metadata": {},
      "source": [
        "## ëª¨ë“ˆ ì„¤ì¹˜"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "5c2ce117-51a8-4a1e-bf6a-ae79e5a0d409",
      "metadata": {
        "id": "5c2ce117-51a8-4a1e-bf6a-ae79e5a0d409"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in /Users/gauspy-ma/.pyenv/versions/3.13.3/lib/python3.13/site-packages (1.78.0)\n",
            "Requirement already satisfied: python-dotenv in /Users/gauspy-ma/.pyenv/versions/3.13.3/lib/python3.13/site-packages (1.1.0)\n",
            "Requirement already satisfied: pyperclip in /Users/gauspy-ma/.pyenv/versions/3.13.3/lib/python3.13/site-packages (1.9.0)\n",
            "Requirement already satisfied: langchain in /Users/gauspy-ma/.pyenv/versions/3.13.3/lib/python3.13/site-packages (0.3.25)\n",
            "Requirement already satisfied: langchain-community in /Users/gauspy-ma/.pyenv/versions/3.13.3/lib/python3.13/site-packages (0.3.24)\n",
            "Requirement already satisfied: langchain-openai in /Users/gauspy-ma/.pyenv/versions/3.13.3/lib/python3.13/site-packages (0.3.16)\n",
            "Requirement already satisfied: youtube-transcript-api in /Users/gauspy-ma/.pyenv/versions/3.13.3/lib/python3.13/site-packages (1.1.0)\n",
            "Requirement already satisfied: tiktoken in /Users/gauspy-ma/.pyenv/versions/3.13.3/lib/python3.13/site-packages (0.9.0)\n",
            "Requirement already satisfied: google-api-python-client in /Users/gauspy-ma/.pyenv/versions/3.13.3/lib/python3.13/site-packages (2.169.0)\n",
            "Collecting jinja2\n",
            "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/gauspy-ma/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /Users/gauspy-ma/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/gauspy-ma/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/gauspy-ma/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/gauspy-ma/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from openai) (2.11.4)\n",
            "Requirement already satisfied: sniffio in /Users/gauspy-ma/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /Users/gauspy-ma/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /Users/gauspy-ma/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from openai) (4.13.2)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in /Users/gauspy-ma/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from langchain) (0.3.61)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /Users/gauspy-ma/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /Users/gauspy-ma/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from langchain) (0.3.42)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/gauspy-ma/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from langchain) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /Users/gauspy-ma/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /Users/gauspy-ma/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/gauspy-ma/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from langchain-community) (3.11.18)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /Users/gauspy-ma/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from langchain-community) (9.1.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/gauspy-ma/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /Users/gauspy-ma/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from langchain-community) (2.9.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /Users/gauspy-ma/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from langchain-community) (0.4.0)\n",
            "Requirement already satisfied: numpy>=2.1.0 in /Users/gauspy-ma/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from langchain-community) (2.2.5)\n",
            "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /Users/gauspy-ma/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from youtube-transcript-api) (0.7.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /Users/gauspy-ma/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /Users/gauspy-ma/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from google-api-python-client) (0.22.0)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0 in /Users/gauspy-ma/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from google-api-python-client) (2.40.1)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /Users/gauspy-ma/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from google-api-python-client) (0.2.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5 in /Users/gauspy-ma/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from google-api-python-client) (2.24.2)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /Users/gauspy-ma/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from google-api-python-client) (4.1.1)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2)\n",
            "  Downloading MarkupSafe-3.0.2-cp313-cp313-macosx_11_0_arm64.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/gauspy-ma/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /Users/gauspy-ma/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /Users/gauspy-ma/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /Users/gauspy-ma/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/gauspy-ma/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /Users/gauspy-ma/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/gauspy-ma/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.0)\n",
            "Requirement already satisfied: idna>=2.8 in /Users/gauspy-ma/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/gauspy-ma/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/gauspy-ma/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /Users/gauspy-ma/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (1.70.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in /Users/gauspy-ma/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (5.29.4)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /Users/gauspy-ma/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (1.26.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/gauspy-ma/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/gauspy-ma/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/gauspy-ma/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (4.9.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /Users/gauspy-ma/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client) (3.2.3)\n",
            "Requirement already satisfied: certifi in /Users/gauspy-ma/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /Users/gauspy-ma/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /Users/gauspy-ma/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/gauspy-ma/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /Users/gauspy-ma/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (24.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/gauspy-ma/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/gauspy-ma/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /Users/gauspy-ma/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /Users/gauspy-ma/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /Users/gauspy-ma/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/gauspy-ma/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/gauspy-ma/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from requests<3,>=2->langchain) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/gauspy-ma/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from requests<3,>=2->langchain) (2.4.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /Users/gauspy-ma/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain) (3.0.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /Users/gauspy-ma/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (0.6.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/gauspy-ma/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\n",
            "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "Downloading MarkupSafe-3.0.2-cp313-cp313-macosx_11_0_arm64.whl (12 kB)\n",
            "Installing collected packages: MarkupSafe, jinja2\n",
            "Successfully installed MarkupSafe-3.0.2 jinja2-3.1.6\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install openai python-dotenv pyperclip langchain langchain-community langchain-openai youtube-transcript-api tiktoken google-api-python-client jinja2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b4de5d8",
      "metadata": {},
      "source": [
        "## ëª¨ë“ˆ ë¶ˆëŸ¬ì˜¤ê¸°/ API í‚¤ í˜¸ì¶œ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "85650708-158b-48d1-be26-196572898d3a",
      "metadata": {
        "id": "85650708-158b-48d1-be26-196572898d3a"
      },
      "outputs": [],
      "source": [
        "# OpenAI API ì‚¬ìš©\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "import pyperclip\n",
        "import re\n",
        "import sqlite3\n",
        "from datetime import datetime, timedelta\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_community.document_loaders import YoutubeLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.chains import load_summarize_chain\n",
        "from langchain.schema import Document\n",
        "from langchain.prompts import PromptTemplate\n",
        "from googleapiclient.discovery import build"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "5fa08760",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# .env íŒŒì¼ì—ì„œ API í‚¤ ë¡œë“œ\n",
        "load_dotenv()\n",
        "\n",
        "def get_api_key(name, prompt):\n",
        "    key = os.getenv(name)\n",
        "    if not key or key.strip() == \"\":\n",
        "        key = input(f\"{prompt}: \").strip()\n",
        "    return key\n",
        "\n",
        "OPENAI_API_KEY = get_api_key(\"OPENAI_API_KEY\", \"OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ca6ab36",
      "metadata": {},
      "source": [
        "## API í˜¸ì¶œ í† í° ê³„ì‚°"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "6f6f92dd",
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "API í† í° ê³„ì‚°ìš©\n",
        "'''\n",
        "\n",
        "import math\n",
        "import tiktoken\n",
        "\n",
        "def count_tokens(text, model_name=\"gpt-4o\"):\n",
        "    try:\n",
        "        encoding = tiktoken.encoding_for_model(model_name)\n",
        "    except Exception:\n",
        "        encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
        "    return len(encoding.encode(text))\n",
        "\n",
        "'''\n",
        "model = ChatOpenAI(model='gpt-4o-mini')\n",
        "prompt = 'ì•ˆë…•í•˜ì„¸ìš”. ì˜¤ëŠ˜ ì„œìš¸ì˜ ë‚ ì”¨ê°€ ë¬´ì—‡ì¸ê°€ìš”?'\n",
        "prompt_tokens = count_tokens(prompt)\n",
        "result = model.invoke(prompt)\n",
        "content = getattr(result, 'content', None) or str(result)\n",
        "completion_tokens = count_tokens(content)\n",
        "print(prompt_tokens,completion_tokens)\n",
        "'''\n",
        "\n",
        "prompt_tokens = 0\n",
        "content_tokens = 0 "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b47298ff-b5a7-4cfb-a6eb-66c5177ae2b4",
      "metadata": {
        "id": "b47298ff-b5a7-4cfb-a6eb-66c5177ae2b4"
      },
      "source": [
        "## YOUTUBE ì˜ìƒ ìš”ì•½ ë°”íƒ•ìœ¼ë¡œ ê°€ì´ë“œë¼ì¸ ì œê³µ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "3525e7c4-bff2-43c2-ba5a-e023a340802d",
      "metadata": {
        "id": "3525e7c4-bff2-43c2-ba5a-e023a340802d"
      },
      "outputs": [],
      "source": [
        "# â–¶ URL ë½‘ì•„ë‚´ê¸° ---------------------------------------------\n",
        "# í´ë¦½ë³´ë“œì—ì„œ ìœ íŠœë¸Œ URLì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜\n",
        "# - í´ë¦½ë³´ë“œì— ìœ íš¨í•œ ìœ íŠœë¸Œ URLì´ ìˆëŠ” ê²½ìš° ë°˜í™˜\n",
        "# - URLì´ ì—†ëŠ” ê²½ìš°, ì§ì ‘ URLì„ ì…ë ¥ë°›ìŒ\n",
        "\n",
        "def get_youtube_url_from_clipboard():\n",
        "    try:\n",
        "        text = pyperclip.paste()\n",
        "        m = re.search(r'https?://www\\.youtube\\.com/watch\\?v=[\\w\\-]+', text)\n",
        "        if m:\n",
        "            url = m.group(0)\n",
        "            print(f\"[ğŸ”—] ê°ì§€ëœ ìœ íŠœë¸Œ URL: {url}\")\n",
        "            return url\n",
        "        else:\n",
        "            raise ValueError(\"í´ë¦½ë³´ë“œì— ìœ íŠœë¸Œ ë§í¬ ì—†ìŒ.\")\n",
        "    except Exception as e:\n",
        "        print(f\"[âš ï¸ í´ë¦½ë³´ë“œ ì˜¤ë¥˜] {e}\")\n",
        "        url = input(\"ìœ íŠœë¸Œ ë§í¬ë¥¼ ì§ì ‘ ì…ë ¥í•˜ì„¸ìš”: \")\n",
        "        return url"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "f8f0bdf9-86f2-4538-924f-e275e57dff48",
      "metadata": {
        "id": "f8f0bdf9-86f2-4538-924f-e275e57dff48"
      },
      "outputs": [],
      "source": [
        "# â–¶ URLì„ video_idë¡œ ë³€í™˜ ---------------------------------------------\n",
        "\n",
        "def url_to_video_id(url):\n",
        "    m = re.search(r\"v=([\\w\\-]+)\", url)\n",
        "    return m.group(1) if m else None\n",
        "\n",
        "# â–¶ video_idë¥¼ URLë¡œ ë³€í™˜ ---------------------------------------------\n",
        "\n",
        "def video_id_to_url(video_id):\n",
        "    url = f\"https://www.youtube.com/watch?v={video_id}\"\n",
        "    return url if video_id else None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84dbf1f5-237c-4052-a0d6-dbff67758dd6",
      "metadata": {
        "id": "84dbf1f5-237c-4052-a0d6-dbff67758dd6",
        "outputId": "94278c47-4fd2-4ef7-ba5d-3c3aab0600e1"
      },
      "outputs": [],
      "source": [
        "## ğŸ’¬ ìœ íŠœë¸Œ ì˜ìƒ ì‹œì²­ í›„ ëŒ€í™” ê°€ì´ë“œë¼ì¸ ì œê³µ ì½”ë“œ\n",
        "\n",
        "from enum import Enum\n",
        "from typing import List, Tuple\n",
        "from pydantic import BaseModel\n",
        "from jinja2 import Template\n",
        "import json\n",
        "from youtube_transcript_api import YouTubeTranscriptApi\n",
        "from youtube_transcript_api._errors import TranscriptsDisabled, VideoUnavailable\n",
        "from openai import OpenAI\n",
        "\n",
        "# --- 1. Define Models and Enums ---\n",
        "\n",
        "class ParentType(str, Enum):\n",
        "    Mother = \"Mother\"\n",
        "    Father = \"Father\"\n",
        "\n",
        "class CardCategory(str, Enum):\n",
        "    Topic = \"Topic\"\n",
        "    Action = \"Action\"\n",
        "    Emotion = \"Emotion\"\n",
        "    Core= \"Core\"\n",
        "\n",
        "class ParentGuideCategory(str, Enum):\n",
        "    Intention = \"intention\"\n",
        "    Specification = \"specification\"\n",
        "    Choice = \"choice\"\n",
        "    Clues = \"clues\"\n",
        "    Coping = \"coping\"\n",
        "    Stimulate = \"stimulate\"\n",
        "    Share = \"share\"\n",
        "    Empathize = \"empathize\"\n",
        "    Encourage = \"encourage\"\n",
        "    Emotion = \"emotion\"\n",
        "    Extend = \"extend\"\n",
        "    Terminate = \"terminate\"\n",
        "\n",
        "    def description(self):\n",
        "        return {\n",
        "            \"intention\": \"Check the intention behind the childâ€™s response and ask back\",\n",
        "            \"specification\": \"Ask about \\\"what\\\" to specify the event\",\n",
        "            \"choice\": \"Provide choices for children to select their answers\",\n",
        "            \"clues\": \"Give clues that can be answered based on previously known information\",\n",
        "            \"coping\": \"Suggest coping strategies for specific situations to the child\",\n",
        "            \"stimulate\": \"Present information that contradicts what is known to stimulate the child's interest\",\n",
        "            \"share\": \"Share the parent's emotions and thoughts in simple language\",\n",
        "            \"empathize\": \"Empathize with the child's feelings\",\n",
        "            \"encourage\": \"Encourage the child's actions or emotions\",\n",
        "            \"emotion\": \"Asking about the child's feelings and emotions\",\n",
        "            \"extend\": \"Inducing an expansion or change of the conversation topic\",\n",
        "            \"terminate\": \"Inquiring about the desire to end the conversation\"\n",
        "        }[self.value]\n",
        "\n",
        "class InappropriateDialogueCategory(str, Enum):\n",
        "    Blame = \"blame\"\n",
        "    Correction = \"correction\"\n",
        "    Complex = \"complex\"\n",
        "\n",
        "    def description(self):\n",
        "        return {\n",
        "            \"blame\": \"When the parent criticizes or negatively evaluates the child's responds, like reprimanding or scolding\",\n",
        "            \"correction\": \"When the parent is compulsively correcting the child's response or pointing out that the child is wrong\",\n",
        "            \"complex\": \"When a parent's dialogue contains more than one goal or intent\"\n",
        "        }[self.value]\n",
        "\n",
        "class DialogueMessage(BaseModel):\n",
        "    speaker: str  # \"Parent\" or \"Child\"\n",
        "    text: str = \"\"\n",
        "    cards: List[Tuple[str, CardCategory]] = []\n",
        "\n",
        "class ParentGuideElement(BaseModel):\n",
        "    category: ParentGuideCategory\n",
        "    guide: str\n",
        "\n",
        "class AvoidGuideItem(BaseModel):\n",
        "    example: str\n",
        "    feedback: str\n",
        "\n",
        "class AvoidGuides(BaseModel):\n",
        "    blame: AvoidGuideItem\n",
        "    correction: AvoidGuideItem\n",
        "    complex: AvoidGuideItem\n",
        "\n",
        "class SessionTopicCategory(str, Enum):\n",
        "    Plan = \"Plan\"\n",
        "    Recall = \"Recall\"\n",
        "    Experience = \"Experience\"\n",
        "\n",
        "class SessionTopicInfo(BaseModel):\n",
        "    category: SessionTopicCategory\n",
        "\n",
        "    def to_readable_description(self):\n",
        "        return f\"{self.category.value.lower()} conversation\"\n",
        "\n",
        "\n",
        "# --- 2. OpenAI Client Setup ---\n",
        "\n",
        "client = OpenAI(api_key=\"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\")\n",
        "\n",
        "\n",
        "\n",
        "# --- 3. Youtube Transcript ---\n",
        "from youtube_transcript_api import YouTubeTranscriptApi\n",
        "\n",
        "def get_transcript_allow_generated(video_id: str) -> str:\n",
        "    try:\n",
        "        transcript_list = YouTubeTranscriptApi.list_transcripts(video_id)\n",
        "\n",
        "        try:\n",
        "            transcript = transcript_list.find_generated_transcript(['ko'])\n",
        "        except:\n",
        "            transcript = transcript_list.find_generated_transcript(['en'])\n",
        "\n",
        "        entries = transcript.fetch()\n",
        "        return \"\\n\".join([entry.text for entry in entries])  # âœ… ìˆ˜ì •\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ ìë§‰ ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "\n",
        "# --- 4. Video Summary and Question Generation Prompt ---\n",
        "\n",
        "summary_prompt_template = Template(\"\"\"\n",
        "You are a language therapist helping parents talk meaningfully with their autistic children.\n",
        "Analyze the following YouTube video transcript. Then:\n",
        "\n",
        "1. Summarize the key message in 3-4 sentences.\n",
        "2. For each of the following conversation types â€” Plan, Recall, Experience â€”\n",
        "   suggest a topic that could be discussed with the child based on the video.\n",
        "3. For each topic, provide 2 clear and simple example questions a parent could ask.\n",
        "\n",
        "Format:\n",
        "- Summary: (3~4 sentence summary in Korean)\n",
        "- Topics and Questions by Category:\n",
        "  - [1. Plan]\n",
        "    - Topic: (1-line description in Korean)\n",
        "    - Questions:\n",
        "      - Q1: ...\n",
        "      - Q2: ...\n",
        "  - [2. Recall]\n",
        "    - Topic: ...\n",
        "    - Questions:\n",
        "      - Q1: ...\n",
        "      - Q2: ...\n",
        "  - [3. Experience]\n",
        "    - Topic: ...\n",
        "    - Questions:\n",
        "      - Q1: ...\n",
        "      - Q2: ...\n",
        "\n",
        "The final output should be written in Korean.\n",
        "\n",
        "Transcript:\n",
        "{{ transcript }}\n",
        "\"\"\")\n",
        "\n",
        "\n",
        "def generate_video_summary_and_questions(transcript: str) -> str:\n",
        "    if not transcript:\n",
        "        raise ValueError(\"Transcript is empty or None. Cannot generate summary.\")\n",
        "    prompt = summary_prompt_template.render(transcript=transcript[:4000])  # Cut for safety\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "\n",
        "# --- 5. Parent Guide Generation Prompt ---\n",
        "\n",
        "guide_template = Template(\"\"\"\n",
        "- Role: You are a helpful assistant who helps facilitate communication between minimally verbal autistic children and their parents.\n",
        "- Video summary for context: {{ summary }}\n",
        "\n",
        "- Goal of the conversation: {{ topic.to_readable_description() }}. Help the child and the {{ parent_type }} elaborate on that topic together.\n",
        "- You must help the parent and the child explore this topic together, in a way that strongly reflects the main theme and emotional/educational message of the YouTube video.\n",
        "- All guidance must be **rooted in** the key ideas presented in the video.\n",
        "\n",
        "- ğŸ“Œ ëª¨ë“  ì¶œë ¥ì€ ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.\n",
        "â—ï¸Do not include any explanation, markdown formatting, section titles (like ### 1 or ### 2), or any additional text. Return ONLY the final JSON array as mentioned below task 2 as raw output.\n",
        "\n",
        "There are 2 tasks.\n",
        "### 1\n",
        "- Task 1:\n",
        "{%- if dialogue %}\n",
        "  Given the dialogue history and the childâ€™s keyword response ({{ child_cards }}),\n",
        "  suggest {{ num_guides }} parent guides from the categories below.\n",
        "{%- else %}\n",
        "  Suggest {{ num_guides }} starting-point guides for initiating the conversation.\n",
        "{% endif %}\n",
        "\n",
        "[General instructions for parent's guide]\n",
        "- Provide simple and easy-to-understand sentences consisting of no more than 5-6 words.\n",
        "- Each guide should contain one purpose or intention.\n",
        "- {% if dialogue | length > 0 %}\n",
        "    - Each guide should be contextualized based on the child's response and not be too general.\n",
        "    - **However, the guide must remain within the main theme of the video.**\n",
        "    {% endif %}\n",
        "\n",
        "\n",
        "[Parent guide categories]\n",
        "{% for cat in categories %}\n",
        "- \"{{ cat.value }}\": {{ cat.description() }}\n",
        "{% endfor %}\n",
        "\n",
        "[Response format]\n",
        "Return a json list with each element formatted as:\n",
        "{\n",
        "  \"category\": The category of \"Parent guide category\",\n",
        "  \"guide\": The guide message provided to the {{parent_type}}.\n",
        "}\n",
        "\n",
        "{% if example_block %}\n",
        "[Examples]\n",
        "{{ example_block }}\n",
        "{% endif %}\n",
        "- ğŸ“Œ ëª¨ë“  ì¶œë ¥ì€ ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.\n",
        "\n",
        "### 2\n",
        "- Task 2:\n",
        "{%- if dialogue %}\n",
        "  Analyze the dialogue and generate 3 examples of inappropriate parent responses â€” one for each category below.\n",
        "    - Based on the most recent parent question and child response, generate one inappropriate response for each of the three categories.\n",
        "    - Responses should feel realistic and be phrased as if a parent might naturally say them.\n",
        "    - ì œë°œ ì•„ì´ì˜ í‚¤ì›Œë“œ ë‹µë³€ë§Œ ë³´ê³  ê°€ì´ë“œë¥¼ ì œê³µí•˜ì§€ ë§ê³ , \"ì˜ìƒ ì£¼ì œì™€ ë¶€ëª¨ê°€ ì´ì „ì— ë˜ì§„ ì§ˆë¬¸ ë§¥ë½ì— ë§ê²Œ\" ê°€ì´ë“œë¼ì¸ì„ ì œì‹œí•´ì¤˜.\n",
        "  For each category:\n",
        "  - Provide an inappropriate example.\n",
        "  - Explain why it is problematic.\n",
        "  - Suggest how to rephrase it better.\n",
        "\n",
        "[Inappropriate guide categories]\n",
        "{% for cat in bad_categories %}\n",
        "- \"{{ cat.value }}\": {{ cat.description() }}\n",
        "{% endfor %}\n",
        "\n",
        "{% if bad_example_block %}\n",
        "[Examples]\n",
        "{{ bad_example_block }}\n",
        "{% endif %}\n",
        "{% endif %}\n",
        "\n",
        "\n",
        "### Final Output Format\n",
        "The final output should be written in Korean.\n",
        "â—ï¸Do not include any explanation, markdown formatting, section titles (like ### 1 or ### 2), or any additional text. Return ONLY the final JSON array as mentioned below as raw output.\n",
        "\n",
        "[Response format]\n",
        "Return a json list with one object, structured as follows:\n",
        "[\n",
        "  \"good_guides\": [\n",
        "        {\n",
        "        \"category\": The category of \"Parent guide category\",\n",
        "        \"guide\": The guide message provided to the {{parent_type}}.\n",
        "        },\n",
        "        {\n",
        "        \"category\": \"...\",\n",
        "        \"guide\": \"...\"\n",
        "        },\n",
        "        {\n",
        "        \"category\": \"...\",\n",
        "        \"guide\": \"...\"\n",
        "        }\n",
        "    ]\n",
        "    ,\n",
        "  \"avoid_guides\": {\n",
        "        \"blame\": {\n",
        "          \"example\": \"...\",\n",
        "          \"feedback\": \"...\"\n",
        "        },\n",
        "        \"correction\": {\n",
        "          \"example\": \"...\",\n",
        "          \"feedback\": \"...\"\n",
        "        },\n",
        "        \"complex\": {\n",
        "          \"example\": \"...\",\n",
        "          \"feedback\": \"...\"\n",
        "        }\n",
        "    }\n",
        "]\n",
        "\n",
        "âš ï¸âš ï¸ No explanation, markdown, or headers â€” just valid JSON. âš ï¸âš ï¸\n",
        "\n",
        "- ğŸ“Œ ëª¨ë“  ì¶œë ¥ì€ ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.\n",
        "\"\"\")\n",
        "\n",
        "example_block = \"\"\"\n",
        "[Example 1]\n",
        "topic: Recall\n",
        "\n",
        "Dialogue:\n",
        "Parent: How was your day at kinder?\n",
        "Child: [\"Kinder\"(Topic), \"Friend\"(Topic), \"Tough\"(Emotion)]\n",
        "\n",
        "Suggested Parent Guides:\n",
        "- [Empathize] Empathize that the kid had tough time due to a friend.\n",
        "- [Intention] Check whether the kid had tough time with the friend.\n",
        "- [Specification] Ask what was tough with the friend.\n",
        "\n",
        "[Example 2]\n",
        "topic: Plan\n",
        "\n",
        "Dialogue:\n",
        "Parent: Did you remember that we will visit granma today?\n",
        "Child: [\"Grandma\"(Topic), \"Play\"(Action)]\n",
        "\n",
        "Suggested Parent Guides:\n",
        "- [Empathize] Repeat that your kid wants to play with grandma.\n",
        "- [Encourage] Suggest things that the kid can do with grandma playing.\n",
        "- [Specification] Ask about what your kid wants to do playing.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "bad_example_block = \"\"\"\n",
        "[Example 1]\n",
        "InappropriateDialogueCategory: Blame\n",
        "\n",
        "Dialogue:\n",
        "Parent: What did you do at school?\n",
        "Child: [\"School\"(Topic), \"Play\"(Action)]\n",
        "Parent: I asked you not to play games at school. Didn't I?\n",
        "\n",
        "Rationale: The parent is about to scold the child not to play games.\n",
        "Feedback: You seem to be scolding him before obtaining to more concrete information. Please gather more information before judgment.\n",
        "\n",
        "[Example 2]\n",
        "InappropriateDialogueCategory: Correction\n",
        "\n",
        "Dialogue:\n",
        "Parent: What did you do at school?\n",
        "Child: [\"School\"(Topic), \"Play\"(Action)]\n",
        "Parent: You should say, 'I played with my friends at school.'\n",
        "\n",
        "Rationale: The parent is trying to improve the child's response with better sentences or phrases.\n",
        "Feedback: You seem to be correcting the child's response. Please focus more on the topic and context of the conversation.\n",
        "\n",
        "[Example 3]\n",
        "InappropriateDialogueCategory: Complex\n",
        "\n",
        "Dialogue:\n",
        "Parent: How are you feeling right now?\n",
        "Child: [\"Happy\"(Emotion)]\n",
        "Parent: What are your plans for today and where are you going to be?\n",
        "\n",
        "Rationale: The parent is confusing the child by asking about both plans and location at once.\n",
        "Feedback: Please ask about only one thing to make it easier for the child to answer.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "def build_guide_prompt(parent_type: ParentType, topic: SessionTopicInfo, dialogue: List[DialogueMessage], child_cards: List[Tuple[str, CardCategory]],  example_block: str, bad_example_block: str, summary: str, num_guides: int = 3) -> str:\n",
        "    return guide_template.render(\n",
        "        parent_type=parent_type.value,\n",
        "        topic=topic,\n",
        "        dialogue=dialogue,\n",
        "        child_cards=\", \".join([c[0] for c in child_cards]),\n",
        "        categories=list(ParentGuideCategory),\n",
        "        bad_categories=list(InappropriateDialogueCategory),\n",
        "        summary=summary,\n",
        "        num_guides=num_guides,\n",
        "        example_block=example_block,\n",
        "        bad_example_block=bad_example_block\n",
        "    )\n",
        "\n",
        "\n",
        "def call_gpt_for_guides(prompt: str) -> List[ParentGuideElement]:\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=0.7\n",
        "    )\n",
        "    result_text = response.choices[0].message.content\n",
        "    print(\"\\nğŸ§  GPT Output:\\n\", result_text)\n",
        "    try:\n",
        "        parsed = json.loads(result_text)\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(\"âŒ JSON íŒŒì‹± ì‹¤íŒ¨:\", e)\n",
        "        raise\n",
        "\n",
        "    good_guides = parsed[0].get(\"good_guides\", [])\n",
        "    good_guide_list = [\n",
        "        ParentGuideElement(\n",
        "            category=ParentGuideCategory(g[\"category\"]),\n",
        "            guide=g[\"guide\"]\n",
        "        ) for g in good_guides\n",
        "    ]\n",
        "\n",
        "    avoid_guide_list = AvoidGuides(**parsed[0].get(\"avoid_guides\", {}))\n",
        "\n",
        "    return good_guide_list, avoid_guide_list\n",
        "\n",
        "\n",
        "# --- 6. Interactive Dialogue Loop ---\n",
        "\n",
        "# Step 1: Load YouTube Video\n",
        "\n",
        "\n",
        "# 1. ìë§‰ ê°€ì ¸ì˜¤ê¸° (ìë™ ìƒì„± í¬í•¨)\n",
        "url = get_youtube_url_from_clipboard()\n",
        "video_id = url_to_video_id(url)\n",
        "transcript = get_transcript_allow_generated(video_id)\n",
        "\n",
        "# 2. ìë§‰ì„ ê¸°ë°˜ìœ¼ë¡œ ìš”ì•½ ìƒì„±\n",
        "if transcript:\n",
        "    try:\n",
        "        summary = generate_video_summary_and_questions(transcript)\n",
        "        print(\"\\nğŸ“‹ Summary and Conversation categories (Korean):\\n\", summary)\n",
        "\n",
        "        # 3. ì¹´í…Œê³ ë¦¬ ì„ íƒ\n",
        "        selected_category_num = int(input(\"ğŸ’¬ ì„ íƒí•œ ëŒ€í™” ì¹´í…Œê³ ë¦¬ì˜ ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš” (Plan: 1, Recall: 2, Experience: 3)\\n\"))\n",
        "        category_dic = {\n",
        "            1: SessionTopicCategory.Plan,\n",
        "            2: SessionTopicCategory.Recall,\n",
        "            3: SessionTopicCategory.Experience\n",
        "        }\n",
        "        selected_category = category_dic[selected_category_num]\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
        "else:\n",
        "    print(\"âŒ ìë§‰ì„ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í•´ ìš”ì•½ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "\n",
        "\n",
        "# url = get_youtube_url_from_clipboard()\n",
        "# video_id = url_to_video_id(url)\n",
        "\n",
        "# if transcript:\n",
        "#     transcript = get_youtube_transcript(video_id)\n",
        "#     summary = generate_video_summary_and_questions(transcript)\n",
        "#     print(\"\\nğŸ“‹ Summary and Conversation categories (Korean):\\n\", summary)\n",
        "#     selected_category_num = int(input(\"ğŸ’¬ ì„ íƒí•œ ëŒ€í™” ì¹´í…Œê³ ë¦¬ì˜ ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš” (Plan: 1, Recall: 2, Experience: 3)\"))\n",
        "#     category_dic = {\n",
        "#         1: SessionTopicCategory.Plan,\n",
        "#         2: SessionTopicCategory.Recall,\n",
        "#         3: SessionTopicCategory.Experience\n",
        "#     }\n",
        "#     selected_category = category_dic[selected_category_num]\n",
        "# else:\n",
        "#     print(\"âŒ ìë§‰ì„ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í•´ ìš”ì•½ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "\n",
        "# Step 2: Initialize Dialogue Context\n",
        "parent_type = ParentType.Mother\n",
        "topic_info = SessionTopicInfo(category=selected_category)\n",
        "dialogue = []\n",
        "turn_count = 1\n",
        "\n",
        "# Step 3: Start Interactive Loop\n",
        "while True:\n",
        "    selected_question = input(\"\\nğŸ’¬ ë¶€ëª¨ê°€ ì„ íƒí•œ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”: \")\n",
        "    if selected_question.strip().lower() in [\"ì¢…ë£Œ\", \"exit\", \"quit\"]:\n",
        "        print(\"ğŸ›‘ ëŒ€í™”ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.\")\n",
        "        break\n",
        "    dialogue.append(DialogueMessage(speaker=\"Parent\", text=selected_question))\n",
        "\n",
        "    raw = input(\"ğŸ‘¦ ì•„ì´ì˜ í‚¤ì›Œë“œ ì‘ë‹µì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: í•™êµ(Topic), í”¼ê³¤í•¨(Emotion)):\\n\")\n",
        "    if selected_question.strip().lower() in [\"ì¢…ë£Œ\", \"exit\", \"quit\"]:\n",
        "        print(\"ğŸ›‘ ëŒ€í™”ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.\")\n",
        "        break\n",
        "    child_response = []\n",
        "    for item in raw.split(\",\"):\n",
        "        word, category = item.strip().split(\"(\")\n",
        "        child_response.append((word.strip(), CardCategory[category.replace(\")\", \"\")]))\n",
        "\n",
        "    dialogue.append(DialogueMessage(speaker=\"Child\", cards=child_response))\n",
        "\n",
        "    prompt = build_guide_prompt(parent_type, topic_info, dialogue, child_response, summary, 3, example_block, bad_example_block)\n",
        "    good_guides, avoid_guides = call_gpt_for_guides(prompt)\n",
        "\n",
        "    print(f\"\\nğŸ” Turn {turn_count} - ì•„ì´ì—ê²Œ ì´ë ‡ê²Œ ë¬¼ì–´ë´ì£¼ì„¸ìš”!:\")\n",
        "    for i, g in enumerate(good_guides):\n",
        "        print(f\"{i+1}. [{g.category.value}] {g.guide}\")\n",
        "\n",
        "    print(\"\\nğŸš« ì´ëŸ° ë§ì€ ì£¼ì˜í•´ì£¼ì„¸ìš”:\")\n",
        "    print(f\"[Blame] {avoid_guides.blame.example} â†’ {avoid_guides.blame.feedback}\")\n",
        "    print(f\"[Correction] {avoid_guides.correction.example} â†’ {avoid_guides.correction.feedback}\")\n",
        "    print(f\"[Complex] {avoid_guides.complex.example} â†’ {avoid_guides.complex.feedback}\")\n",
        "\n",
        "    guide_choice = int(input(\"ğŸ‘‰ ì‚¬ìš©í•  ê°€ì´ë“œë¥¼ ë²ˆí˜¸ë¡œ ì„ íƒí•˜ì„¸ìš”: \"))\n",
        "    if selected_question.strip().lower() in [\"ì¢…ë£Œ\", \"exit\", \"quit\"]:\n",
        "        print(\"ğŸ›‘ ëŒ€í™”ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.\")\n",
        "        break\n",
        "    selected_guide =  good_guides[guide_choice - 1].guide\n",
        "    dialogue.append(DialogueMessage(speaker=\"Parent\", text=selected_guide))\n",
        "\n",
        "    turn_count += 1\n",
        "\n",
        "    cont = input(\"â­ï¸ ê³„ì†í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): \")\n",
        "    if cont.lower() != 'y':\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1e8a73a-fa2d-4c88-8a4c-11f42e7ef201",
      "metadata": {
        "id": "b1e8a73a-fa2d-4c88-8a4c-11f42e7ef201"
      },
      "source": [
        "## RAG ë§Œë“¤ê¸°"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9efd3457-84eb-41d5-889d-e9b573217878",
      "metadata": {
        "id": "9efd3457-84eb-41d5-889d-e9b573217878"
      },
      "source": [
        "#### 1. [êµìœ¡ë¶€, ê²½ìƒë¶ë„êµìœ¡ì²­] ì¥ì•  ì˜ì•„ êµìœ¡ì§€ì› ìš´ì˜ê°€ì´ë“œ ì‚¬ë¡€ì§‘(2024).pdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "efa26242-5a51-48f3-9264-161e57729cfa",
      "metadata": {
        "id": "efa26242-5a51-48f3-9264-161e57729cfa"
      },
      "outputs": [],
      "source": [
        "# # 1. [êµìœ¡ë¶€, ê²½ìƒë¶ë„êµìœ¡ì²­] ì¥ì•  ì˜ì•„ êµìœ¡ì§€ì› ìš´ì˜ê°€ì´ë“œ ì‚¬ë¡€ì§‘(2024).pdf ë¡œë”©\n",
        "\n",
        "# from langchain_community.document_loaders import PyPDFLoader\n",
        "# from pathlib import Path\n",
        "# folder = Path('data')\n",
        "# loader1 = PyPDFLoader(folder / '[êµìœ¡ë¶€, ê²½ìƒë¶ë„êµìœ¡ì²­] ì¥ì•  ì˜ì•„ êµìœ¡ì§€ì› ìš´ì˜ê°€ì´ë“œ ì‚¬ë¡€ì§‘(2024).pdf')\n",
        "# pages1 = loader1.load()\n",
        "# len(pages1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8b19696-0f31-40ca-af39-a98e75722988",
      "metadata": {
        "id": "c8b19696-0f31-40ca-af39-a98e75722988"
      },
      "outputs": [],
      "source": [
        "non_empty_pages = [page for page in pages1 if page.page_content.strip() != '']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "879c19d8-21cc-4503-9b3d-a0c5aa56cdec",
      "metadata": {
        "id": "879c19d8-21cc-4503-9b3d-a0c5aa56cdec",
        "outputId": "176d6e62-d19e-493d-af6d-d38582bb19db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "â‘¢ ì˜ì•„ íŠ¹ì„±\n",
            "ì‚¬ë‘ìŠ¤ëŸ¬ìš´ í•˜ì˜ì´ ì•Œì•„ë³´ê¸°\n",
            "â‘£ ë†€ì´ì˜ ì‹œì‘\n",
            "ìŠ¤ìŠ¤ë¡œ ì„­ì‹í•˜ëŠ”ë° ì–´ë ¤ì›€ì„ ë³´ì´ëŠ” í•˜ì˜ì´ë¥¼ ìœ„í•˜ì—¬ ë‹¤ì–‘í•œ ê³¼ì¼ê³¼ ì±„ì†Œë¥¼   \n",
            "ê°€ì§€ê³  ë†€ì´í•  ìˆ˜ ìˆë„ë¡ ì¤€ë¹„í•˜ì—¬ ë†€ì´ìˆ˜ì—…ì„ ì§„í–‰í•´ì™”ë‹¤.\n",
            "10ì›”ì˜ ìƒí™œì£¼ì œ â€˜ê°€ì„â€™ì´ ë˜ì–´ â€˜ê°€ì„ê³¼ì¼ë¡œ ë†€ì´í•´ìš”â€™ ì£¼ì œë¡œ â€˜í™ì‹œë†€ì´â€™ë¥¼ ì¤€ë¹„\n",
            "í–ˆë‹¤. í•˜ì˜ì´ëŠ” ë¬¸ì¥ì„ ì½ì„ ìˆ˜ ìˆê³  ì±…ì— ê´€ì‹¬ì´ ë§ê¸° ë•Œë¬¸ì— ê°ì´ ìµì–´ê°€ëŠ”  \n",
            "ê³¼ì •ì„ ë°°ìš¸ ìˆ˜ ìˆëŠ” ê·¸ë¦¼ì±…ì„ ì¤€ë¹„í•˜ì˜€ë‹¤. ê·¸ë¦¬ê³  ê·¸ë¦¼ì±…ì„ í†µí•´ ê°ì˜ í•œ ì‚´ì´ë¥¼ \n",
            "ë°°ìš°ê³  ì£¼ì¸ê³µì²˜ëŸ¼ ê°ì„ ë§›ë³´ëŠ” ë†€ì´ë¥¼ ê³„íší•˜ì˜€ë‹¤.\n",
            "ì´ë¦„ (ì—°ë ¹) ì´í•˜ì˜ (2ì„¸)\n",
            "ì¥ì• ìœ í˜• ë°œë‹¬ì§€ì²´\n",
            "í˜„í–‰\n",
            "ìˆ˜ì¤€\n",
            "ì¼ìƒ\n",
            "ìƒí™œ\n",
            "ï‚Ÿ ë³´í˜¸ìì˜ ë„ì›€ì„ ë°›ì•„ ì‹ì‚¬ë¥¼ í•¨\n",
            "ï‚Ÿ ê¸°ì €ê·€ë¥¼ ì°©ìš©í•¨\n",
            "ì‚¬íšŒ\n",
            "ì •ì„œ\n",
            "ï‚Ÿ ì—„ë§ˆì™€ ì• ì°©í˜•ì„±ì´ ì˜ ë˜ì–´ ìˆìŒ\n",
            "ì¸ì§€ ï‚Ÿ ë‹¨ì–´ ë° ë¬¸ì¥ì„ ì½ì„ ìˆ˜ ìˆê³ , ìµœê·¼ ìˆ˜ì„¸ê¸°ì— \n",
            "  ê´€ì‹¬ì„ ê°–ê¸° ì‹œì‘í•¨\n",
            "ì˜ì‚¬\n",
            "ì†Œí†µ\n",
            "ï‚Ÿ ì§§ì€ ë‹¨ì–´ ë° ë¬¸ì¥ìœ¼ë¡œ ìì‹ ì˜ ìš”êµ¬ë¥¼ í‘œí˜„í•  \n",
            "  ìˆ˜ ìˆìŒ\n",
            "ì‹ ì²´\n",
            "ìš´ë™\n",
            "ï‚Ÿ ë˜ë˜ì— ë¹„í•˜ì—¬ ì²´êµ¬ê°€ ì‘ê³ , ëŒ€Â·ì†Œê·¼ìœ¡ì˜\n",
            "  ë°œë‹¬ì´ ëŠë¦¼\n",
            "í•˜ì˜ì´ì˜\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(non_empty_pages[100].page_content[:500])  # ì²« í˜ì´ì§€ì˜ ì•ë¶€ë¶„ ë¯¸ë¦¬ë³´ê¸°"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "207edc64-fbe5-455c-85ba-5bd7962c3631",
      "metadata": {
        "id": "207edc64-fbe5-455c-85ba-5bd7962c3631",
        "outputId": "85834b48-ce51-49ea-ab04-b4964e6d616a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "124\n"
          ]
        }
      ],
      "source": [
        "# ë¬¸ì„œ ë¶„í• \n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "# ë¬¸ì„œ ë¶„í• ê¸° ì •ì˜\n",
        "splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1500,\n",
        "    chunk_overlap=200\n",
        ")\n",
        "\n",
        "# í•„í„°ë§ëœ í˜ì´ì§€(non_empty_pages) ë¶„í• \n",
        "splits1 = splitter.split_documents(non_empty_pages)\n",
        "print(len(splits1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9bb4742d-17cf-483e-b236-8acd8f8102f3",
      "metadata": {
        "id": "9bb4742d-17cf-483e-b236-8acd8f8102f3"
      },
      "outputs": [],
      "source": [
        "# # ì„ë² ë”© í›„ ì €ì¥\n",
        "# # ì„ë² ë”© API í˜¸ì¶œë§ˆë‹¤ ë„ˆë¬´ ë§ì€ ì²­í¬ê°€ ë“¤ì–´ê°€ì§€ ì•Šë„ë¡ ë°°ì¹˜ ì‚¬ì´ì¦ˆ ì„¤ì •(í•œë²ˆì— í˜¸ì¶œí•  ê²½ìš° ì—ëŸ¬ ë°œìƒ)\n",
        "# from langchain_chroma import Chroma\n",
        "# from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "# embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
        "# path = \"data/guide-data_1\"\n",
        "\n",
        "# vectorstore1 = Chroma.from_documents(\n",
        "#     collection_name='guide-data_1', #ë²¡í„° DB ì•ˆì˜ ì»¬ë ‰ì…˜ ì´ë¦„\n",
        "#     collection_metadata={'hnsw:space':'cosine'}, #ìœ ì‚¬ë„ ê¸°ì¤€: ì½”ì‚¬ì¸ ê±°ë¦¬\n",
        "#     documents=splits1, #ì•ì„œ ìª¼ê°  ë¬¸ì„œ ì¡°ê°ë“¤\n",
        "#     embedding=embeddings, #ì‚¬ìš©í•  ì„ë² ë”© ëª¨ë¸ (OpenAI)\n",
        "#     persist_directory=path #ë°ì´í„°ë¥¼ ë¡œì»¬ì— ì €ì¥í•  ê²½ë¡œ\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fda4935-6a0c-4cb8-9f71-84ac41bd55c3",
      "metadata": {
        "id": "3fda4935-6a0c-4cb8-9f71-84ac41bd55c3",
        "outputId": "7f3ddd1c-d9eb-4d16-fdee-fd9e2f6e1432"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "124\n"
          ]
        }
      ],
      "source": [
        "print(vectorstore1._collection.count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "916a22e3-0090-44a5-b8c9-1c56d6143837",
      "metadata": {
        "id": "916a22e3-0090-44a5-b8c9-1c56d6143837"
      },
      "outputs": [],
      "source": [
        "# ì„ë² ë”© ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "path = 'data/guide-data_1'\n",
        "embeddings = OpenAIEmbeddings(model='text-embedding-3-large')\n",
        "vectorstore1 = Chroma(\n",
        "    collection_name='guide-data_1',\n",
        "    collection_metadata={'hnsw:space': 'cosine'},\n",
        "    embedding_function=embeddings,\n",
        "    persist_directory=path\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d284ad45-fc4d-4d13-9ae4-9a735c634ae5",
      "metadata": {
        "id": "d284ad45-fc4d-4d13-9ae4-9a735c634ae5",
        "outputId": "10153ac6-2524-4b73-9cda-56ba4c2e07a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "124\n"
          ]
        }
      ],
      "source": [
        "print(vectorstore1._collection.count())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24e78579-321c-420c-b473-462d26fca18e",
      "metadata": {
        "id": "24e78579-321c-420c-b473-462d26fca18e"
      },
      "source": [
        "#### 2. á„‡á…¡á†¯á„ƒá…¡á†¯á„Œá…¡á†¼á„‹á…¢-á„‹á…£á†¼á„‹á…²á†¨á„€á…µá„‰á…®á†¯.pdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee71bae9-59a1-4364-b90a-6ee15ef9072a",
      "metadata": {
        "id": "ee71bae9-59a1-4364-b90a-6ee15ef9072a",
        "outputId": "cc2d9ced-7a22-45eb-cb44-089c0525a947"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "144"
            ]
          },
          "execution_count": 127,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 2. á„‡á…¡á†¯á„ƒá…¡á†¯á„Œá…¡á†¼á„‹á…¢-á„‹á…£á†¼á„‹á…²á†¨á„€á…µá„‰á…®á†¯.pdf ë¡œë”©\n",
        "\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from pathlib import Path\n",
        "folder = Path('data')\n",
        "loader2 = PyPDFLoader(folder / 'á„‡á…¡á†¯á„ƒá…¡á†¯á„Œá…¡á†¼á„‹á…¢-á„‹á…£á†¼á„‹á…²á†¨á„€á…µá„‰á…®á†¯.pdf')\n",
        "pages2 = loader2.load()\n",
        "len(pages2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd7ad2fc-1b24-48f8-87c6-c2a546536653",
      "metadata": {
        "id": "fd7ad2fc-1b24-48f8-87c6-c2a546536653",
        "outputId": "be07e7fe-5908-4639-c898-ac64feb90c61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "page_content='50\n",
            "ì§ˆë¬¸ìˆì–´ìš”\n",
            "ì˜ìœ ì•„ë“¤ì€ ë³´ì™„ëŒ€ì²´ì˜ì‚¬ì†Œí†µì„ ì“°ê¸°ì—ëŠ” ë„ˆë¬´ ì–´ë¦°ê°€ìš”?\n",
            "ì•„ë‹ˆìš”. ë³´ì™„ëŒ€ì²´ì˜ì‚¬ì†Œí†µì˜ ì‚¬ìš©ì€ ì˜ìœ ì•„ë“¤ì—ê²Œë„ ì¤‘ìš”í•©ë‹ˆë‹¤. ì•„ë™ì˜ ì´ˆê¸° 3ë…„ê°„ì˜ \n",
            "ê²½í—˜ì´ ë‚˜ì¤‘ì— ë‡Œ ë°œë‹¬ì˜ ê¸°ì´ˆë¥¼ í˜•ì„±í•˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. ì•„ì´ì™€ ë¶€ëª¨ê°„ì˜ ìƒí˜¸ì‘ìš©ì€ ë§¤ìš° \n",
            "ì¤‘ìš”í•œ ê²½í—˜ì¸ë°, ë§Œì•½ ì–‘ìœ¡ìê°€ ì•„ì´ì˜ ë¯¸ë¬˜í•œ ì˜ì‚¬ì†Œí†µ í–‰ë™ì„ ì•Œì•„ì±„ì§€ ëª»í•˜ê³  ì ì ˆíˆ ë°˜ì‘\n",
            "í•´ì£¼ì§€ ëª»í•œë‹¤ë©´ ì´ˆê¸° ì˜ì‚¬ì†Œí†µ ê²½í—˜ì˜ ê²°í•ìœ¼ë¡œ ì´ì–´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë³´ì™„ëŒ€ì²´ì˜ì‚¬ì†Œí†µì˜ \n",
            "ë¹ ë¥¸ ì ìš©ì€ ì•„ë™ì´ ì˜ë„ì ì¸ ì˜ì‚¬ì†Œí†µí–‰ë™ì„ í•  ìˆ˜ ìˆë„ë¡ ë•ê³ , ì–‘ìœ¡ìê°€ ì•„ë™ì˜ ì˜ì‚¬ì†Œí†µ \n",
            "ì˜ë„ì— ì ì ˆíˆ ë°˜ì‘í•˜ê³  ê°•í™”í•´ì¤„ ìˆ˜ ìˆë„ë¡ ë„ìš¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
            "ì˜ìœ ì•„ê°€ ê¸°ë³¸ì  ìš”êµ¬ë¥¼ í‘œí˜„í•  ìˆ˜ ìˆìœ¼ë©´ ë³´ì™„ëŒ€ì²´ì˜ì‚¬ì†Œí†µì´ í•„ìš”ì—†ë‚˜ìš”?\n",
            "ì•„ë‹ˆìš”. ì¸ê°„ì˜ ì˜ì‚¬ì†Œí†µì€ ë‹¤ì–‘í•œ ê¸°ëŠ¥ì„ í•©ë‹ˆë‹¤. MaslowëŠ” ì¸ê°„ì—ê²Œ ê°€ì¥ ê¸°ì´ˆì ìœ¼ë¡œ \n",
            "ìƒë¦¬ì  ìš•êµ¬, ì•ˆì „ì˜ ìš•êµ¬, ì• ì •ê³¼ ê³µê°ì˜ ìš•êµ¬, ì¡´ê²½ì˜ ìš•êµ¬, ìì•„ì‹¤í˜„ì˜ ìš•êµ¬ê°€ ëª¨ë‘ ìˆë‹¤ê³  \n",
            "í•˜ì˜€ìŠµë‹ˆë‹¤. ì´ ëª¨ë“  ìš•êµ¬ë¥¼ ì¶©ì¡±í•˜ê¸° ìœ„í•´ì„œëŠ” ì˜ì‚¬ì†Œí†µì´ ê¼­ í•„ìš”í•©ë‹ˆë‹¤. ê¸°ë³¸ì ì¸ í•„ìš”ë‚˜ \n",
            "ìš”êµ¬ê°€ ìˆì„ ë•Œë§Œì´ ì•„ë‹ˆê³  ì•Œê³  ìˆëŠ” ê²ƒì„ ì „ë‹¬í•  ë•Œì—ë„, ì‚¬íšŒì  ì—í‹°ì¼“ ë˜ëŠ” ì‚¬íšŒì  ì¹œë°€\n",
            "í•¨ì„ í‘œí˜„í•˜ê¸° ìœ„í•´ì„œë„ ì˜ì‚¬ì†Œí†µì´ í•„ìš”í•©ë‹ˆë‹¤.\n",
            "í•˜ë‚˜ì”© í•˜ë‚˜ì”© ëŠ˜ë ¤ê°€ê¸°\n",
            "ì´ ëª¨ë“  ê²ƒì„ ë™ì‹œì— í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆê³  ì•„ë™ì´ ë°˜ì‘ì„ ë³´ì´ê¸° ì‹œì‘í•˜ëŠ” ê²ƒë¶€í„° í•˜\n",
            "ë‚˜ì”© ì§‘ì¤‘ì ìœ¼ë¡œ ë°˜ë³µí•˜ë©´ì„œ ì ì§„ì ìœ¼ë¡œ ëª©ë¡ì„ ëŠ˜ë ¤ê°€ì•¼ í•©ë‹ˆë‹¤. ë˜í•œ ì•„ë™ì´ ì•„\n",
            "ë¬´ ê²ƒë„ í•˜ì§€ ëª»í•œë‹¤ê³  ìƒê°ë˜ë©´ ì—„ë§ˆê°€ ë¶™ì´ê³  ë°˜ë³µí•˜ë‹¤ê°€ ì•„ë™ì´ ì§‘ì¤‘í•˜ê±°ë‚˜ ì§\n",
            "ì ‘ í•˜ë ¤ëŠ” ì‹œë„ë¥¼ ë³´ì´ë©´ ê²©ë ¤í•´ ì£¼ê±°ë‚˜ ë„ì™€ì£¼ë‹¤ê°€ ë„ì›€ì˜ ì–‘ì„ ì¡°ê¸ˆì”© ì¤„ì—¬ë‚˜ê°‘\n",
            "ë‹ˆë‹¤. ê¸°ì–µí•´ì•¼ í•  ê²ƒì´ ë‘ ê°€ì§€ ë” ìˆìŠµë‹ˆë‹¤.\n",
            "â€¢ ë‚´ ì•„ì´ì™€ ë§ì€ ì‹œê°„ì„ ë³´ë‚´ëŠ” ì‚¬ëŒë“¤ì´ ëª¨ë‘ í˜‘ë ¥í•˜ì—¬ í•¨ê»˜ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì¤‘\n",
            "ìš”í•©ë‹ˆë‹¤. ìš°ë¦¬ê°€ ì¼ë°˜ì ìœ¼ë¡œ ë§ì„ ë°°ìš°ëŠ” ìƒí™©ì„ ìƒìƒí•´ë³´ë©´ ê·¸ ì´ìœ ë¥¼ ì´í•´\n",
            "í•˜ì‹¤ ìˆ˜ ìˆì„ ê²ƒì…ë‹ˆë‹¤. \n",
            "â€¢ ì „ë¬¸ê°€ì˜ ë„ì›€ì„ ë°›ìœ¼ì‹­ì‹œì˜¤. ë³´ì™„ëŒ€ì²´ì˜ì‚¬ì†Œí†µì„ ì ìš©í•  ìˆ˜ ìˆëŠ” ì–¸ì–´ì¹˜ë£Œì‚¬\n",
            "ë‚˜ íŠ¹ìˆ˜êµì‚¬ë¥¼ ì°¾ì•„ë³´ì‹¤ ê²ƒì„ ì¶”ì²œí•©ë‹ˆë‹¤.' metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 18.0 (Windows)', 'creationdate': '2022-11-17T22:48:09+09:00', 'moddate': '2022-12-21T13:12:48+09:00', 'trapped': '/False', 'source': 'data/á„‡á…¡á†¯á„ƒá…¡á†¯á„Œá…¡á†¼á„‹á…¢-á„‹á…£á†¼á„‹á…²á†¨á„€á…µá„‰á…®á†¯.pdf', 'total_pages': 144, 'page': 49, 'page_label': '50'}\n"
          ]
        }
      ],
      "source": [
        "print(pages2[49])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3f7cf24-c2e9-44ed-abf6-07d5e3be56b9",
      "metadata": {
        "id": "d3f7cf24-c2e9-44ed-abf6-07d5e3be56b9",
        "outputId": "3143aeb1-fc49-47da-d688-cd9065be9fd4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "144\n"
          ]
        }
      ],
      "source": [
        "# ë¬¸ì„œ ë¶„í• \n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1500,\n",
        "    chunk_overlap=200 #500ìœ¼ë¡œ í•  ê²½ìš° í† í° ìˆ˜ê°€ ìµœëŒ€ í—ˆìš© í† í° ìˆ˜ë¥¼ ì´ˆê³¼í•˜ì—¬ ì¤„ì„.\n",
        ")\n",
        "splits2 = loader2.load_and_split(splitter)\n",
        "print(len(splits2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab549a28-aff6-48b9-bbbd-ce7a0ccb4f0b",
      "metadata": {
        "id": "ab549a28-aff6-48b9-bbbd-ce7a0ccb4f0b"
      },
      "outputs": [],
      "source": [
        "# # ì„ë² ë”© í›„ ì €ì¥\n",
        "# # ì„ë² ë”© API í˜¸ì¶œë§ˆë‹¤ ë„ˆë¬´ ë§ì€ ì²­í¬ê°€ ë“¤ì–´ê°€ì§€ ì•Šë„ë¡ ë°°ì¹˜ ì‚¬ì´ì¦ˆ ì„¤ì •(í•œë²ˆì— í˜¸ì¶œí•  ê²½ìš° ì—ëŸ¬ ë°œìƒ)\n",
        "# from langchain_chroma import Chroma\n",
        "# from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "# embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
        "# path = \"data/guide-data_2\"\n",
        "\n",
        "# vectorstore2 = Chroma.from_documents(\n",
        "#     collection_name='guide-data_2', #ë²¡í„° DB ì•ˆì˜ ì»¬ë ‰ì…˜ ì´ë¦„\n",
        "#     collection_metadata={'hnsw:space':'cosine'}, #ìœ ì‚¬ë„ ê¸°ì¤€: ì½”ì‚¬ì¸ ê±°ë¦¬\n",
        "#     documents=splits2, #ì•ì„œ ìª¼ê°  ë¬¸ì„œ ì¡°ê°ë“¤\n",
        "#     embedding=embeddings, #ì‚¬ìš©í•  ì„ë² ë”© ëª¨ë¸ (OpenAI)\n",
        "#     persist_directory=path #ë°ì´í„°ë¥¼ ë¡œì»¬ì— ì €ì¥í•  ê²½ë¡œ\n",
        "# )\n",
        "\n",
        "# print(vectorstore2._collection.count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe26c747-fba2-44ec-b12c-c577a9f0e766",
      "metadata": {
        "id": "fe26c747-fba2-44ec-b12c-c577a9f0e766",
        "outputId": "a205a15e-70bf-45ee-f37f-87862b0115e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "144\n"
          ]
        }
      ],
      "source": [
        "# ì„ë² ë”© ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "path = 'data/guide-data_2'\n",
        "embeddings = OpenAIEmbeddings(model='text-embedding-3-large')\n",
        "vectorstore2 = Chroma(\n",
        "    collection_name='guide-data_2',\n",
        "    collection_metadata={'hnsw:space': 'cosine'},\n",
        "    embedding_function=embeddings,\n",
        "    persist_directory=path\n",
        ")\n",
        "\n",
        "# %%% (END-of-Lab) %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
        "\n",
        "print(vectorstore2._collection.count())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ad3d92c-f006-44e5-ac7a-7c12a0347e7b",
      "metadata": {
        "id": "4ad3d92c-f006-44e5-ac7a-7c12a0347e7b"
      },
      "source": [
        "### data-2 ê´€ë ¨í•´ ì˜ˆìƒ ì§ˆë¬¸ ë§Œë“¤ê¸°_rag ìœ„í•œ ë°ì´í„° ì „ì²˜ë¦¬"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34db2879-5068-45d3-95ed-765d8fd429d3",
      "metadata": {
        "id": "34db2879-5068-45d3-95ed-765d8fd429d3",
        "outputId": "3cb47c0d-3e37-4580-bce2-74aa1b5acdc9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "144\n"
          ]
        }
      ],
      "source": [
        "# ë¬¸ì„œ ë¶„í• \n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1500,\n",
        "    chunk_overlap=200 #500ìœ¼ë¡œ í•  ê²½ìš° í† í° ìˆ˜ê°€ ìµœëŒ€ í—ˆìš© í† í° ìˆ˜ë¥¼ ì´ˆê³¼í•˜ì—¬ ì¤„ì„.\n",
        ")\n",
        "splits2 = loader2.load_and_split(splitter)\n",
        "print(len(splits2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf6921e2-22e7-4c4e-84f1-7cec4e1ca2c1",
      "metadata": {
        "id": "cf6921e2-22e7-4c4e-84f1-7cec4e1ca2c1",
        "outputId": "fe6e0b2c-c8b8-4cec-eaf1-abe033bb6c74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âš ï¸ ê±´ë„ˆëœ€: page 28, source: ê¸°íƒ€ / í˜ì´ì§€ 28\n",
            "âš ï¸ ê±´ë„ˆëœ€: page 29, source: ê¸°íƒ€ / í˜ì´ì§€ 29\n",
            "âš ï¸ ê±´ë„ˆëœ€: page 54, source: ê¸°íƒ€ / í˜ì´ì§€ 54\n",
            "âš ï¸ ê±´ë„ˆëœ€: page 55, source: ê¸°íƒ€ / í˜ì´ì§€ 55\n",
            "âš ï¸ ê±´ë„ˆëœ€: page 76, source: ê¸°íƒ€ / í˜ì´ì§€ 76\n",
            "âš ï¸ ê±´ë„ˆëœ€: page 77, source: ê¸°íƒ€ / í˜ì´ì§€ 77\n",
            "âš ï¸ ê±´ë„ˆëœ€: page 94, source: ê¸°íƒ€ / í˜ì´ì§€ 94\n",
            "âš ï¸ ê±´ë„ˆëœ€: page 95, source: ê¸°íƒ€ / í˜ì´ì§€ 95\n",
            "âš ï¸ ê±´ë„ˆëœ€: page 110, source: ê¸°íƒ€ / í˜ì´ì§€ 110\n",
            "âš ï¸ ê±´ë„ˆëœ€: page 118, source: ê¸°íƒ€ / í˜ì´ì§€ 118\n",
            "âš ï¸ ê±´ë„ˆëœ€: page 119, source: ê¸°íƒ€ / í˜ì´ì§€ 119\n",
            "âœ… ì™„ë£Œ! 'prequestion_list_for_parenting_skills.csv'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
          ]
        }
      ],
      "source": [
        "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
        "from langchain_chroma import Chroma\n",
        "from collections import defaultdict\n",
        "import pandas as pd\n",
        "import time\n",
        "import json\n",
        "import re\n",
        "\n",
        "### 1. ë²¡í„°ìŠ¤í† ì–´ ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "docs = vectorstore2.get()[\"documents\"]  # page_content\n",
        "metas = vectorstore2.get()[\"metadatas\"]\n",
        "\n",
        "### 2. LLM ì´ˆê¸°í™”\n",
        "llm = ChatOpenAI(model_name=\"gpt-4o\", temperature=0)\n",
        "\n",
        "### json ì¶”ì¶œ í•¨ìˆ˜\n",
        "def extract_json_from_response(text: str) -> dict:\n",
        "    try:\n",
        "        json_string = re.search(r\"\\{[\\s\\S]*?\\}\", text).group()  # ì¤‘ê´„í˜¸ ë¸”ë¡ ì¶”ì¶œ\n",
        "        return json.loads(json_string)\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ JSON ì¶”ì¶œ ì‹¤íŒ¨: {e}\")\n",
        "        return {}\n",
        "\n",
        "### 3. ì§ˆë¬¸ ìƒì„± í•¨ìˆ˜\n",
        "def generate_question_from_guide(guide_text: str) -> list[str]:\n",
        "    prompt = f\"\"\"\n",
        "The following sentence is an excerpt from a parenting guide for parents of children with developmental disabilities:\n",
        "\n",
        "\"{guide_text}\"\n",
        "\n",
        "Please generate 1-2 realistic and natural questions in Korean that a parent might ask, for which this sentence would be an appropriate answer.\n",
        "\n",
        "Respond in the following JSON format in **Korean**:\n",
        "\n",
        "{{\n",
        "  \"ì§ˆë¬¸\": [\n",
        "    \"ì§ˆë¬¸1\",\n",
        "    \"ì§ˆë¬¸2\"\n",
        "  ]\n",
        "}}\n",
        "If only one question fits, just return one inside the list.\n",
        "\"\"\"\n",
        "    try:\n",
        "        response = llm.predict(prompt)\n",
        "        json_data = extract_json_from_response(response)\n",
        "        return json_data.get(\"ì§ˆë¬¸\", [])\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ ì§ˆë¬¸ ìƒì„± ì‹¤íŒ¨: {e}\")\n",
        "        return []\n",
        "\n",
        "### 4. ì±•í„° êµ¬ì¡°\n",
        "chapter_map = [\n",
        "    {\n",
        "        \"chapter_num\": 1,\n",
        "        \"chapter_title\": \"ê±´ê°•ê´€ë¦¬\",\n",
        "        \"sections\": [\n",
        "            (12, 19, \"1. ìš°ë¦¬ ì•„ì´ ê±´ê°•ê´€ë¦¬ì™€ ì‘ê¸‰ì²˜ì¹˜\"),\n",
        "            (20, 21, \"2. ìš°ë¦¬ ì•„ì´ ì˜ì–‘ê´€ë¦¬\"),\n",
        "            (22, 27, \"3. ìš°ë¦¬ ì•„ì´ ì‹ìŠµê´€ ê´€ë¦¬ ë° ì§€ë„\")\n",
        "        ]\n",
        "    },\n",
        "    {\n",
        "        \"chapter_num\": 2,\n",
        "        \"chapter_title\": \"ì˜ì‚¬ì†Œí†µ\",\n",
        "        \"sections\": [\n",
        "            (30, 43, \"1. ì–´íœ˜ ë° ì˜ì‚¬ì†Œí†µ ë°œë‹¬ ì´‰ì§„\"),\n",
        "            (44, 53, \"2. ëŒ€ì•ˆì  ì˜ì‚¬ì†Œí†µ ì§€ì›\")\n",
        "        ]\n",
        "    },\n",
        "    {\n",
        "        \"chapter_num\": 3,\n",
        "        \"chapter_title\": \"êµìœ¡ì§€ì›\",\n",
        "        \"sections\": [\n",
        "            (56, 62, \"1. ìœ ì•„êµìœ¡ê¸°ê´€ ì·¨í•™ ì¤€ë¹„\"),\n",
        "            (63, 66, \"2. ìœ ì•„êµìœ¡ê¸°ê´€ì—ì„œì˜ êµìœ¡í™œë™\"),\n",
        "            (67, 68, \"3. ì´ˆë“±í•™êµ ì·¨í•™ ì¤€ë¹„\"),\n",
        "            (69, 71, \"4. ë˜ë˜ì™€ í•¨ê»˜ ìƒí™œí•˜ê¸°\"),\n",
        "            (72, 75, \"ë¶€ë¡. ì–‘ìœ¡ ì‚¬ë¡€\")\n",
        "        ]\n",
        "    },\n",
        "    {\n",
        "        \"chapter_num\": 4,\n",
        "        \"chapter_title\": \"í–‰ë™ì§€ì›\",\n",
        "        \"sections\": [\n",
        "            (78, 79, \"1. í–‰ë™ì˜ ê¸°ëŠ¥\"),\n",
        "            (80, 83, \"2. ë¬¸ì œí–‰ë™ ì¤‘ì¬ ë°©ë²•\"),\n",
        "            (84, 89, \"3. ë¬¸ì œí–‰ë™ ëŒ€ì²˜í•˜ê¸°\"),\n",
        "            (90, 93, \"4. ë°”ëŒì§í•œ í›ˆìœ¡ ë°©ë²•\")\n",
        "        ]\n",
        "    },\n",
        "    {\n",
        "        \"chapter_num\": 5,\n",
        "        \"chapter_title\": \"ì¼ìƒìƒí™œ\",\n",
        "        \"sections\": [\n",
        "            (96, 102, \"1. ë°°ë³€ìŠµê´€ ê¸°ë¥´ê¸°\"),\n",
        "            (103, 109, \"2. ì°©íƒˆì˜ ìŠµê´€ ê¸°ë¥´ê¸°\"),\n",
        "            (110, 109, \"3. ê°€ì • ë‚´ ë†€ì´í™˜ê²½ ê¾¸ë¯¸ê¸°\"),  # í˜ì´ì§€ ëˆ„ë½ ê°€ëŠ¥\n",
        "            (111, 114, \"4. ë†€ì´í•  ë•Œ ë‹¤ë£¨ê¸° ì–´ë ¤ìš´ í–‰ë™\"),\n",
        "            (115, 116, \"5. ì•ˆì „í•œ ë†€ì´ í™˜ê²½ ê¾¸ë¯¸ê¸°\")\n",
        "        ]\n",
        "    },\n",
        "    {\n",
        "        \"chapter_num\": 6,\n",
        "        \"chapter_title\": \"ê¶Œë¦¬ì˜¹í˜¸\",\n",
        "        \"sections\": [\n",
        "            (120, 125, \"1. ì•„ì´ê°€ ìœ„í—˜í•œ ìƒí™©ì— ë†“ì˜€ì„ ë•Œ\"),\n",
        "            (126, 131, \"2. ì¼ìƒìƒí™œì—ì„œ ì°¨ë³„ì„ ë‹¹í–ˆì„ ë•Œ\")\n",
        "        ]\n",
        "    }\n",
        "]\n",
        "\n",
        "### 5. ì±•í„° ë§¤í•‘ í•¨ìˆ˜\n",
        "def get_structured_source(page_str: str) -> str:\n",
        "    try:\n",
        "        page = int(page_str)\n",
        "    except ValueError:\n",
        "        return \"ì¶œì²˜ ì—†ìŒ\"\n",
        "\n",
        "    for chapter in chapter_map:\n",
        "        for start, end, section_title in chapter[\"sections\"]:\n",
        "            if start <= page <= end:\n",
        "                return f\"ã€Œì¥ì• ì˜ìœ ì•„ ì–‘ìœ¡ ê°€ì´ë“œë¶ 2ê¶Œ ë°œë‹¬ì¥ì• -ì–‘ìœ¡ê¸°ìˆ ã€, êµ­ë¦½íŠ¹ìˆ˜êµìœ¡ì›, ì±•í„° {chapter['chapter_num']}. {chapter['chapter_title']} / {section_title}, {page}ìª½\"\n",
        "\n",
        "    return f\"ê¸°íƒ€ / í˜ì´ì§€ {page}\"\n",
        "\n",
        "\n",
        "### 6. ì „ì²´ ì‹¤í–‰\n",
        "results = []\n",
        "\n",
        "for i, (doc_text, meta) in enumerate(zip(docs[11:129], metas[11:129])):\n",
        "    guide_text = doc_text.strip()\n",
        "    page_str = meta.get('page_label', \"0\")\n",
        "    source = get_structured_source(page_str)\n",
        "\n",
        "    # ì±•í„° ë²”ìœ„ ë°–ì¼ ê²½ìš° ê±´ë„ˆë›°ê¸°\n",
        "    if source.startswith(\"ê¸°íƒ€ / í˜ì´ì§€\") or \"ì¶œì²˜ ì—†ìŒ\" in source:\n",
        "        print(f\"âš ï¸ ê±´ë„ˆëœ€: page {page_str}, source: {source}\")\n",
        "        continue\n",
        "\n",
        "    questions = generate_question_from_guide(guide_text)\n",
        "    for question in questions:\n",
        "        results.append({\n",
        "            \"ì§ˆë¬¸\": question,\n",
        "            \"ì›ë¬¸ ë°ì´í„°\": guide_text,\n",
        "            \"ì¶œì²˜\": source\n",
        "        })\n",
        "        time.sleep(1.2)  # LLM ìš”ì²­ ê³¼ë‹¤ ë°©ì§€\n",
        "\n",
        "### 7. Pandasë¡œ ì •ë¦¬\n",
        "df = pd.DataFrame(results)\n",
        "df.to_csv(\"prequestion_list_for_parenting_skills.csv\", index=False)\n",
        "print(\"âœ… ì™„ë£Œ! 'prequestion_list_for_parenting_skills.csv'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d64aff7-ca4a-4142-9d8b-88382f4854fb",
      "metadata": {
        "id": "7d64aff7-ca4a-4142-9d8b-88382f4854fb",
        "outputId": "d42660a9-6e29-4a2b-9e00-d77244737a1e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ì§ˆë¬¸</th>\n",
              "      <th>ì›ë¬¸ ë°ì´í„°</th>\n",
              "      <th>ì¶œì²˜</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>MMR ì˜ˆë°©ì ‘ì¢…ì´ ìíì„±ì¥ì• ë¥¼ ìœ ë°œí•  ìˆ˜ ìˆë‹¤ëŠ” ì£¼ì¥ì´ ìˆë˜ë°, ì •ë§ ê·¸ëŸ°ê°€ìš”?</td>\n",
              "      <td>12\\n1. ìš°ë¦¬ ì•„ì´ ê±´ê°•ê´€ë¦¬ì™€ ì‘ê¸‰ì²˜ì¹˜\\nâŠ ì˜ˆë°©ì ‘ì¢…ì€ ê¼­ ë°›ë„ë¡ í•©ì‹œë‹¤\\nì§€ë‚œ...</td>\n",
              "      <td>ã€Œì¥ì• ì˜ìœ ì•„ ì–‘ìœ¡ ê°€ì´ë“œë¶ 2ê¶Œ ë°œë‹¬ì¥ì• -ì–‘ìœ¡ê¸°ìˆ ã€, êµ­ë¦½íŠ¹ìˆ˜êµìœ¡ì›, ì±•í„° 1. ê±´...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ìš°ë¦¬ ì•„ì´ì—ê²Œ MMR ì˜ˆë°©ì ‘ì¢…ì„ ê¼­ í•´ì•¼ í• ê¹Œìš”?</td>\n",
              "      <td>12\\n1. ìš°ë¦¬ ì•„ì´ ê±´ê°•ê´€ë¦¬ì™€ ì‘ê¸‰ì²˜ì¹˜\\nâŠ ì˜ˆë°©ì ‘ì¢…ì€ ê¼­ ë°›ë„ë¡ í•©ì‹œë‹¤\\nì§€ë‚œ...</td>\n",
              "      <td>ã€Œì¥ì• ì˜ìœ ì•„ ì–‘ìœ¡ ê°€ì´ë“œë¶ 2ê¶Œ ë°œë‹¬ì¥ì• -ì–‘ìœ¡ê¸°ìˆ ã€, êµ­ë¦½íŠ¹ìˆ˜êµìœ¡ì›, ì±•í„° 1. ê±´...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ë°œë‹¬ì¥ì• ê°€ ìˆëŠ” ì•„ì´ì˜ ì˜ˆë°©ì ‘ì¢…ì€ ì–´ë–»ê²Œ í•´ì•¼ í•˜ë‚˜ìš”?</td>\n",
              "      <td>ê±´ê°•ê´€ë¦¬ _ 13\\n01\\n02\\n03\\n04\\n05\\n06\\në‡Œ ì†ìƒì´ ë°œìƒí•œ ì‚¬...</td>\n",
              "      <td>ã€Œì¥ì• ì˜ìœ ì•„ ì–‘ìœ¡ ê°€ì´ë“œë¶ 2ê¶Œ ë°œë‹¬ì¥ì• -ì–‘ìœ¡ê¸°ìˆ ã€, êµ­ë¦½íŠ¹ìˆ˜êµìœ¡ì›, ì±•í„° 1. ê±´...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ì•„ì´ì˜ ì˜ˆë°©ì ‘ì¢… ì¼ì •í‘œë¥¼ ì–´ë””ì„œ í™•ì¸í•  ìˆ˜ ìˆë‚˜ìš”?</td>\n",
              "      <td>ê±´ê°•ê´€ë¦¬ _ 13\\n01\\n02\\n03\\n04\\n05\\n06\\në‡Œ ì†ìƒì´ ë°œìƒí•œ ì‚¬...</td>\n",
              "      <td>ã€Œì¥ì• ì˜ìœ ì•„ ì–‘ìœ¡ ê°€ì´ë“œë¶ 2ê¶Œ ë°œë‹¬ì¥ì• -ì–‘ìœ¡ê¸°ìˆ ã€, êµ­ë¦½íŠ¹ìˆ˜êµìœ¡ì›, ì±•í„° 1. ê±´...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ìš°ë¦¬ ì•„ì´ì˜ êµ¬ê°•ê´€ë¦¬ëŠ” ì–´ë–»ê²Œ í•´ì•¼ í•˜ë‚˜ìš”?</td>\n",
              "      <td>14\\nâ‹ ìš°ë¦¬ ì•„ì´ êµ¬ê°•ê´€ë¦¬ëŠ” ì´ë ‡ê²Œ í•©ì‹œë‹¤\\nì˜ìœ ì•„ì˜ êµ¬ê°•ê´€ë¦¬\\nì¹˜ì•„ê°€ í•œ ê°œ ...</td>\n",
              "      <td>ã€Œì¥ì• ì˜ìœ ì•„ ì–‘ìœ¡ ê°€ì´ë“œë¶ 2ê¶Œ ë°œë‹¬ì¥ì• -ì–‘ìœ¡ê¸°ìˆ ã€, êµ­ë¦½íŠ¹ìˆ˜êµìœ¡ì›, ì±•í„° 1. ê±´...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             ì§ˆë¬¸  \\\n",
              "0  MMR ì˜ˆë°©ì ‘ì¢…ì´ ìíì„±ì¥ì• ë¥¼ ìœ ë°œí•  ìˆ˜ ìˆë‹¤ëŠ” ì£¼ì¥ì´ ìˆë˜ë°, ì •ë§ ê·¸ëŸ°ê°€ìš”?   \n",
              "1                   ìš°ë¦¬ ì•„ì´ì—ê²Œ MMR ì˜ˆë°©ì ‘ì¢…ì„ ê¼­ í•´ì•¼ í• ê¹Œìš”?   \n",
              "2                ë°œë‹¬ì¥ì• ê°€ ìˆëŠ” ì•„ì´ì˜ ì˜ˆë°©ì ‘ì¢…ì€ ì–´ë–»ê²Œ í•´ì•¼ í•˜ë‚˜ìš”?   \n",
              "3                  ì•„ì´ì˜ ì˜ˆë°©ì ‘ì¢… ì¼ì •í‘œë¥¼ ì–´ë””ì„œ í™•ì¸í•  ìˆ˜ ìˆë‚˜ìš”?   \n",
              "4                      ìš°ë¦¬ ì•„ì´ì˜ êµ¬ê°•ê´€ë¦¬ëŠ” ì–´ë–»ê²Œ í•´ì•¼ í•˜ë‚˜ìš”?   \n",
              "\n",
              "                                              ì›ë¬¸ ë°ì´í„°  \\\n",
              "0  12\\n1. ìš°ë¦¬ ì•„ì´ ê±´ê°•ê´€ë¦¬ì™€ ì‘ê¸‰ì²˜ì¹˜\\nâŠ ì˜ˆë°©ì ‘ì¢…ì€ ê¼­ ë°›ë„ë¡ í•©ì‹œë‹¤\\nì§€ë‚œ...   \n",
              "1  12\\n1. ìš°ë¦¬ ì•„ì´ ê±´ê°•ê´€ë¦¬ì™€ ì‘ê¸‰ì²˜ì¹˜\\nâŠ ì˜ˆë°©ì ‘ì¢…ì€ ê¼­ ë°›ë„ë¡ í•©ì‹œë‹¤\\nì§€ë‚œ...   \n",
              "2  ê±´ê°•ê´€ë¦¬ _ 13\\n01\\n02\\n03\\n04\\n05\\n06\\në‡Œ ì†ìƒì´ ë°œìƒí•œ ì‚¬...   \n",
              "3  ê±´ê°•ê´€ë¦¬ _ 13\\n01\\n02\\n03\\n04\\n05\\n06\\në‡Œ ì†ìƒì´ ë°œìƒí•œ ì‚¬...   \n",
              "4  14\\nâ‹ ìš°ë¦¬ ì•„ì´ êµ¬ê°•ê´€ë¦¬ëŠ” ì´ë ‡ê²Œ í•©ì‹œë‹¤\\nì˜ìœ ì•„ì˜ êµ¬ê°•ê´€ë¦¬\\nì¹˜ì•„ê°€ í•œ ê°œ ...   \n",
              "\n",
              "                                                  ì¶œì²˜  \n",
              "0  ã€Œì¥ì• ì˜ìœ ì•„ ì–‘ìœ¡ ê°€ì´ë“œë¶ 2ê¶Œ ë°œë‹¬ì¥ì• -ì–‘ìœ¡ê¸°ìˆ ã€, êµ­ë¦½íŠ¹ìˆ˜êµìœ¡ì›, ì±•í„° 1. ê±´...  \n",
              "1  ã€Œì¥ì• ì˜ìœ ì•„ ì–‘ìœ¡ ê°€ì´ë“œë¶ 2ê¶Œ ë°œë‹¬ì¥ì• -ì–‘ìœ¡ê¸°ìˆ ã€, êµ­ë¦½íŠ¹ìˆ˜êµìœ¡ì›, ì±•í„° 1. ê±´...  \n",
              "2  ã€Œì¥ì• ì˜ìœ ì•„ ì–‘ìœ¡ ê°€ì´ë“œë¶ 2ê¶Œ ë°œë‹¬ì¥ì• -ì–‘ìœ¡ê¸°ìˆ ã€, êµ­ë¦½íŠ¹ìˆ˜êµìœ¡ì›, ì±•í„° 1. ê±´...  \n",
              "3  ã€Œì¥ì• ì˜ìœ ì•„ ì–‘ìœ¡ ê°€ì´ë“œë¶ 2ê¶Œ ë°œë‹¬ì¥ì• -ì–‘ìœ¡ê¸°ìˆ ã€, êµ­ë¦½íŠ¹ìˆ˜êµìœ¡ì›, ì±•í„° 1. ê±´...  \n",
              "4  ã€Œì¥ì• ì˜ìœ ì•„ ì–‘ìœ¡ ê°€ì´ë“œë¶ 2ê¶Œ ë°œë‹¬ì¥ì• -ì–‘ìœ¡ê¸°ìˆ ã€, êµ­ë¦½íŠ¹ìˆ˜êµìœ¡ì›, ì±•í„° 1. ê±´...  "
            ]
          },
          "execution_count": 230,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# CSV íŒŒì¼ ê²½ë¡œ\n",
        "csv_path = \"data/prequestion_list_for_parenting_skills.csv\"\n",
        "\n",
        "# CSV íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# ë°ì´í„°í”„ë ˆì„ ë¯¸ë¦¬ë³´ê¸°\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11a8f80a-ff94-4551-94a0-eed22d441b0c",
      "metadata": {
        "id": "11a8f80a-ff94-4551-94a0-eed22d441b0c"
      },
      "outputs": [],
      "source": [
        "#ì„ë² ë”© ì €ì¥\n",
        "# from langchain_core.documents import Document\n",
        "# from langchain_openai import OpenAIEmbeddings\n",
        "# from langchain_chroma import Chroma\n",
        "\n",
        "# # ì„ë² ë”© ëª¨ë¸ ë° ì €ì¥ ê²½ë¡œ\n",
        "# embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
        "# path = \"data/pre-qna-parenting\"\n",
        "\n",
        "# # 2. textsì™€ metadatas ìƒì„±\n",
        "# texts = (df[\"ì§ˆë¬¸\"] + \"\\n\" + df[\"ì›ë¬¸ ë°ì´í„°\"]).tolist()\n",
        "# metadatas = df[[\"ì§ˆë¬¸\", \"ì›ë¬¸ ë°ì´í„°\", \"ì¶œì²˜\"]].to_dict(orient=\"records\")\n",
        "\n",
        "# # 3. Chroma ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ë° ì €ì¥\n",
        "# vectorstore2_2 = Chroma.from_texts(\n",
        "#     texts=texts,\n",
        "#     embedding=embeddings,\n",
        "#     metadatas=metadatas,\n",
        "#     collection_name=\"pre-qna-parenting\",\n",
        "#     collection_metadata={\"source\": \"ì–‘ìœ¡ê°€ì´ë“œ QnA\"},\n",
        "#     persist_directory=path\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8714c7ec-ad7a-468e-9c0c-a1dbbbd5b104",
      "metadata": {
        "id": "8714c7ec-ad7a-468e-9c0c-a1dbbbd5b104",
        "outputId": "6e1e4c80-83eb-4209-acdf-ee20f33db7b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "213\n"
          ]
        }
      ],
      "source": [
        "# ì„ë² ë”© ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "path = 'data/pre-qna-parenting'\n",
        "embeddings = OpenAIEmbeddings(model='text-embedding-3-large')\n",
        "vectorstore2_2 = Chroma(\n",
        "    collection_name='pre-qna-parenting',\n",
        "    collection_metadata={\"source\": \"ì–‘ìœ¡ê°€ì´ë“œ QnA\"},\n",
        "    embedding_function=embeddings,\n",
        "    persist_directory=path\n",
        ")\n",
        "\n",
        "# %%% (END-of-Lab) %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
        "\n",
        "print(vectorstore2_2._collection.count())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5dc5794",
      "metadata": {},
      "source": [
        "## Node êµ¬ì„±"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "89ad6f95-9bc1-4b01-951b-e1114ff9ebe2",
      "metadata": {
        "id": "89ad6f95-9bc1-4b01-951b-e1114ff9ebe2"
      },
      "outputs": [],
      "source": [
        "# ëª¨ë¸ ë° íŒŒë¼ë¯¸í„° ì„¤ì •\n",
        "from langchain.chat_models import init_chat_model\n",
        "\n",
        "#YouTubeSummaryNodeì—ì„œ ì‚¬ìš©í•  ëª¨ë¸\n",
        "summarize_model = init_chat_model(\n",
        "    model='openai:gpt-4.1-mini',\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "#DocumentReviewNodeì—ì„œ ì‚¬ìš©í•  ëª¨ë¸\n",
        "doc_review_model = init_chat_model(\n",
        "    model='openai:gpt-4.1-mini',\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "#AnswerGenerationNodeì—ì„œ ì‚¬ìš©í•  ëª¨ë¸\n",
        "answering_model = init_chat_model(\n",
        "    model='openai:gpt-4.1',\n",
        "    temperature=0\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1096ff4d-e1bd-4973-b4c8-712bce105ba5",
      "metadata": {
        "id": "1096ff4d-e1bd-4973-b4c8-712bce105ba5"
      },
      "outputs": [],
      "source": [
        "# ë°ì´í„° ìŠ¤í‚¤ë§ˆ ì •ì˜\n",
        "# DocumentReviewNodeì˜ ì‘ì—… í‹€ ë§Œë“¤ê¸°\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import Literal\n",
        "\n",
        "class GradeDocument(BaseModel): #ë¬¸ì„œì˜ ê´€ë ¨ì„± í‰ê°€ ê²°ê³¼ë¥¼ ë‹´ëŠ” ë°ì´í„° ëª¨ë¸\n",
        "    #í•„ë“œ ì´ë¦„: ë¬¸ì„œê°€ ê´€ë ¨ ìˆëŠ”ì§€ ì—¬ë¶€, ì´ í•„ë“œ ê°’ì€ ë°˜ë“œì‹œ ì´ ë‘ ê°’ ì¤‘ í•˜ë‚˜ì—¬ì•¼ í•¨\n",
        "    relevance: Literal['relevant', 'irrelevant'] = Field(\n",
        "        ...,\n",
        "        description='Indicates whether the document is relevent to the query: '\n",
        "                    \"'relevent' or 'irrelevant'\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8a74c13-3f46-45b2-be95-9d8761e036c5",
      "metadata": {
        "id": "e8a74c13-3f46-45b2-be95-9d8761e036c5"
      },
      "outputs": [],
      "source": [
        "# ê·¸ë˜í”„ ìƒíƒœ ì •ì˜\n",
        "import operator\n",
        "from langchain.schema import Document\n",
        "from typing import TypedDict, Annotated, List, Dict\n",
        "\n",
        "class State(TypedDict):\n",
        "    new_video: str\n",
        "    video_url: str # ì˜ìƒ ì£¼ì†Œ\n",
        "    video_transcript: str\n",
        "    video_summary: str # ì˜ìƒ ë‚´ìš© ìš”ì•½ë³¸\n",
        "    recommendation: List[Dict[str, str]] # ë‹¤ëª¨ì•„ ì˜ìƒ ì¶”ì²œ\n",
        "    answer: str # ìƒì„±ëœ ë‹µë³€\n",
        "    formatted_output: str\n",
        "    documents: Annotated[List, operator.add] # rag ê²€ìƒ‰ì‹œ ì°¸ì¡°ëœ ë¬¸ì„œë“¤\n",
        "    option: Literal['parenting_skill', 'play_reco', 'video recommendation'] # ê³ ë¥¸ ì„ íƒì§€(ëŒ€í™”, ì–‘ìœ¡ê¸°ìˆ  ê°€ì´ë“œ, ë†€ì´ ì¶”ì²œ, ì˜ìƒ ì¶”ì²œ)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aea1a0cc-6c3b-41ac-9268-586794c14d04",
      "metadata": {
        "id": "aea1a0cc-6c3b-41ac-9268-586794c14d04"
      },
      "source": [
        "### 1. RetrieverNode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ade008c3-363d-46c7-9de3-532245a44f50",
      "metadata": {
        "id": "ade008c3-363d-46c7-9de3-532245a44f50"
      },
      "outputs": [],
      "source": [
        "# ê²€ìƒ‰ ë° ì¶”ì¶œ ë…¸ë“œ í´ë˜ìŠ¤ ì •ì˜\n",
        "from langchain_core.runnables import Runnable\n",
        "from langchain import hub\n",
        "from typing import Optional\n",
        "\n",
        "#ì£¼ì–´ì§„ ì§ˆë¬¸ì— ëŒ€í•´ ë²¡í„° ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ê³ , ê·¸ ê²°ê³¼ ë¬¸ì„œë“¤ì„ stateì— ì¶”ê°€\n",
        "class RetrieverNode:\n",
        "    \"\"\"\n",
        "    ê²€ìƒ‰ ë° ì¶”ì¶œ ì—ì´ì „íŠ¸ í´ë˜ìŠ¤ ë…¸ë“œ\n",
        "    ë²¡í„°ìŠ¤í† ì–´ ê²€ìƒ‰ê¸°ë¥¼ ì‚¬ìš©í•˜ì—¬ ì§ˆë¬¸ì— ëŒ€í•œ ê´€ë ¨ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ê³  ì¶”ì¶œí•œë‹¤.\n",
        "    \"\"\"\n",
        "    def __init__(self, runnable: Runnable) -> None:\n",
        "        self.__runnable = runnable\n",
        "\n",
        "    def __call__(self, state: State) -> State:\n",
        "        node_name = '--- Retriever node'\n",
        "        print(f'\\n{node_name} {'-' * (79 - len('\\n') - len(node_name) - 1)}')\n",
        "\n",
        "        # í˜„ì¬ ê·¸ë˜í”„ ìƒíƒœì—ì„œ ì§ˆë¬¸ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¨ë‹¤.\n",
        "        video_summary = state['video_summary']\n",
        "\n",
        "        # ê²€ìƒ‰ ë° ì¶”ì¶œì„ ì‹¤í–‰í•œë‹¤.\n",
        "        documents = self.__runnable.invoke(video_summary)\n",
        "\n",
        "        # ê¸°ì¡´ ìƒíƒœì— ë¬¸ì„œ ë°ì´í„°ë¥¼ ì¶”ê°€í•˜ê³  ë°˜í™˜í•œë‹¤.\n",
        "        # print(f'retrieverNodeì—ì„œ ë³¸ ì˜µì…˜ {state.get('option')}')\n",
        "        return state | {'documents': documents}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2eba7cb9-e3f8-4c21-a098-736436a7ee3b",
      "metadata": {
        "id": "2eba7cb9-e3f8-4c21-a098-736436a7ee3b",
        "outputId": "f2ee955f-710c-400b-99ed-9d1740b3eacb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“Œ ì´ ì˜ìƒì—ì„œëŠ” ë°œë‹¬ì¥ì•  ì•„ë™ì´ ìŠ¤ìŠ¤ë¡œ ë¬¼ê±´ì„ ì •ë¦¬í•˜ëŠ” ë°©ë²•ê³¼ ê·¸ ì¤‘ìš”ì„±ì— ëŒ€í•´ ë°°ìš¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì•„ì´ê°€ ì¼ìƒì—ì„œ ì •ë¦¬ ìŠµê´€ì„ ê¸°ë¥´ê¸° ìœ„í•´ì„œëŠ” ë¶€ëª¨ì™€ í•¨ê»˜ ë†€ì´ë¥¼ í†µí•´ ìì—°ìŠ¤ëŸ½ê²Œ ì—°ìŠµí•˜ëŠ” ê²ƒì´ ë„ì›€ì´ ë©ë‹ˆë‹¤. ì•„ë˜ì˜ ë†€ì´ í™œë™ì€ ì•„ì´ê°€ ì •ë¦¬ì •ëˆì„ ì¬ë¯¸ìˆê²Œ ìµíˆê³ , ë™ì‹œì— ì†Œê·¼ìœ¡ ë°œë‹¬ê³¼ ì¸ì§€ ëŠ¥ë ¥, ì˜ì‚¬ì†Œí†µ ëŠ¥ë ¥ê¹Œì§€ í•¨ê»˜ í‚¤ìš¸ ìˆ˜ ìˆë„ë¡ ë„ì™€ì¤ë‹ˆë‹¤.\n",
            "\n",
            "ğŸ™‹â€â™€ï¸ ë” ì•Œê³  ì‹¶ì–´ìš”!\n",
            "ğŸ® ë†€ì´ ì¶”ì²œ: ì •ë¦¬ì •ëˆ ëª¨ë°© ë†€ì´\n",
            "\n",
            "ğŸ“œ ë†€ì´ ê³¼ì •:\n",
            "1ï¸âƒ£ ë¶€ëª¨ë‹˜ì´ ë¨¼ì € ì±…ìƒ ìœ„ì— ì—¬ëŸ¬ ê°€ì§€ ë¬¼ê±´(ì±…, ì—°í•„, ì¥ë‚œê° ë“±)ì„ ì–´ì§€ëŸ½í˜€ ë†“ìŠµë‹ˆë‹¤.\n",
            "2ï¸âƒ£ ì•„ì´ì—ê²Œ 'ì´ì œ ìš°ë¦¬ ê°™ì´ ì •ë¦¬í•´ë³¼ê¹Œ?'ë¼ê³  ë§í•˜ë©°, í•˜ë‚˜ì”© ë¬¼ê±´ì„ ì œìë¦¬ì— ë†“ëŠ” ëª¨ìŠµì„ ì²œì²œíˆ ë³´ì—¬ì¤ë‹ˆë‹¤.\n",
            "3ï¸âƒ£ ì•„ì´ê°€ ë¶€ëª¨ë‹˜ì˜ í–‰ë™ì„ ë”°ë¼í•  ìˆ˜ ìˆë„ë¡ ê²©ë ¤í•˜ë©°, 'ì´ê±´ ì–´ë””ì— ë‘˜ê¹Œ?', 'ì—°í•„ì€ í•„í†µì— ë„£ì–´ë³¼ê¹Œ?'ì™€ ê°™ì´ ì§ˆë¬¸ì„ ë˜ì§‘ë‹ˆë‹¤.\n",
            "4ï¸âƒ£ ì•„ì´ê°€ ì§ì ‘ ë¬¼ê±´ì„ ì •ë¦¬í•  ë•Œë§ˆë‹¤ ì¹­ì°¬í•´ì£¼ê³ , ì •ë¦¬ëœ ê³µê°„ì„ í•¨ê»˜ ë³´ë©° 'ì •ë¦¬ê°€ ì˜ ë˜ì—ˆë„¤!'ë¼ê³  ê¸ì •ì ì¸ í”¼ë“œë°±ì„ ì¤ë‹ˆë‹¤.\n",
            "5ï¸âƒ£ ë†€ì´ê°€ ëë‚œ í›„ì—ëŠ” ì •ë¦¬ì •ëˆì´ ì™œ ì¤‘ìš”í•œì§€, ì •ë¦¬ëœ ê³µê°„ì´ ì–¼ë§ˆë‚˜ í¸ë¦¬í•œì§€ í•¨ê»˜ ì´ì•¼ê¸°í•´ë´…ë‹ˆë‹¤.\n",
            "\n",
            "ğŸ“ ë†€ì´ë¡œ ì–»ì„ ìˆ˜ ìˆëŠ” êµí›ˆ:\n",
            "ì´ ë†€ì´ëŠ” ì•„ì´ê°€ ëª¨ë°©ì„ í†µí•´ ì •ë¦¬ì •ëˆ ë°©ë²•ì„ ìì—°ìŠ¤ëŸ½ê²Œ ìµíˆê³ , ì†Œê·¼ìœ¡ ë°œë‹¬ê³¼ ì¸ì§€ ëŠ¥ë ¥, ì˜ì‚¬ì†Œí†µ ëŠ¥ë ¥ì„ í•¨ê»˜ í‚¤ìš¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ ë¶€ëª¨ì™€ì˜ ìƒí˜¸ì‘ìš©ì„ í†µí•´ ì •ì„œì  ì•ˆì •ê°ê³¼ ì„±ì·¨ê°ì„ ëŠë‚„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
            "\n",
            "ğŸ“ ì°¸ê³ í•œ ë†€ì´ ì‚¬ë¡€:\n",
            "ì¼ìƒìƒí™œì—ì„œ ëª¨ë°© ë†€ì´ ì´ë ‡ê²Œ í•´ì£¼ì„¸ìš”. ì–´ë–»ê²Œ í–‰ë™ì„ ëª¨ë°©í•˜ê²Œ í• ê¹Œìš”? ëª¨ë°© ëŠ¥ë ¥ í–¥ìƒì„ ìœ„í•´ ê°€ì •ì—ì„œ í•  ìˆ˜ ìˆëŠ” ë†€ì´ëŠ” ë¬´ì—‡ì¸ê°€ìš”? (ì‹œê°) ì‹œê°ì¥ì• ì˜ì•„ë¥¼ ìœ„í•œ ëª¨ë°© ì§€ë„ ë°©ë²• ì•Œì•„ë³´ê¸°. (ì§€ì²´) ì§€ì²´ì¥ì• ì˜ì•„ë¥¼ ìœ„í•œ ëª¨ë°© ì§€ë„ ë°©ë²• ì•Œì•„ë³´ê¸°.\n",
            "ğŸ“š ì¶œì²˜: [êµìœ¡ë¶€, ê²½ìƒë¶ë„êµìœ¡ì²­] ì¥ì•  ì˜ì•„ êµìœ¡ì§€ì› ìš´ì˜ê°€ì´ë“œ ì‚¬ë¡€ì§‘(2024), 88ìª½\n"
          ]
        }
      ],
      "source": [
        "def extract_json_from_response(text: str) -> dict:\n",
        "            try:\n",
        "                # í…ìŠ¤íŠ¸ì—ì„œ JSON ê°ì²´ ì¶”ì¶œ\n",
        "                json_string = re.search(r\"\\{[\\s\\S]+\\}\", text, re.DOTALL).group()\n",
        "                return json.loads(json_string)\n",
        "            except Exception as e:\n",
        "                print(f\"âŒ JSON ì¶”ì¶œ ì‹¤íŒ¨: {e}\")\n",
        "                return {}\n",
        "\n",
        "# ë²ˆí˜¸ê°€ ë¶™ì€ í•­ëª©ì„ ê°ì§€í•˜ê³  ë¶„ë¦¬í•˜ëŠ” í•¨ìˆ˜\n",
        "def split_by_emoji_numbers(answer: str) -> list:\n",
        "    pattern = r'(1ï¸âƒ£|2ï¸âƒ£|3ï¸âƒ£|4ï¸âƒ£|5ï¸âƒ£|6ï¸âƒ£|7ï¸âƒ£|8ï¸âƒ£|9ï¸âƒ£|ğŸ”Ÿ)'\n",
        "    parts = re.split(pattern, answer)\n",
        "    combined = []\n",
        "    i = 1\n",
        "    while i < len(parts):\n",
        "        emoji = parts[i]\n",
        "        text = parts[i + 1] if i + 1 < len(parts) else ''\n",
        "        combined.append(f\"{emoji} {text.strip()}\")\n",
        "        i += 2\n",
        "    return combined\n",
        "\n",
        "# state['answer']ì—ì„œ JSON ë°ì´í„°ë¥¼ ì¶”ì¶œ\n",
        "parsed = extract_json_from_response(state['answer'])\n",
        "\n",
        "# `intro` í…ìŠ¤íŠ¸ ì¶œë ¥\n",
        "intro = parsed.get(\"intro\", \"No introduction provided.\")\n",
        "print(f'ğŸ“Œ {intro}\\n')\n",
        "print(\"ğŸ™‹â€â™€ï¸ ë” ì•Œê³  ì‹¶ì–´ìš”!\")\n",
        "\n",
        "# QnA ì •ë³´ ì¶œë ¥\n",
        "play_recommendation = parsed.get(\"play_recommendation\", {})\n",
        "name = play_recommendation.get(\"name\", \"No play recommendation found.\")\n",
        "steps = play_recommendation.get(\"steps\", \"No steps provided.\")\n",
        "lessons = play_recommendation.get(\"lessons\", \"No lessons provided.\")\n",
        "original_content = play_recommendation.get(\"original_content\", \"No original content provided.\")\n",
        "\n",
        "# í¬ë§·íŒ…ëœ ê²°ê³¼ ì¶œë ¥\n",
        "print(f\"ğŸ® ë†€ì´ ì¶”ì²œ: {name}\")\n",
        "print()\n",
        "print(f\"ğŸ“œ ë†€ì´ ê³¼ì •:\\n{steps}\")\n",
        "print()\n",
        "print(f\"ğŸ“ ë†€ì´ë¡œ ì–»ì„ ìˆ˜ ìˆëŠ” êµí›ˆ:\\n{lessons}\")\n",
        "print()\n",
        "if original_content:\n",
        "    print(f\"ğŸ“ ì°¸ê³ í•œ ë†€ì´ ì‚¬ë¡€:\\n{original_content}\")\n",
        "\n",
        "# ì¶œì²˜ ì¶œë ¥\n",
        "if source:\n",
        "    source = parsed.get(\"source\", \"No source provided.\")\n",
        "    print(f\"ğŸ“š ì¶œì²˜: {source}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5f5ec9d-f286-4c86-ba73-b5667dafada5",
      "metadata": {
        "id": "e5f5ec9d-f286-4c86-ba73-b5667dafada5"
      },
      "outputs": [],
      "source": [
        "# summarize_model = init_chat_model(\n",
        "#     model='openai:gpt-4.1-mini',\n",
        "#     temperature=0\n",
        "# )\n",
        "# summarizer = YouTubeSummaryNode(summarize_model)\n",
        "# state = summarizer({'video_url': 'https://www.youtube.com/watch?v=V2HcJsRsdmQ'})\n",
        "# print(state)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f211debc-0d98-4282-aec9-c75823b676fc",
      "metadata": {
        "id": "f211debc-0d98-4282-aec9-c75823b676fc"
      },
      "source": [
        "### VideoStartRouterNode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62200c78-90eb-4ede-9292-6ffa9eafdd10",
      "metadata": {
        "id": "62200c78-90eb-4ede-9292-6ffa9eafdd10"
      },
      "outputs": [],
      "source": [
        "from langgraph.graph import START, END\n",
        "from typing import Literal, Dict, Optional\n",
        "from langchain_core.runnables import Runnable, RunnableConfig\n",
        "\n",
        "class VideoStartRouterNode(Runnable):\n",
        "    @staticmethod\n",
        "    def route(state: State) -> Literal['parenting_skill', 'play_reco', 'video recommendation']:\n",
        "        option = state.get('option')\n",
        "        # print(f\"ìœ íŠœë¸Œ ë…¸ë“œ ë¼ìš°íŒ… ì˜µì…˜ í™•ì¸: {state.get('option')}\") # ë””ë²„ê¹…ì„ ìœ„í•œ ì¶œë ¥\n",
        "\n",
        "        if option=='parenting_skill':\n",
        "            return 'parenting_skill'\n",
        "        elif option=='video rocommendation':\n",
        "            return 'video rocommendation'\n",
        "        else:\n",
        "            return 'play_reco'\n",
        "\n",
        "    @staticmethod\n",
        "    def route(state: Dict) -> Literal['Video Summarizer', 'Retriever_ParentingSkill', 'Retriever_PlayReco']:\n",
        "        if state.get('new_video'):\n",
        "            return 'Video Summarizer'\n",
        "        elif state.get('option') == 'parenting_skill':\n",
        "            return 'Retriever_ParentingSkill'\n",
        "        else:\n",
        "            return 'Retriever_PlayReco'\n",
        "\n",
        "    def invoke(self, input: Dict, config: Optional[RunnableConfig] = None) -> Dict:\n",
        "        \"\"\"\n",
        "        Implements the abstract 'invoke' method for Runnable.\n",
        "        For a router node, it simply passes the state through as its \"output\".\n",
        "        The actual routing logic is handled by the `route` static method via conditional_edges.\n",
        "        \"\"\"\n",
        "        # A router node typically doesn't modify the state itself, it just helps decide the next step.\n",
        "        # It should return the input state, or a modified state if it had some processing role.\n",
        "        # In this case, it just passes the state through.\n",
        "        print(f\"VideoStartRouterNode Invoke: Passing state through: {input}\")\n",
        "        return input # Return the state as is. This is crucial for LangGraph's state management.\n",
        "\n",
        "\n",
        "    def __call__(self, state: Dict, config: Optional[RunnableConfig] = None) -> Dict:\n",
        "    # ì´ ë…¸ë“œëŠ” ë¼ìš°íŒ… ë¡œì§ë§Œ ìˆ˜í–‰í•˜ë©°, ìƒíƒœë¥¼ ì§ì ‘ ë³€ê²½í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n",
        "    # LangGraphì˜ conditional_edgesì—ì„œ pathë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤.\n",
        "        return state"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4611e4cb-d4d5-4f8b-913f-18d0a8108436",
      "metadata": {
        "id": "4611e4cb-d4d5-4f8b-913f-18d0a8108436"
      },
      "source": [
        "### 2. YouTubeSummaryNode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "876cd82a-5de6-4d88-8340-68700a7f0f15",
      "metadata": {
        "id": "876cd82a-5de6-4d88-8340-68700a7f0f15"
      },
      "outputs": [],
      "source": [
        "'''ìë§‰ ì§ì ‘ ë‹¤ìš´ ë°›ì•„ì„œ ìš”ì•½ í•˜ëŠ” ë²„ì „'''\n",
        "\n",
        "'''\n",
        "import os\n",
        "import subprocess\n",
        "import tiktoken\n",
        "from typing import Dict, Union\n",
        "from langchain_core.runnables import Runnable\n",
        "\n",
        "class YouTubeSummaryNode(Runnable):\n",
        "    def __init__(self, model, language='en', max_tokens=3000, delete_after=True):\n",
        "        self.model = model\n",
        "        self.language = language\n",
        "        self.max_tokens = max_tokens\n",
        "        self.delete_after = delete_after\n",
        "        self.tokenizer = tiktoken.encoding_for_model(\"gpt-4\")\n",
        "\n",
        "    def download_subtitles(self, video_url: str):\n",
        "        command = [\n",
        "            \"yt-dlp\",\n",
        "            \"--write-auto-sub\",\n",
        "            f\"--sub-lang={self.language}\",\n",
        "            \"--skip-download\",\n",
        "            \"-o\", f\"video_transcript.%(ext)s\",\n",
        "            video_url\n",
        "        ]\n",
        "        # subprocess.run(command, check=True)\n",
        "        try:\n",
        "            subprocess.run(command, check=True, capture_output=True, text=True)\n",
        "            # ìº¡ì²˜ëœ ì¶œë ¥ì„ ì—¬ê¸°ì— ì €ì¥í•˜ì§€ë§Œ, ì‚¬ìš©í•˜ì§€ ì•Šìœ¼ë©´ í™”ë©´ì— í‘œì‹œë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n",
        "            # result.stdout, result.stderr\n",
        "        except subprocess.CalledProcessError as e:\n",
        "            # ì—ëŸ¬ê°€ ë°œìƒí–ˆì„ ë•Œë§Œ ì—ëŸ¬ ë©”ì‹œì§€ë¥¼ ë³¼ ìˆ˜ ìˆë„ë¡ ì²˜ë¦¬\n",
        "            print(f\"yt-dlp ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
        "            print(f\"í‘œì¤€ ì¶œë ¥: {e.stdout}\")\n",
        "            print(f\"í‘œì¤€ ì—ëŸ¬: {e.stderr}\")\n",
        "            raise # ì˜¤ë¥˜ë¥¼ ë‹¤ì‹œ ë°œìƒì‹œì¼œ ìƒìœ„ í˜¸ì¶œìì—ê²Œ ì•Œë¦½ë‹ˆë‹¤.\n",
        "        except Exception as e:\n",
        "            print(f\"ìë§‰ ë‹¤ìš´ë¡œë“œ ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
        "            raise\n",
        "\n",
        "    def parse_vtt(self, filepath: str) -> str:\n",
        "        with open(filepath, 'r', encoding='utf-8') as f:\n",
        "            lines = f.readlines()\n",
        "        return ' '.join([\n",
        "            line.strip() for line in lines\n",
        "            if line.strip() and '-->' not in line and not line.strip().isdigit()\n",
        "        ])\n",
        "\n",
        "    def split_by_token_limit(self, text: str) -> list:\n",
        "        words = text.split()\n",
        "        chunks, current_chunk = [], []\n",
        "        for word in words:\n",
        "            current_chunk.append(word)\n",
        "            if len(self.tokenizer.encode(\" \".join(current_chunk))) > self.max_tokens:\n",
        "                chunks.append(\" \".join(current_chunk[:-1]))\n",
        "                current_chunk = [word]\n",
        "        if current_chunk:\n",
        "            chunks.append(\" \".join(current_chunk))\n",
        "        return chunks\n",
        "\n",
        "    def summarize_chunks(self, chunks: list) -> list:\n",
        "        summaries = []\n",
        "        for i, chunk in enumerate(chunks):\n",
        "            print(f\"ğŸ§© ì˜ìƒ ìš”ì•½ ì¤‘: {i+1}/{len(chunks)}\")\n",
        "            response = self.model.invoke(f\"Summarize this transcript chunk:\\n\\n{chunk}\")\n",
        "            summaries.append(response.content)\n",
        "        return summaries\n",
        "\n",
        "    def create_final_summary(self, summaries: list) -> str:\n",
        "        instructions = \"\"\"\n",
        "1. Combine and refine the following partial summaries into a single coherent summary.\n",
        "2. Make sure that the summary is 3-4 sentences.\n",
        "3. The response should be written in **Korean**.\n",
        "4. The summary should reflect that the video is designed for children with developmental disabilities and may be watched by them.\n",
        "5. Please use gentle, clear, and supportive language that is easy to understand for parents or educators working with such children.\n",
        "\"\"\"\n",
        "        prompt = instructions + \"\\n\\n\" + \"\\n\\n\".join(summaries)\n",
        "        final_response = self.model.invoke(prompt)\n",
        "        return final_response.content\n",
        "\n",
        "    def run(self, state: Dict) -> Dict:\n",
        "        video_url = state.get(\"video_url\")\n",
        "        if not video_url:\n",
        "            raise ValueError(\"State must contain 'video_url'\")\n",
        "\n",
        "        self.download_subtitles(video_url)\n",
        "        vtt_file = f\"video_transcript.{self.language}.vtt\"\n",
        "        if not os.path.exists(vtt_file):\n",
        "            raise FileNotFoundError(f\"ìë§‰ íŒŒì¼ ì—†ìŒ: {vtt_file}\")\n",
        "\n",
        "        transcript = self.parse_vtt(vtt_file)\n",
        "        chunks = self.split_by_token_limit(transcript)\n",
        "        summaries = self.summarize_chunks(chunks)\n",
        "        final_summary = self.create_final_summary(summaries)\n",
        "\n",
        "        if self.delete_after:\n",
        "            try:\n",
        "                os.remove(vtt_file)\n",
        "                # print(f\"ğŸ—‘ï¸ ìë§‰ íŒŒì¼ ì‚­ì œ ì™„ë£Œ: {vtt_file}\")\n",
        "            except Exception as e:\n",
        "                print(f\"âš ï¸ ì‚­ì œ ì‹¤íŒ¨: {e}\")\n",
        "\n",
        "        return state | {\n",
        "            \"video_transcript\": transcript,\n",
        "            \"video_summary\": final_summary,\n",
        "            \"answer\": final_summary  # ê¸°ë³¸ answer ì„¸íŒ…\n",
        "        }\n",
        "    def __call__(self, state: Dict) -> Dict:\n",
        "        return self.run(state)\n",
        "\n",
        "    def invoke(self, input: Union[Dict, str], config: Optional[RunnableConfig] = None) -> Dict:\n",
        "        # invokeëŠ” ì´ˆê¸° ìƒíƒœë¥¼ ì„¤ì •í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.\n",
        "        if isinstance(input, dict):\n",
        "            # run ë©”ì„œë“œê°€ ì „ì²´ ìƒíƒœë¥¼ ì²˜ë¦¬í•˜ë„ë¡ í•©ë‹ˆë‹¤.\n",
        "            # print(input)\n",
        "            return self.run(input)\n",
        "        else:\n",
        "            raise ValueError(\"Input to invoke must be a dictionary.\")\n",
        "\n",
        "     # --- conditional edge ----------------------------------------------------\n",
        "    @staticmethod\n",
        "    def route(state: State) -> Literal['parenting_skill','play_reco']:\n",
        "        option = state.get('option')\n",
        "        # print(f\"ìœ íŠœë¸Œ ë…¸ë“œ ë¼ìš°íŒ… ì˜µì…˜ í™•ì¸: {state.get('option')}\") # ë””ë²„ê¹…ì„ ìœ„í•œ ì¶œë ¥\n",
        "\n",
        "        if option=='parenting_skill':\n",
        "            return 'parenting_skill'\n",
        "        elif option=='video recommendation':\n",
        "            return 'video recommendation'\n",
        "        else:\n",
        "            return 'play_reco' '''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d08d9866",
      "metadata": {},
      "outputs": [],
      "source": [
        "# youtube_transcript_api ì‚¬ìš© ë²„ì „\n",
        "import tiktoken\n",
        "from typing import Dict, Union, Optional, Literal\n",
        "from langchain_core.runnables import Runnable\n",
        "from youtube_transcript_api import YouTubeTranscriptApi, TranscriptsDisabled, NoTranscriptFound, VideoUnavailable, YouTubeRequestFailed\n",
        "\n",
        "class YouTubeSummaryNode(Runnable):\n",
        "    def __init__(self, model, language='ko', max_tokens=3000):\n",
        "        self.model = model\n",
        "        self.language = language\n",
        "        self.max_tokens = max_tokens\n",
        "        self.tokenizer = tiktoken.encoding_for_model(\"gpt-4\")\n",
        "\n",
        "    def get_youtube_transcript(self, video_url, languages=['ko', 'en']):\n",
        "        try:\n",
        "            if \"v=\" in video_url:\n",
        "                video_id = video_url.split(\"v=\")[-1].split(\"&\")[0]\n",
        "            else:\n",
        "                video_id = video_url.strip().split(\"/\")[-1]\n",
        "            transcript = YouTubeTranscriptApi().get_transcript(\n",
        "                video_id,\n",
        "                languages=languages\n",
        "            )\n",
        "            return \" \".join([snippet['text'] for snippet in transcript])\n",
        "        except (TranscriptsDisabled, NoTranscriptFound, VideoUnavailable, YouTubeRequestFailed):\n",
        "            print(\"[âŒ] ìë§‰ ì—†ìŒ ë˜ëŠ” ì ‘ê·¼ ë¶ˆê°€\")\n",
        "            return None\n",
        "        except Exception as e:\n",
        "            print(f\"[âŒ] ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜: {e}\")\n",
        "            return None\n",
        "\n",
        "    def split_by_token_limit(self, text: str) -> list:\n",
        "        words = text.split()\n",
        "        chunks, current_chunk = [], []\n",
        "        for word in words:\n",
        "            current_chunk.append(word)\n",
        "            if len(self.tokenizer.encode(\" \".join(current_chunk))) > self.max_tokens:\n",
        "                chunks.append(\" \".join(current_chunk[:-1]))\n",
        "                current_chunk = [word]\n",
        "        if current_chunk:\n",
        "            chunks.append(\" \".join(current_chunk))\n",
        "        return chunks\n",
        "\n",
        "    def summarize_chunks(self, chunks: list) -> list:\n",
        "        summaries = []\n",
        "        for i, chunk in enumerate(chunks):\n",
        "            print(f\"ğŸ§© ì˜ìƒ ìš”ì•½ ì¤‘: {i+1}/{len(chunks)}\")\n",
        "            response = self.model.invoke(f\"Summarize this transcript chunk:\\n\\n{chunk}\")\n",
        "            summaries.append(response.content)\n",
        "        return summaries\n",
        "\n",
        "    def create_final_summary(self, summaries: list) -> str:\n",
        "        instructions = \"\"\"\n",
        "1. Combine and refine the following partial summaries into a single coherent summary.\n",
        "2. Make sure that the summary is 3-4 sentences.\n",
        "3. The response should be written in **Korean**.\n",
        "4. The summary should reflect that the video is designed for children with developmental disabilities and may be watched by them.\n",
        "5. Please use gentle, clear, and supportive language that is easy to understand for parents or educators working with such children.\n",
        "\"\"\"\n",
        "        prompt = instructions + \"\\n\\n\" + \"\\n\\n\".join(summaries)\n",
        "        response = self.model.invoke(prompt)\n",
        "        prompt_tokens += count_tokens(prompt)\n",
        "        completion_tokens += count_tokens(response)\n",
        "        return response.content\n",
        "\n",
        "    def run(self, state: Dict) -> Dict:\n",
        "        video_url = state.get(\"video_url\")\n",
        "        if not video_url:\n",
        "            raise ValueError(\"State must contain 'video_url'\")\n",
        "\n",
        "        transcript = self.get_youtube_transcript(video_url, languages=[self.language, \"en\"])\n",
        "        if not transcript:\n",
        "            raise FileNotFoundError(f\"ìë§‰ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŒ: {video_url}\")\n",
        "\n",
        "        chunks = self.split_by_token_limit(transcript)\n",
        "        summaries = self.summarize_chunks(chunks)\n",
        "        final_summary = self.create_final_summary(summaries)\n",
        "\n",
        "        return state | {\n",
        "            \"video_transcript\": transcript,\n",
        "            \"video_summary\": final_summary,\n",
        "            \"answer\": final_summary\n",
        "        }\n",
        "        \n",
        "    def __call__(self, state: Dict) -> Dict:\n",
        "        return self.run(state)\n",
        "\n",
        "    def invoke(self, input: Union[Dict, str], config: Optional[dict] = None) -> Dict:\n",
        "        if isinstance(input, dict):\n",
        "            return self.run(input)\n",
        "        else:\n",
        "            raise ValueError(\"Input to invoke must be a dictionary.\")\n",
        "\n",
        "    @staticmethod\n",
        "    def route(state: Dict) -> Literal['parenting_skill','play_reco']:\n",
        "        option = state.get('option')\n",
        "        if option=='parenting_skill':\n",
        "            return 'parenting_skill'\n",
        "        elif option=='video recommendation':\n",
        "            return 'video recommendation'\n",
        "        else:\n",
        "            return 'play_reco'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "gFkD32c7F-Gu",
      "metadata": {
        "id": "gFkD32c7F-Gu"
      },
      "source": [
        "### VideoRecommendationNode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07804c91",
      "metadata": {},
      "outputs": [],
      "source": [
        "import operator\n",
        "import re\n",
        "from langchain_core.runnables import Runnable\n",
        "from langchain_community.utilities import SQLDatabase\n",
        "from langchain.chat_models import init_chat_model\n",
        "\n",
        "class VideoRecommendationNode:\n",
        "    \"\"\"\n",
        "    ì˜ìƒ ì¶”ì²œ íŒŒì´í”„ë¼ì¸ì˜ ë©”ì¸ í´ë˜ìŠ¤. LLMê³¼ DBë¥¼ ì—°ê²°í•´ ì˜ìƒ ì¶”ì²œ ê²°ê³¼ë¥¼ ìƒì„±í•˜ê³  í•„í„°ë§í•œë‹¤.\n",
        "    \"\"\"\n",
        "    def __init__(self, runnable: Runnable, chunk_size: int = 50) -> None:\n",
        "        self.__runnable = runnable\n",
        "        self.__chunk_size = chunk_size\n",
        "\n",
        "    def _build_prompt_header(self, user_input: str, header_note: str) -> List[str]:\n",
        "        \"\"\"\n",
        "        LLM í”„ë¡¬í”„íŠ¸ì˜ ê³µí†µ í—¤ë”(ì‚¬ìš©ì ê´€ì‹¬ì‚¬ + ì•ˆë‚´ë¬¸) ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜\n",
        "        user_input: ì¶”ì²œ ê¸°ì¤€(ì˜ˆ: ì˜ìƒ ìš”ì•½ë¬¸ ë“±)\n",
        "        header_note: í”„ë¡¬í”„íŠ¸ ì¤‘ê°„ ì•ˆë‚´ ë¬¸êµ¬\n",
        "        \"\"\"\n",
        "        return [\n",
        "            \"Below is a description of the user's interest:\",\n",
        "            user_input,\n",
        "            f\"\\n{header_note}\"\n",
        "        ]\n",
        "\n",
        "    def __call__(self, state: State) -> State:\n",
        "        \"\"\"\n",
        "        ì…ë ¥ ìš”ì•½ì„ ë°›ì•„ ì˜ìƒ ì¶”ì²œ í”„ë¡¬í”„íŠ¸ë¥¼ ë§Œë“¤ê³  LLMìœ¼ë¡œ ê²°ê³¼ë¥¼ ì¶”ì²œë°›ì•„ ë°˜í™˜\n",
        "        (ì¶”ì²œ í•„í„°ë§ê¹Œì§€ í•œ ë²ˆì— ìˆ˜í–‰)\n",
        "        state: State ì…ë ¥\n",
        "        return: ì¶”ì²œ ê²°ê³¼ í¬í•¨ëœ VideoRecommendState\n",
        "        \"\"\"\n",
        "        node_name = '--- Video Recommendation Node'\n",
        "        print(f'\\n{node_name} {'-' * (79 - len('\\n') - len(node_name) - 1)}')  \n",
        "\n",
        "        user_input = state.get(\"video_summary\") or \"\"\n",
        "        if not user_input:\n",
        "            print(\"ì…ë ¥ê°’ ì—†ìŒ (summary í•„ë“œ í•„ìš”)\")\n",
        "            return state\n",
        "\n",
        "        query = \"\"\"\n",
        "            SELECT ì œëª©, í‚¤ì›Œë“œ, ìš”ì•½, ë§í¬\n",
        "            FROM Damoavideo;\n",
        "        \"\"\"\n",
        "        db = SQLDatabase.from_uri(\"sqlite:///data/moav.db\")\n",
        "        rows = db._execute(query)\n",
        "        if not isinstance(rows, list):\n",
        "            print(\"ë°ì´í„°ë² ì´ìŠ¤ ì‘ë‹µ ì˜¤ë¥˜\")\n",
        "            return state\n",
        "\n",
        "        chunks = [rows[i:i+self.__chunk_size] for i in range(0, len(rows), self.__chunk_size)]\n",
        "        row_map = {str(row.get('ì œëª©', '')).strip(): row for row in rows}\n",
        "        all_recommended = {}\n",
        "\n",
        "        for chunk in chunks:\n",
        "            prompt_lines = self._build_prompt_header(user_input, \"Here is a list of videos:\")\n",
        "            for row in chunk:\n",
        "                prompt_lines.append(\n",
        "                    f\"Title: {row['ì œëª©']}\\nKeywords: {row['í‚¤ì›Œë“œ']}\\nSummary: {row['ìš”ì•½']}\"\n",
        "                )\n",
        "            prompt_lines.append(\n",
        "                \"\"\"\n",
        "                Please recommend up to 3 videos that are most closely related to the user's input.\n",
        "                Do not recommend videos that are not clearly relevant.\n",
        "                Output in the same language as the user's input.\n",
        "                Only include one video per line in the following format:\n",
        "                Title: [video title]\n",
        "                Link: [video link]\n",
        "                Reason: [a short reason why this video is relevant to the user's input]\n",
        "                Separate each video with a blank line.\n",
        "                \"\"\"\n",
        "            )\n",
        "            prompt = \"\\n\\n\".join(prompt_lines)\n",
        "            \n",
        "            try:\n",
        "                response = self.__runnable.invoke(prompt)\n",
        "            except Exception as e:\n",
        "                print(f\"LLM ì‘ë‹µ ì‹¤íŒ¨: {e}\")\n",
        "                continue\n",
        "            \n",
        "            if not hasattr(response, \"content\") or not isinstance(response.content, str):\n",
        "                print(\"LLM ì‘ë‹µ í˜•ì‹ ì˜¤ë¥˜: content ì†ì„±ì´ ì—†ê±°ë‚˜ ë¬¸ìì—´ì´ ì•„ë‹˜\")\n",
        "                continue\n",
        "            # ì…ë ¥ ì¶œë ¥ í† í° ìˆ˜ ëˆ„ì ì¹˜ ê³„ì‚°\n",
        "            prompt_tokens += count_tokens(prompt)\n",
        "            completion_tokens += count_tokens(response)\n",
        "\n",
        "            blocks = response.content.strip().split('\\n\\n')\n",
        "            for block in blocks:\n",
        "                title_match = re.search(r\"^Title:\\s*(.+)$\", block, re.MULTILINE)\n",
        "                link_match = re.search(r\"^Link:\\s*(.+)$\", block, re.MULTILINE)\n",
        "                reason_match = re.search(r\"^Reason:\\s*(.+)$\", block, re.MULTILINE)\n",
        "                if title_match:\n",
        "                    title = title_match.group(1).strip()\n",
        "                    link = link_match.group(1).strip() if link_match else \"\"\n",
        "                    reason = reason_match.group(1).strip() if reason_match else \"\"\n",
        "                    all_recommended[title] = {\"title\": title, \"link\": link, \"reason\": reason}\n",
        "\n",
        "        recommendations = []\n",
        "        for title, data in all_recommended.items():\n",
        "            row = row_map.get(title)\n",
        "            if row:\n",
        "                recommendations.append({\n",
        "                    \"title\": title,\n",
        "                    \"link\": row['ë§í¬'],\n",
        "                    \"reason\": data['reason']\n",
        "                })\n",
        "\n",
        "        if recommendations:\n",
        "            review_lines = self._build_prompt_header(user_input, \"Here is a list of recommended videos:\")\n",
        "            for rec in recommendations:\n",
        "                review_lines.append(f\"Title: {rec['title']}\\nLink: {rec['link']}\\nReason: {rec['reason']}\")\n",
        "            review_lines.append(\n",
        "                \"\"\"\n",
        "                From the recommended list above, filter and return only the videos that are most relevant to the user's input.\n",
        "                Exclude any videos that are not clearly relevant.\n",
        "                Output in the same language as the user's input.\n",
        "                Only include one video per line in the following format:\n",
        "                Title: [video title]\n",
        "                Link: [video link]\n",
        "                Reason: [a short reason why this video is relevant to the user's input]\n",
        "                Separate each video with a blank line.\n",
        "                \"\"\"\n",
        "            )\n",
        "            review_prompt = \"\\n\\n\".join(review_lines)\n",
        "            try:\n",
        "                review_response = self.__runnable.invoke(review_prompt)\n",
        "            except Exception as e:\n",
        "                print(f\"LLM í•„í„°ë§ ì‹¤íŒ¨: {e}\")\n",
        "                return {\"recommendation\": recommendations, **state}\n",
        "\n",
        "            if not hasattr(review_response, \"content\") or not isinstance(review_response.content, str):\n",
        "                print(\"LLM í•„í„°ë§ ì‘ë‹µ í˜•ì‹ ì˜¤ë¥˜\")\n",
        "                return {\"recommendation\": recommendations, **state}\n",
        "            \n",
        "            # ì…ë ¥ ì¶œë ¥ í† í° ìˆ˜ ëˆ„ì ì¹˜ ê³„ì‚°\n",
        "            prompt_tokens += count_tokens(review_prompt)\n",
        "            completion_tokens += count_tokens(review_response)\n",
        "\n",
        "            filtered_titles = set()\n",
        "            blocks = review_response.content.strip().split('\\n\\n')\n",
        "            for block in blocks:\n",
        "                title_match = re.search(r\"^Title:\\s*(.+)$\", block, re.MULTILINE)\n",
        "                if title_match:\n",
        "                    title = title_match.group(1).strip()\n",
        "                    filtered_titles.add(title)\n",
        "\n",
        "            recommendations = [rec for rec in recommendations if rec['title'] in filtered_titles]\n",
        "\n",
        "        return {\"recommendation\": recommendations}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "baceb0f0-cae6-459c-a6d6-80021c9ad5e4",
      "metadata": {
        "id": "baceb0f0-cae6-459c-a6d6-80021c9ad5e4"
      },
      "source": [
        "### 3. DocumentReviewNode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81fca2ca-f426-41af-99ce-b9345086dc57",
      "metadata": {
        "id": "81fca2ca-f426-41af-99ce-b9345086dc57"
      },
      "outputs": [],
      "source": [
        "# ì¶”ì¶œí•œ ë¬¸ì„œ ì‹¬ì‚¬ ë…¸ë“œ í´ë˜ìŠ¤ ì •ì˜\n",
        "from langchain_core.runnables import Runnable, RunnableConfig\n",
        "from langchain import hub\n",
        "from typing import Optional, Literal\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "class DocumentReviewNode:\n",
        "    def __init__(self, runnable: Runnable) -> None:\n",
        "        prompt = ChatPromptTemplate.from_template(\"\"\"\n",
        "        Below is a video summary and a document.\n",
        "        If the document is relevant to the topic of the video summary, respond with 'relevant'.\n",
        "        If it is not related, respond with 'irrelevant' only.\n",
        "\n",
        "        [Video Summary]\n",
        "        {video_summary}\n",
        "\n",
        "        [Document]\n",
        "        {document}\n",
        "\n",
        "        Response:\n",
        "        \"\"\")\n",
        "        self.__runnable = (\n",
        "            prompt\n",
        "            | runnable.with_structured_output(GradeDocument)  # LLM ì¶œë ¥ê°’ì„ GradeDocumentë¡œ ìë™ íŒŒì‹±\n",
        "        )\n",
        "    def __call__(self, state: State, config: Optional[RunnableConfig] = None) -> State:\n",
        "        node_name = '--- Document Review node'\n",
        "        # print(f'\\n{node_name} {'-' * (79 - len('\\n') - len(node_name) - 1)}')\n",
        "\n",
        "        # í˜„ì¬ ê·¸ë˜í”„ ìƒíƒœì—ì„œ ë¬¸ì„œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¨ë‹¤.\n",
        "        documents = state.get('documents', [])\n",
        "                # --- ê° ë¬¸ì„œë¥¼ ì±„ì í•˜ê³  ê´€ë ¨ ë¬¸ì„œë§Œ í•„í„°ë§í•œë‹¤.\n",
        "        relevant_docs = []\n",
        "        for doc in documents:\n",
        "            score = self.__runnable.invoke(\n",
        "                input={'video_summary': state['video_summary'], 'document': doc.page_content},\n",
        "                config=config  # (note) for a configurable model\n",
        "            )\n",
        "            \n",
        "            # ì…ë ¥ ì¶œë ¥ í† í° ìˆ˜ ëˆ„ì ì¹˜ ê³„ì‚°\n",
        "            prompt_filled = f\"\"\"\n",
        "            Below is a video summary and a document.\n",
        "            If the document is relevant to the topic of the video summary, respond with 'relevant'.\n",
        "            If it is not related, respond with 'irrelevant' only.\n",
        "\n",
        "            [Video Summary]\n",
        "            {state['video_summary']}\n",
        "\n",
        "            [Document]\n",
        "            {doc.page_content}\n",
        "\n",
        "            Response:\n",
        "            \"\"\"\n",
        "            prompt_tokens += count_tokens(prompt_filled)\n",
        "            completion_tokens += count_tokens(score)\n",
        "\n",
        "            grade = score.relevance\n",
        "            if grade == 'relevant':  # ë¬¸ì„œê°€ ê´€ë ¨ì„±ì´ ìˆìœ¼ë©´\n",
        "                # print(f'%> Evaluating: DOCUMENT RELEVANT')\n",
        "                relevant_docs.append(doc) # ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€í•œë‹¤.\n",
        "            else:                    # ë¬¸ì„œê°€ ê´€ë ¨ì„±ì´ ì—†ìœ¼ë©´\n",
        "                # print(f'%> Evaluating: DOCUMENT NOT RELEVANT')\n",
        "                continue             # ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€í•˜ì§€ ì•ŠëŠ”ë‹¤.\n",
        "        print(f\"Relevant documents: {len(relevant_docs)}\")  # ê´€ë ¨ ë¬¸ì„œ ê°œìˆ˜ í™•ì¸\n",
        "\n",
        "        return state | {'documents': relevant_docs}\n",
        "\n",
        "     # --- conditional edge ----------------------------------------------------\n",
        "    @staticmethod\n",
        "    def route(state: State) -> Literal['parenting_skill','play_reco']:\n",
        "        option = state.get('option')\n",
        "        # print(f\"review node ë¼ìš°íŒ… ì˜µì…˜ í™•ì¸: {state.get('option')}\") # ë””ë²„ê¹…ì„ ìœ„í•œ ì¶œë ¥\n",
        "\n",
        "        if option=='parenting_skill':\n",
        "            return 'parenting_skill'\n",
        "        else:\n",
        "            return 'play_reco'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd2c8c9f-1b1d-45f6-a4df-367a8c7d6c6f",
      "metadata": {
        "id": "dd2c8c9f-1b1d-45f6-a4df-367a8c7d6c6f"
      },
      "source": [
        "### 4. AnswerGenerationNode_PlayReco"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e36724a0-e104-4b14-8f60-26507edd24aa",
      "metadata": {
        "id": "e36724a0-e104-4b14-8f60-26507edd24aa"
      },
      "outputs": [],
      "source": [
        "from langchain_core.runnables import Runnable, RunnableConfig\n",
        "from typing import Optional\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "class AnswerGenerationNode_PlayReco:\n",
        "    def __init__(self, runnable: Runnable) -> None:\n",
        "        self.runnable = runnable # ë°›ì€ runnable ì €ì¥\n",
        "\n",
        "        # ì‹œìŠ¤í…œ í…œí”Œë¦¿ì€ ê³ ì •\n",
        "        self.system_template = \"\"\"\n",
        "You are a parenting expert with over 10 years of experience, specializing in supporting children with developmental disabilities.\n",
        "You provide clear, empathetic, and developmentally appropriate suggestions for parents and children.\n",
        "\"\"\"\n",
        "        # ì¸ê°„ í…œí”Œë¦¿ì˜ ê³ ì • ë¶€ë¶„ë§Œ ì •ì˜\n",
        "        self.base_human_template_start = \"\"\"\n",
        "You will be given a summary of a video, along with a reference document that includes examples of related play & education activities.\n",
        "\n",
        "Your task is as follows:\n",
        "\n",
        "1. **Suggest a play activity** that parents and children can do together, after watching the video.\n",
        "    - Use the video summary and play & education reference document as the foundation for your suggestion.\n",
        "    - Try to preserve the **main idea** and **vocabulary** used in the reference as much as possible.\n",
        "    - **Format** your response as a short paragraph or as a numbered list (e.g., 1ï¸âƒ£, \\n2ï¸âƒ£, \\n3ï¸âƒ£), especially when the play involves multiple steps or recommendations. Use numbering for **step-by-step** activities.\n",
        "    - **Include the original content from the reference document.\n",
        "\n",
        "    Your response should include the following:\n",
        "    1) **Name of the Play**: Provide a clear, short title for the play.\n",
        "    2) **Steps for Play**: Write the steps in detail, explaining how the activity should be done.\n",
        "    3) **Lessons from the Play**: Describe the educational or developmental value of the play.\n",
        "    4) **Original Content**: Provide the text or description from the original reference that inspired your recommendation.\n",
        "                                Make the original content into sentences.\n",
        "\n",
        "2. Write a **short introductory paragraph** that helps parents connect the video to the play you recommend.\n",
        "    - The introductory paragraph should link the content of the video with the play activity.\n",
        "    - Ensure that parents understand how the play relates to the video content, especially since the video is designed for children with developmental disabilities.\n",
        "    - This part will be the \"intro\" in output format.\n",
        "\n",
        "3. Your output **must be in Korean**, even though the instructions are written in English.\n",
        "\n",
        "4. **Format** your final output exactly in the JSON structure shown below. Ensure **correct formatting** and accuracy:\n",
        "    - The `source` value **must** be **exactly** as provided in the input. Do not rewrite or interpret it.\n",
        "\n",
        "[Video Summary]\n",
        "{video_summary}\n",
        "\n",
        "[Play Activity Reference]\n",
        "\"\"\"\n",
        "\n",
        "        self.base_human_template_end = \"\"\"\n",
        "[Output Format Example]\n",
        "```json\n",
        "{{\n",
        "  \"intro\": \"...\",\n",
        "  \"play_recommendation\": {{\n",
        "    \"name\": \"...\",\n",
        "    \"steps\": \"...\",\n",
        "    \"lessons\": \"...\",\n",
        "    \"original_content\": \"...\"\n",
        "  }},\n",
        "  \"source\": \"\"\n",
        "}}\n",
        "\n",
        "âš ï¸ Make sure to respond only in Korean, and follow the JSON format exactly.\n",
        "âš ï¸ All answers must be in Korean.\n",
        "\"\"\"\n",
        "\n",
        "    def __call__(self, state: State, config: Optional[RunnableConfig] = None) -> State:\n",
        "        node_name = '--- Answer Generation Agent node'\n",
        "        print(f'\\n{node_name} {'-' * (79 - len('\\n') - len(node_name) - 1)}')\n",
        "\n",
        "        rag_docs = state.get(\"documents\", [])\n",
        "        play_examples_for_prompt = \"\" # í”„ë¡¬í”„íŠ¸ì— ì¶”ê°€í•  ë¬¸ìì—´\n",
        "\n",
        "        # doc.metadata.get('source') ì˜¤ë¥˜ í•´ê²° ë° play_examples_for_prompt ë™ì  ìƒì„±\n",
        "        if rag_docs:\n",
        "            for i, doc in enumerate(rag_docs[:3], 1): # ìµœëŒ€ 3ê°œ ë¬¸ì„œë§Œ ì‚¬ìš©í•˜ë„ë¡ ì œí•œ\n",
        "                page = doc.metadata.get('page_label', '')\n",
        "                content = doc.page_content\n",
        "\n",
        "                raw_source = doc.metadata.get('source')\n",
        "                source = raw_source.replace('data/', '').replace('.pdf', '') if raw_source else \"ì•Œ ìˆ˜ ì—†ëŠ” ì¶œì²˜\"\n",
        "\n",
        "                final_source = f\"{source}, {page}ìª½\"\n",
        "\n",
        "                play_examples_for_prompt += f\"\"\"\n",
        "{i}.\n",
        "Play & Education Reference: {content}\n",
        "Source: {final_source}\n",
        "\"\"\"\n",
        "        else:\n",
        "            play_examples_for_prompt = \"\"\"\n",
        "No Reference found, so you should make play on your own, according to the information below.\n",
        "Prompt:\n",
        "\n",
        "You are an expert in developmental therapy and special education. Based on the following guidelines, generate practical suggestions for designing play activities for children with developmental disabilities. Please ensure your suggestions are specific, actionable, and tailored to the needs of these children.\n",
        "\n",
        "Guidelines for Creating Play Activities for Children with Developmental Disabilities:\n",
        "\n",
        "Prioritize the childâ€™s developmental level and interests.\n",
        "\n",
        "Recognize that children with developmental disabilities may have different developmental speeds, interests, and strengths compared to their peers.\n",
        "\n",
        "Observe what the child enjoys, repeats, or shows interest in, and incorporate these elements into play.\n",
        "\n",
        "Start with simple, structured play and gradually expand.\n",
        "\n",
        "Begin with basic functional play (rolling a ball, stacking blocks) and gradually move to constructive play (building with blocks), symbolic play (pretend play), and games with rules.\n",
        "\n",
        "Clearly explain the rules and help the child practice them through repetition.\n",
        "\n",
        "Use visual, tactile, and concrete materials.\n",
        "\n",
        "Utilize puzzles, blocks, picture cards, foam pieces, and other visual/tactile aids to increase engagement and understanding.\n",
        "\n",
        "For example, use social skills puzzles or stepping stone games that allow the child to physically interact and practice specific scenarios.\n",
        "\n",
        "Incorporate social skills and real-life situations into play.\n",
        "\n",
        "Design activities that help children practice real-life social behaviors, suchs as sitting in class, greeting friends, or waiting in line at a store.\n",
        "\n",
        "Use role play, skits, or stepping stone games to rehearse appropriate responses in specific situations.\n",
        "\n",
        "Provide frequent opportunities for success and positive feedback.\n",
        "\n",
        "Offer praise, stickers, or small rewards for achievements, no matter how small, to motivate the child.\n",
        "\n",
        "Adjust the difficulty and goals to match the childâ€™s level, focusing on building positive experiences.\n",
        "\n",
        "Emphasize repetition and predictability.\n",
        "\n",
        "Children with developmental disabilities often feel more comfortable with routines and predictable structures.\n",
        "\n",
        "Keep the sequence and rules of play consistent, and gradually introduce new elements as the child becomes more confident.\n",
        "\n",
        "Design activities for parent or peer participation.\n",
        "\n",
        "Create play activities that parents or peers can easily join, such as collaborative puzzles, role play, or simple games with rules.\n",
        "\n",
        "Encourage cooperative play and sharing of roles.\n",
        "\n",
        "Examples of Play Activities:\n",
        "\n",
        "Social skills puzzles: Each puzzle piece represents a social skill to practice as the puzzle is completed.\n",
        "\n",
        "Stepping stone games: Each step represents a real-life situation (e.g., waiting at the hospital) and the child practices the appropriate behavior.\n",
        "\n",
        "Block play: Stacking, color matching, or building shapes.\n",
        "\n",
        "Pretend play: Role-playing as family members, doctors, store clerks, etc., to naturally practice social interaction.\n",
        "\"\"\"\n",
        "\n",
        "        # ìµœì¢… human_template ì¡°í•©\n",
        "        human_template_full = self.base_human_template_start + play_examples_for_prompt + self.base_human_template_end\n",
        "\n",
        "        prompt = ChatPromptTemplate.from_messages([\n",
        "            (\"system\", self.system_template),\n",
        "            (\"human\", human_template_full)\n",
        "        ])\n",
        "\n",
        "        # runnableì„ __call__ ë‚´ì—ì„œ ì •ì˜ (ë™ì  í”„ë¡¬í”„íŒ…ì„ ìœ„í•´)\n",
        "        current_runnable = prompt | self.runnable | StrOutputParser()\n",
        "\n",
        "        video_summary = state.get(\"video_summary\", \"\") # ê¸°ë³¸ê°’ ì„¤ì •\n",
        "\n",
        "        generation = current_runnable.invoke(\n",
        "            {\n",
        "                'video_summary': video_summary # ë¹„ë””ì˜¤ ìš”ì•½ë§Œ ì „ë‹¬\n",
        "            },\n",
        "            config=config\n",
        "        )\n",
        "        \n",
        "        # ì…ë ¥ ì¶œë ¥ í† í° ìˆ˜ ëˆ„ì ì¹˜ ê³„ì‚°\n",
        "        # í…œí”Œë¦¿ í”„ë¡¬í”„íŠ¸ ê°ì²´ë¥¼ ë¬¸ìì—´ë¡œ ë°›ì•„ì˜¤ê¸°\n",
        "        prompt_str = prompt.format(video_summary=video_summary).to_string()\n",
        "        prompt_tokens += count_tokens(prompt_str)\n",
        "        completion_tokens += count_tokens(generation)\n",
        "\n",
        "        # í˜„ì¬ ê·¸ë˜í”„ ìƒíƒœì—ì„œ ë¬¸ì„œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¨ë‹¤.\n",
        "        documents = state.get('documents', [])\n",
        "                # --- ê° ë¬¸ì„œë¥¼ ì±„ì í•˜ê³  ê´€ë ¨ ë¬¸ì„œë§Œ í•„í„°ë§í•œë‹¤.\n",
        "        relevant_docs = []\n",
        "        for doc in documents:\n",
        "            score = self.__runnable.invoke(\n",
        "                input={'video_summary': state['video_summary'], 'document': doc.page_content},\n",
        "                config=config  # (note) for a configurable model\n",
        "            )\n",
        "\n",
        "        return state | {'answer': generation}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d582060f-7f5a-4b6c-964b-542c5338cebb",
      "metadata": {
        "id": "d582060f-7f5a-4b6c-964b-542c5338cebb"
      },
      "source": [
        "### 5. AnswerGenerationNode_ParentingSkill"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0bca980b-c935-45e9-97c5-fad5c2b858d4",
      "metadata": {
        "id": "0bca980b-c935-45e9-97c5-fad5c2b858d4"
      },
      "outputs": [],
      "source": [
        "from langchain_core.runnables import Runnable, RunnableConfig\n",
        "from typing import Optional\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "class AnswerGenerationNode_ParentingSkill:\n",
        "    def __init__(self, runnable: Runnable) -> None:\n",
        "        self.base_runnable = runnable\n",
        "\n",
        "    def __call__(self, state: State, config: Optional[RunnableConfig] = None) -> State:\n",
        "        node_name = '--- Answer Generation Agent node'\n",
        "        print(f'\\n{node_name} {'-' * (79 - len('\\n') - len(node_name) - 1)}')\n",
        "\n",
        "        # ì§ˆë¬¸ê³¼ ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ QnA ì„¸íŠ¸ êµ¬ì„±\n",
        "        qna_sets = []\n",
        "        for doc in state['documents']:\n",
        "            qna_sets.append({\n",
        "                'question': doc.page_content,\n",
        "                'document': doc.metadata.get('ì›ë¬¸ ë°ì´í„°', ''),\n",
        "                'source': doc.metadata.get('ì¶œì²˜', '')\n",
        "            })\n",
        "\n",
        "        # ê´€ë ¨ ì§ˆë¬¸ì´ í•˜ë‚˜ë„ ì—†ì„ ê²½ìš° ê¸°ë³¸ ë©”ì‹œì§€ ì¶œë ¥\n",
        "        if not qna_sets:\n",
        "            print('%> No relevant QnA found. Returning default message.')\n",
        "            return state | {'answer': 'ê¶ê¸ˆí•œê²Œ ìˆë‹¤ë©´ ì§ˆë¬¸í•´ì£¼ì„¸ìš”.'}\n",
        "\n",
        "        # â–¶ Prompt ë¬¸ìì—´ ë™ì  êµ¬ì„±\n",
        "        human_template = \"\"\"You are an expert in parenting children with developmental disabilities, with over 10 years of experience.\n",
        "\n",
        "You will be given a summary of a video, along with several questions and corresponding parenting guideline documents.\n",
        "\n",
        "Your task is as follows:\n",
        "\n",
        "1. Based on the video summary, write a short introductory paragraph that helps connect the video to the following questions and answers.\n",
        "The goal is to ensure that parents do not feel the questions and answers are unrelated to the video.\n",
        "\n",
        "2. For each question, write a clear and helpful answer by referencing the given guideline document.\n",
        "Do not change the meaning of the original guideline.\n",
        "Try to preserve the vocabulary and expressions used in the guideline as much as possible.\n",
        "+ Format each answer as a short paragraph or as a numbered list (e.g., 1ï¸âƒ£, \\n2ï¸âƒ£, \\n3ï¸âƒ£), depending on the content. Use numbering especially when the guideline includes multiple steps or recommendations.\n",
        "\n",
        "3. Your output **must be in Korean**, even though the instructions are written in English.\n",
        "\n",
        "4. Format your final output exactly in the JSON structure shown below.\n",
        "âš ï¸ Make sure to use the `source` value **exactly as provided** in the input, without any rewriting or interpretation.\n",
        "\n",
        "[Video Summary]\n",
        "{video_summary}\n",
        "\n",
        "[Questions & Parenting Guidelines]\n",
        "\"\"\"  # Insert qna below this\n",
        "\n",
        "        # Add QnAs dynamically\n",
        "        for i, qna in enumerate(qna_sets[:3], 1):\n",
        "            human_template += f\"\"\"\n",
        "        {i}.\n",
        "        Q: {qna['question']}\n",
        "        Parenting Guideline: {qna['document']}\n",
        "        Source: {qna['source']}\"\"\"\n",
        "\n",
        "        human_template += \"\"\"\n",
        "\n",
        "[Output Format Example]\n",
        "```json\n",
        "{{\n",
        "  \"intro\": \"ì´ ì˜ìƒì€ ì¹œêµ¬ë“¤ì˜ ìš°ì •ì„ í†µí•´ ì„œë¡œ ë‹¤ë¦„ì„ ì´í•´í•˜ëŠ” ê³¼ì •ì„ ë³´ì—¬ì£¼ë©°, ì•„ë˜ ì§ˆë¬¸ë“¤ì€ ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì•„ì´ì™€ì˜ ëŒ€í™”ë¥¼ ë•ê¸° ìœ„í•œ ê²ƒì…ë‹ˆë‹¤.\",\n",
        "  \"qna\": [\n",
        "    {{\n",
        "      \"question\": \"ì•„ì´ì™€ ì¹œêµ¬ ê´€ê³„ì—ì„œ ë°°ë ¤ë¥¼ ì–´ë–»ê²Œ ê°€ë¥´ì¹  ìˆ˜ ìˆì„ê¹Œìš”?\",\n",
        "      \"answer\": \"ë°°ë ¤ëŠ” ì¼ìƒ ì† ì‘ì€ ì‹¤ì²œì„ í†µí•´ ìì—°ìŠ¤ëŸ½ê²Œ ë°°ìš¸ ìˆ˜ ìˆë„ë¡ í•´ì•¼ í•©ë‹ˆë‹¤. ...\",\n",
        "      \"source\": \"ã€í•¨ê»˜ í¬ëŠ” ìš°ë¦¬ ì•„ì´: ê´€ê³„ í˜•ì„± í¸ã€ p.27\"\n",
        "    }},\n",
        "    {{\n",
        "      \"question\": \"...\",\n",
        "      \"answer\": \"...\",\n",
        "      \"source\": \"...\"\n",
        "    }}\n",
        "  ]\n",
        "}}\n",
        "\n",
        "âš ï¸ Make sure to respond only in Korean, and follow the JSON format exactly.\n",
        "âš ï¸ All answers must be in Korean.\n",
        "âš ï¸ source field must match exactly what was provided in the input.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "        # â–¶ Prompt ê°ì²´ ìƒì„±\n",
        "        prompt = ChatPromptTemplate.from_messages([\n",
        "            (\"system\", 'You are an expert in parenting children with developmental disabilities, with over 10 years of experience.'),\n",
        "            (\"human\", human_template)\n",
        "        ])\n",
        "\n",
        "        # â–¶ ì „ì²´ runnable êµ¬ì„±\n",
        "        full_runnable = prompt | self.base_runnable | StrOutputParser()\n",
        "        video_summary = state.get('video_summary','')\n",
        "\n",
        "        # â–¶ LLM ì‹¤í–‰\n",
        "        '''generation = full_runnable.invoke(\n",
        "            {'video_summary': state['video_summary']},\n",
        "            config=config\n",
        "        )'''\n",
        "        generation = full_runnable.invoke(\n",
        "            {'video_summary': video_summary},\n",
        "            config=config\n",
        "        )\n",
        "\n",
        "\n",
        "        # ì…ë ¥ ì¶œë ¥ í† í° ìˆ˜ ëˆ„ì ì¹˜ ê³„ì‚°\n",
        "        # í…œí”Œë¦¿ í”„ë¡¬í”„íŠ¸ ê°ì²´ë¥¼ ë¬¸ìì—´ë¡œ ë°›ì•„ì˜¤ê¸°\n",
        "        prompt_str = prompt.format(video_summary=video_summary).to_string()\n",
        "        prompt_tokens += count_tokens(prompt_str)\n",
        "        completion_tokens += count_tokens(generation)\n",
        "\n",
        "        return state | {'answer': generation}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03e7a350-5c44-4d5f-8239-52b2de509e1e",
      "metadata": {
        "id": "03e7a350-5c44-4d5f-8239-52b2de509e1e"
      },
      "source": [
        "### 6. FinalFormattingNode_PlayReco"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f45cdf2-a430-479b-bf3d-3837d69e34eb",
      "metadata": {
        "id": "0f45cdf2-a430-479b-bf3d-3837d69e34eb"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import json\n",
        "import textwrap\n",
        "from typing import Optional\n",
        "from langchain_core.runnables import Runnable, RunnableConfig\n",
        "\n",
        "class FinalFormattingNode_PlayReco(Runnable):\n",
        "    def invoke(self, state: dict, config: Optional[RunnableConfig] = None) -> dict:\n",
        "\n",
        "        # JSON ë¬¸ìì—´ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜\n",
        "        def extract_json_from_response(text: str) -> dict:\n",
        "            try:\n",
        "                # í…ìŠ¤íŠ¸ì—ì„œ JSON ê°ì²´ ì¶”ì¶œ\n",
        "                json_string = re.search(r\"\\{[\\s\\S]+\\}\", text, re.DOTALL).group()\n",
        "                return json.loads(json_string)\n",
        "            except Exception as e:\n",
        "                print(f\"âŒ JSON ì¶”ì¶œ ì‹¤íŒ¨: {e}\")\n",
        "                return {}\n",
        "\n",
        "        # ë²ˆí˜¸ê°€ ë¶™ì€ í•­ëª©ì„ ê°ì§€í•˜ê³  ë¶„ë¦¬í•˜ëŠ” í•¨ìˆ˜\n",
        "        def split_by_emoji_numbers(answer: str) -> list:\n",
        "            pattern = r'(1ï¸âƒ£|2ï¸âƒ£|3ï¸âƒ£|4ï¸âƒ£|5ï¸âƒ£|6ï¸âƒ£|7ï¸âƒ£|8ï¸âƒ£|9ï¸âƒ£|ğŸ”Ÿ)'\n",
        "            parts = re.split(pattern, answer)\n",
        "            combined = []\n",
        "            i = 1\n",
        "            while i < len(parts):\n",
        "                emoji = parts[i]\n",
        "                text = parts[i + 1] if i + 1 < len(parts) else ''\n",
        "                combined.append(f\"{emoji} {text.strip()}\")\n",
        "                i += 2\n",
        "            return combined\n",
        "\n",
        "        # ì½˜ì†” ì¶œë ¥ ë° JSON ì¶”ì¶œ\n",
        "        # print('\\n--- Final Formatting Node --------------------------------------------------------')\n",
        "\n",
        "        # state['answer']ì—ì„œ JSON ë°ì´í„°ë¥¼ ì¶”ì¶œ\n",
        "        parsed = extract_json_from_response(state['answer'])\n",
        "\n",
        "        # `intro` í…ìŠ¤íŠ¸ ì¶œë ¥\n",
        "        intro = parsed.get(\"intro\", \"No introduction provided.\")\n",
        "        print(f'ğŸ“Œ {intro}\\n')\n",
        "        print(\"ğŸ™‹â€â™€ï¸ ë” ì•Œê³  ì‹¶ì–´ìš”!\")\n",
        "\n",
        "        # QnA ì •ë³´ ì¶œë ¥\n",
        "        play_recommendation = parsed.get(\"play_recommendation\", {})\n",
        "        name = play_recommendation.get(\"name\", \"No play recommendation found.\")\n",
        "        steps = play_recommendation.get(\"steps\", \"No steps provided.\")\n",
        "        lessons = play_recommendation.get(\"lessons\", \"No lessons provided.\")\n",
        "        original_content = play_recommendation.get(\"original_content\", \"No original content provided.\")\n",
        "\n",
        "        # í¬ë§·íŒ…ëœ ê²°ê³¼ ì¶œë ¥\n",
        "        print(f\"ğŸ® ë†€ì´ ì¶”ì²œ: {name}\")\n",
        "        print(f\"ğŸ“œ ë†€ì´ ê³¼ì •:\\n{steps}\")\n",
        "        print(f\"ğŸ“ ë†€ì´ë¡œ ì–»ì„ ìˆ˜ ìˆëŠ” êµí›ˆ:\\n{lessons}\")\n",
        "        print(f\"ğŸ“ ì›ë¬¸ ë‚´ìš©:\\n{original_content}\")\n",
        "\n",
        "        # ì¶œì²˜ ì¶œë ¥\n",
        "        source = parsed.get(\"source\", \"No source provided.\")\n",
        "        print(f\"ğŸ“š ì¶œì²˜: {source}\")\n",
        "\n",
        "        print(\"â”€\" * 90)\n",
        "\n",
        "        # ë°˜í™˜í•  JSON êµ¬ì¡°\n",
        "        result = {\n",
        "            \"intro\": intro,\n",
        "            \"play_recommendation\": {\n",
        "                \"name\": name,\n",
        "                \"steps\": steps,\n",
        "                \"lessons\": lessons,\n",
        "                \"original_content\": original_content\n",
        "            },\n",
        "            \"source\": source\n",
        "        }\n",
        "\n",
        "        # JSON í˜•ì‹ìœ¼ë¡œ ì¶œë ¥ ë° state ë°˜í™˜\n",
        "        return state | {'formatted_output': json.dumps(result, ensure_ascii=False, indent=2)}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e160b61-36bf-4485-a59a-651cdd809dce",
      "metadata": {
        "id": "3e160b61-36bf-4485-a59a-651cdd809dce"
      },
      "source": [
        "### 7. FinalFormattingNode_ParentingSkill"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ea93913-9f14-42cf-af10-2da6e0cb473c",
      "metadata": {
        "id": "8ea93913-9f14-42cf-af10-2da6e0cb473c"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import json\n",
        "import textwrap\n",
        "from typing import Optional\n",
        "from langchain_core.runnables import Runnable, RunnableConfig\n",
        "from langchain_core.runnables import Runnable\n",
        "\n",
        "class FinalFormattingNode_ParentingSkill(Runnable):\n",
        "    def invoke(self, state: dict, config: Optional[RunnableConfig] = None) -> dict:\n",
        "        def extract_json_from_response(text: str) -> dict:\n",
        "            try:\n",
        "                json_string = re.search(r\"\\{[\\s\\S]+\\}\", text, re.DOTALL).group()\n",
        "                return json.loads(json_string)\n",
        "            except Exception as e:\n",
        "                print(f\"âŒ JSON ì¶”ì¶œ ì‹¤íŒ¨: {e}\")\n",
        "                return {}\n",
        "\n",
        "        def split_by_emoji_numbers(answer: str) -> list:\n",
        "            pattern = r'(1ï¸âƒ£|2ï¸âƒ£|3ï¸âƒ£|4ï¸âƒ£|5ï¸âƒ£|6ï¸âƒ£|7ï¸âƒ£|8ï¸âƒ£|9ï¸âƒ£|ğŸ”Ÿ)'\n",
        "            parts = re.split(pattern, answer)\n",
        "            combined = []\n",
        "            i = 1\n",
        "            while i < len(parts):\n",
        "                emoji = parts[i]\n",
        "                text = parts[i + 1] if i + 1 < len(parts) else ''\n",
        "                combined.append(f\"{emoji} {text.strip()}\")\n",
        "                i += 2\n",
        "            return combined\n",
        "\n",
        "        # print('\\n--- Final Formatting Node --------------------------------------------------------')\n",
        "\n",
        "        parsed = extract_json_from_response(state['answer'])\n",
        "\n",
        "        print(f'ğŸ“Œ {parsed.get(\"intro\", \"\")}\\n')\n",
        "        print(\"ğŸ™‹â€â™€ï¸ ë” ì•Œê³  ì‹¶ì–´ìš”!\")\n",
        "\n",
        "        for i, qna in enumerate(parsed.get(\"qna\", []), 1):\n",
        "            print(f\"{i}. â“ Q: {qna['question']}\\n\")\n",
        "            print(\"   ğŸ’¬ A:\")\n",
        "            if '1ï¸âƒ£' in qna['answer']:\n",
        "                numbered_lines = split_by_emoji_numbers(qna['answer'])\n",
        "                for line in numbered_lines:\n",
        "                    print(f\"     {textwrap.fill(line, width=80, subsequent_indent='     ')}\")\n",
        "            else:\n",
        "                print(f\"     {textwrap.fill(qna['answer'], width=80, subsequent_indent='     ')}\")\n",
        "            print(f\"\\n   ğŸ“š ì¶œì²˜: {qna['source']}\")\n",
        "            print(\"â”€\" * 90)\n",
        "\n",
        "        return state"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da3f57ad-03ba-4443-92d8-f80b06b8dc98",
      "metadata": {
        "id": "da3f57ad-03ba-4443-92d8-f80b06b8dc98"
      },
      "source": [
        "### ê·¸ë˜í”„ íë¦„ ì •ì˜"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33bb4319-4832-4ecd-bea5-b62b7de86e6d",
      "metadata": {
        "id": "33bb4319-4832-4ecd-bea5-b62b7de86e6d"
      },
      "outputs": [],
      "source": [
        "# ê·¸ë˜í”„ íë¦„ ì •ì˜\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "\n",
        "graph = StateGraph(State)\n",
        "graph.add_node('Video Start Router', VideoStartRouterNode())\n",
        "graph.add_node('Video Summarizer', YouTubeSummaryNode(summarize_model))\n",
        "graph.add_node(\n",
        "    'Retriever_ParentingSkill',\n",
        "    RetrieverNode(vectorstore2_2.as_retriever(\n",
        "        search_type='similarity',\n",
        "        search_kwargs={'k': 15}\n",
        "    ))\n",
        ")\n",
        "graph.add_node(\n",
        "    'Retriever_PlayReco',\n",
        "    RetrieverNode(vectorstore1.as_retriever(\n",
        "        search_type='similarity',\n",
        "        search_kwargs={'k': 15}\n",
        "    ))\n",
        ")\n",
        "graph.add_node('Video Recommendation Node', VideoRecommendationNode(summarize_model))\n",
        "graph.add_node('Document Reviewer', DocumentReviewNode(doc_review_model))\n",
        "graph.add_node('Answer Generator_ParentingSkill', AnswerGenerationNode_ParentingSkill(answering_model))\n",
        "graph.add_node('Answer Generator_PlayReco', AnswerGenerationNode_PlayReco(answering_model))\n",
        "graph.add_node('Final Formatter_ParentingSkill', FinalFormattingNode_ParentingSkill())\n",
        "graph.add_node('Final Formatter_PlayReco', FinalFormattingNode_PlayReco())\n",
        "\n",
        "graph.add_conditional_edges(\n",
        "    source='Video Start Router',\n",
        "    path=VideoStartRouterNode.route,\n",
        "    path_map={\n",
        "        'Video Summarizer': 'Video Summarizer',\n",
        "        'Retriever_ParentingSkill': 'Retriever_ParentingSkill',\n",
        "        'Retriever_PlayReco': 'Retriever_PlayReco',\n",
        "        'Video Recommendation': 'Video Recommendation'\n",
        "    }\n",
        ")\n",
        "\n",
        "graph.add_conditional_edges(\n",
        "    source='Video Summarizer',\n",
        "    path=YouTubeSummaryNode.route,\n",
        "    path_map={\n",
        "        'parenting_skill': 'Retriever_ParentingSkill',\n",
        "        'play_reco': 'Retriever_PlayReco',\n",
        "        'Video Recommendation': 'Video Recommendation'\n",
        "\n",
        "    }\n",
        ")\n",
        "graph.add_conditional_edges(\n",
        "    source='Document Reviewer',\n",
        "    path=DocumentReviewNode.route,\n",
        "    path_map={\n",
        "        'parenting_skill': 'Answer Generator_ParentingSkill',\n",
        "        'play_reco': 'Answer Generator_PlayReco'\n",
        "    }\n",
        ")\n",
        "\n",
        "graph.add_edge(START, 'Video Start Router')\n",
        "graph.add_edge('Retriever_ParentingSkill', 'Document Reviewer')\n",
        "graph.add_edge('Retriever_PlayReco', 'Document Reviewer')\n",
        "\n",
        "graph.add_edge('Answer Generator_ParentingSkill', 'Final Formatter_ParentingSkill')\n",
        "graph.add_edge('Answer Generator_PlayReco', 'Final Formatter_PlayReco')\n",
        "\n",
        "graph.add_edge('Final Formatter_ParentingSkill', END)\n",
        "graph.add_edge('Final Formatter_PlayReco', END)\n",
        "\n",
        "# --- compile\n",
        "workflow = graph.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3fdabad-3982-466b-bfec-93076e656c62",
      "metadata": {
        "id": "e3fdabad-3982-466b-bfec-93076e656c62",
        "outputId": "56b705d3-0ef4-4fac-f289-fd43a45c2bb6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                +-----------+                               \n",
            "                                | __start__ |                               \n",
            "                                +-----------+                               \n",
            "                                       *                                    \n",
            "                                       *                                    \n",
            "                                       *                                    \n",
            "                            +--------------------+                          \n",
            "                            | Video Start Router |                          \n",
            "                         ...+--------------------+....                      \n",
            "                    .....              .              ......                \n",
            "              ......                   .                    .....           \n",
            "        ......                         .                         ......     \n",
            "     ...                     +------------------+                      ...  \n",
            "       ..                    | Video Summarizer |                     ..    \n",
            "         ...                 +------------------+                  ...      \n",
            "            ...              ...               ...              ...         \n",
            "               ..         ...                     ...         ..            \n",
            "                 ..     ..                           ..     ..              \n",
            "          +--------------------+           +--------------------------+     \n",
            "          | Retriever_PlayReco |           | Retriever_ParentingSkill |     \n",
            "          +--------------------+           +--------------------------+     \n",
            "                             ***               ***                          \n",
            "                                ***         ***                             \n",
            "                                   **     **                                \n",
            "                            +-------------------+                           \n",
            "                            | Document Reviewer |                           \n",
            "                            +-------------------+                           \n",
            "                           ...                   ...                        \n",
            "                       ....                         ....                    \n",
            "                     ..                                 ..                  \n",
            "+---------------------------------+           +---------------------------+ \n",
            "| Answer Generator_ParentingSkill |           | Answer Generator_PlayReco | \n",
            "+---------------------------------+           +---------------------------+ \n",
            "                  *                                         *               \n",
            "                  *                                         *               \n",
            "                  *                                         *               \n",
            "+--------------------------------+            +--------------------------+  \n",
            "| Final Formatter_ParentingSkill |            | Final Formatter_PlayReco |  \n",
            "+--------------------------------+            +--------------------------+  \n",
            "                           ***                   ***                        \n",
            "                              ****           ****                           \n",
            "                                  **       **                               \n",
            "                                  +---------+                               \n",
            "                                  | __end__ |                               \n",
            "                                  +---------+                               \n"
          ]
        }
      ],
      "source": [
        "print(workflow.get_graph().draw_ascii())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd077a46-a09a-4be9-b639-951cb946f82b",
      "metadata": {
        "id": "bd077a46-a09a-4be9-b639-951cb946f82b"
      },
      "source": [
        "### ìµœì¢… ì—ì´ì „íŠ¸"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c6c0d5b-9e12-4155-85cd-821437e8ec08",
      "metadata": {
        "id": "2c6c0d5b-9e12-4155-85cd-821437e8ec08",
        "outputId": "d983f43a-48bb-4607-8cc3-f71dd8546106"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "parenting_skill\n"
          ]
        }
      ],
      "source": [
        "user_input2 = '1'\n",
        "option_dic = {'1': 'parenting_skill', '2': 'play_reco'}\n",
        "print(option_dic[user_input2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "fcc95e9e-4690-4920-8875-c70b0970bfd8",
      "metadata": {
        "id": "fcc95e9e-4690-4920-8875-c70b0970bfd8"
      },
      "outputs": [],
      "source": [
        "from langchain_core.runnables import RunnableConfig\n",
        "from typing import Optional\n",
        "\n",
        "class KuBot:\n",
        "    def __init__(self, workflow):\n",
        "        self.workflow = workflow # ì±—ë´‡ ì‹¤í–‰ì— ì‚¬ìš©í•  ì›Œí¬í”Œë¡œìš° ê°ì²´ ì €ì¥\n",
        "        self.quit_commands = {'quit', 'q', 'exit', 'ì¢…ë£Œ'} # ì¢…ë£Œ ëª…ë ¹ì–´ ì§‘í•© ì •ì˜\n",
        "\n",
        "    def get_response(self, user_input1: str = '', user_input2: str = '', config: Optional[RunnableConfig] = None) -> str:\n",
        "        option_dic = {'1': 'parenting_skill', '2': 'play_reco', '3': 'video_recommendation'}\n",
        "        response = self.workflow.invoke({'video_url': user_input1, 'option': option_dic[user_input2]}, config)\n",
        "        if option_dic[user_input2] == 'video_recommendation' and 'recommendation' in response:\n",
        "            reco_list = response['recommendation']\n",
        "            msg = \"\\nğŸ¬ ì¶”ì²œ ì˜ìƒ ëª©ë¡!\\n\"\n",
        "            for i, rec in enumerate(reco_list, 1):\n",
        "                msg += f\"{i}. ì œëª©: {rec['title']}\\n   ë§í¬: {rec['link']}\\n   ì¶”ì²œ ì´ìœ : {rec['reason']}\\n\"\n",
        "            return msg\n",
        "        else:\n",
        "            return response['answer']\n",
        "\n",
        "    def start(self):\n",
        "        print('ì•ˆë…•í•˜ì„¸ìš”. ë°œë‹¬ì¥ì• ì¸ì„ ìœ„í•œ ì±—ë´‡, ğŸ¤—\"ì¿ ë´‡\"ğŸ¤—ì…ë‹ˆë‹¤!')\n",
        "        print('\\nğŸ˜† ì‹œì²­í•˜ëŠ” ì˜ìƒì˜ ì£¼ì†Œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”. ëŒ€í™”ì¢…ë£Œë¥¼ ì›í•˜ì‹œë©´ \"quit\", \"q\", \"exit\", \"ì¢…ë£Œ\" ì¤‘ í•˜ë‚˜ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.')\n",
        "        question = input('\\n>>> ')\n",
        "        # ì¢…ë£Œ ëª…ë ¹ì–´ ì…ë ¥ ì‹œ ì¢…ë£Œ\n",
        "        if question.lower() in self.quit_commands:\n",
        "            print('ê°ì‚¬í•©ë‹ˆë‹¤. ëŒ€í™”ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤. ')\n",
        "            return\n",
        "        while True:\n",
        "            print('''\n",
        "            \\nâ“ ë‹¤ìŒ ì¤‘ ì›í•˜ëŠ” ì˜µì…˜ì„ ì„ íƒí•´ì£¼ì„¸ìš”,\n",
        "1. ì˜ìƒ ë‚´ìš©ê³¼ ê´€ë ¨í•œ ì–‘ìœ¡ê¸°ìˆ  ì •ë³´ ë°›ê¸°\n",
        "2. ì˜ìƒ ì‹œì²­ í›„ ì•„ì´ì™€ í•  ë†€ì´ ì¶”ì²œë°›ê¸°\n",
        "3. ì¶”ì²œ ì˜ìƒ\n",
        "(ì…ë ¥ ì–‘ì‹ ì˜ˆ: 1)\n",
        "ëŒ€í™”ì¢…ë£Œë¥¼ ì›í•˜ì‹œë©´ \"quit\", \"q\", \"exit\", \"ì¢…ë£Œ\" ì¤‘ í•˜ë‚˜ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.\n",
        "            ''')\n",
        "            option = input('\\n>>> ')\n",
        "            if option.lower() in self.quit_commands:\n",
        "                print('ê°ì‚¬í•©ë‹ˆë‹¤. ëŒ€í™”ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤. ')\n",
        "                break\n",
        "\n",
        "            response = self.get_response(question, option)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64d808a1-2bf2-4e4a-b5e0-d5602b461a9e",
      "metadata": {
        "id": "64d808a1-2bf2-4e4a-b5e0-d5602b461a9e",
        "outputId": "acd2940a-1963-40dd-8b42-efe99190f418"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ì•ˆë…•í•˜ì„¸ìš”. ë°œë‹¬ì¥ì• ì¸ì„ ìœ„í•œ ì±—ë´‡, ğŸ¤—\"ì¿ ë´‡\"ğŸ¤—ì…ë‹ˆë‹¤!\n",
            "\n",
            "ğŸ˜† ì‹œì²­í•˜ëŠ” ì˜ìƒì˜ ì£¼ì†Œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”. ëŒ€í™”ì¢…ë£Œë¥¼ ì›í•˜ì‹œë©´ \"quit\", \"q\", \"exit\", \"ì¢…ë£Œ\" ì¤‘ í•˜ë‚˜ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            ">>>  https://www.youtube.com/watch?v=ukykOIv4doE\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "            \n",
            "â“ ë‹¤ìŒ ì¤‘ ì›í•˜ëŠ” ì˜µì…˜ì„ ì„ íƒí•´ì£¼ì„¸ìš”, \n",
            "1. ì˜ìƒ ë‚´ìš©ê³¼ ê´€ë ¨í•œ ì–‘ìœ¡ê¸°ìˆ  ì •ë³´ ë°›ê¸° \n",
            "2. ì˜ìƒ ì‹œì²­ í›„ ì•„ì´ì™€ í•  ë†€ì´ ì¶”ì²œë°›ê¸° \n",
            "(ì…ë ¥ ì–‘ì‹ ì˜ˆ: 1)\n",
            "ëŒ€í™”ì¢…ë£Œë¥¼ ì›í•˜ì‹œë©´ \"quit\", \"q\", \"exit\", \"ì¢…ë£Œ\" ì¤‘ í•˜ë‚˜ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.\n",
            "            \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            ">>>  1\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VideoStartRouterNode Invoke: Passing state through: {'video_url': 'https://www.youtube.com/watch?v=ukykOIv4doE', 'documents': [], 'option': 'parenting_skill'}\n",
            "VideoStartRouterNode: current_video_url=https://www.youtube.com/watch?v=ukykOIv4doE, last_processed_video_url=None, option=parenting_skill\n",
            "ìƒˆë¡œìš´ ì˜ìƒì´ê±°ë‚˜ ìš”ì•½ë³¸ ì—†ìŒ. Video Summarizer ë…¸ë“œë¡œ ì‹œì‘í•©ë‹ˆë‹¤.\n",
            "ğŸ§© ì˜ìƒ ìš”ì•½ ì¤‘: 1/2\n",
            "ğŸ§© ì˜ìƒ ìš”ì•½ ì¤‘: 2/2\n",
            "Relevant documents: 2\n",
            "ğŸ“Œ ì´ ì˜ìƒì€ ë°œë‹¬ì¥ì•  ì•„ë™ì´ ì† ì”»ê¸°, ì–‘ì¹˜ì§ˆ, ëª¸ ì”»ê¸° ë“± ê¸°ë³¸ì ì¸ ìœ„ìƒ ìŠµê´€ê³¼ ì§‘ì•ˆ í™˜ê²½ ê´€ë¦¬, ì“°ë ˆê¸° ë¶„ë¦¬ìˆ˜ê±° ë°©ë²•ì„ ì‰½ê²Œ ìµí ìˆ˜ ìˆë„ë¡ ë„ì™€ì¤ë‹ˆë‹¤. ì•„ë˜ ì§ˆë¬¸ê³¼ ë‹µë³€ì€ ì˜ìƒì—ì„œ ë‹¤ë£¬ ì¼ìƒìƒí™œ ì† ìœ„ìƒ ë° ìê¸°ê´€ë¦¬ í™œë™ì„ ì‹¤ì œë¡œ ê°€ì •ì—ì„œ ì‹¤ì²œí•˜ê³ , ì•„ì´ì˜ ì˜ì‚¬ì†Œí†µê³¼ ìë¦½ì„ ì§€ì›í•˜ëŠ” ë° ë„ì›€ì´ ë  ìˆ˜ ìˆëŠ” êµ¬ì²´ì ì¸ ë°©ë²•ì„ ì•ˆë‚´í•©ë‹ˆë‹¤.\n",
            "\n",
            "ğŸ™‹â€â™€ï¸ ë” ì•Œê³  ì‹¶ì–´ìš”!\n",
            "1. â“ Q: ë°œë‹¬ì¥ì•  ì•„ë™ì—ê²Œ ì¼ìƒì ì¸ í™œë™ì„ í†µí•´ ì˜ì‚¬ì†Œí†µì„ ê°€ë¥´ì¹˜ëŠ” ë°©ë²•ì´ ìˆì„ê¹Œìš”?\n",
            "\n",
            "   ğŸ’¬ A:\n",
            "     ì¼ìƒì ì¸ í™œë™ì„ í†µí•´ ì˜ì‚¬ì†Œí†µì„ ê°€ë¥´ì¹˜ê¸° ìœ„í•´ì„œëŠ”, ìœµíŒì´ë‚˜ ì—„ë§ˆ ì•ì¹˜ë§ˆì— ì–´ë¦°ì´ì§‘ ì‚¬ì§„(ë“±ì›ì°¨ëŸ‰ì´ë‚˜ êµì‚¬ì˜ ì–¼êµ´ ë“± ì•„ë™ì´ ì¸ì‹ ê°€ëŠ¥í•œ ê²ƒì—\n",
            "     ì°ì°ì´ë¥¼ ë¶€ì°©)ì„ ì—„ë§ˆì™€ í•¨ê»˜ ë¶™ì´ê³  ë‚˜ì„œëŠ” ë°©ë²•ì´ ìˆìŠµë‹ˆë‹¤. ë˜í•œ ì‹ì‚¬ë‚˜ ë¬¼ì„ ë§ˆì‹œê¸° ì§ì „ì—ëŠ” í•­ìƒ ì»µ(ì‚¬ì§„ì´ë‚˜ ì‚¬ë¬¼ ìƒì§•)ì„ ë³´ì´ê³ \n",
            "     ìƒì§•íŒì— ë¶™ì¸ í›„ ë¨¹ê±°ë‚˜ ë§ˆì‹œë„ë¡ í•©ë‹ˆë‹¤. ì ˆëŒ€ë¡œ í—ˆìš©í•  ìˆ˜ ì—†ëŠ” ìœ„í—˜í•œ í–‰ë™ì´ ë°˜ë³µë  ê²½ìš°, 'ì•ˆ ëœë‹¤'ëŠ” ì˜ë¯¸ì˜ ê°™ì€ ëª¨ì–‘ì˜ ì¹´ë“œë¥¼\n",
            "     í•­ìƒ ì œì‹œí•˜ê³  ëê¹Œì§€ í—ˆìš©í•˜ì§€ ì•ŠëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤. ì´ ë‹¦ê¸°, ê¸°ì €ê·€ ê°ˆê¸°, í™”ì¥ì‹¤ ìš©ë³€ë³´ê¸°, ì ì˜· ê°ˆì•„ì…ê¸° ë“± ë§¤ì¼ ë°˜ë³µë˜ëŠ”\n",
            "     ì¼ìƒì—ì„œ í•´ë‹¹ ìƒì§•ì„ ê°€ë¦¬í‚¤ê±°ë‚˜ ë–¼ê±°ë‚˜ ë¶™ì´ê¸° ë“± ì•„ë™ì´ í•  ìˆ˜ ìˆëŠ” ë™ì‘ìœ¼ë¡œ ë°œì „ì‹œì¼œ ë‚˜ê°€ë©´ ì˜ì‚¬ì†Œí†µ ëŠ¥ë ¥ í–¥ìƒì— ë„ì›€ì´ ë©ë‹ˆë‹¤.\n",
            "\n",
            "   ğŸ“š ì¶œì²˜: ã€Œì¥ì• ì˜ìœ ì•„ ì–‘ìœ¡ ê°€ì´ë“œë¶ 2ê¶Œ ë°œë‹¬ì¥ì• -ì–‘ìœ¡ê¸°ìˆ ã€, êµ­ë¦½íŠ¹ìˆ˜êµìœ¡ì›, ì±•í„° 2. ì˜ì‚¬ì†Œí†µ / 2. ëŒ€ì•ˆì  ì˜ì‚¬ì†Œí†µ ì§€ì›, 49ìª½\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "2. â“ Q: ë°œë‹¬ ì¥ì• ê°€ ìˆëŠ” ì•„ì´ì˜ ë°°ë³€ í›ˆë ¨ì€ ì–´ë–»ê²Œ ì‹œì‘í•´ì•¼ í•˜ë‚˜ìš”?\n",
            "\n",
            "   ğŸ’¬ A:\n",
            "     ë°°ë³€ í›ˆë ¨ì€ ì–´ë¦´ ë•Œë¶€í„° ì¼ê´€ì ì¸ êµìœ¡ê³¼ ì—°ìŠµì˜ ê¸°íšŒë¥¼ í†µí•´ ì˜¬ë°”ë¥¸ ë°°ë³€ìŠµê´€ì´ í˜•ì„±ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì¡°ê¸‰í•¨ì„ ë²„ë¦¬ê³  ë§¤ì¼ ë°˜ë³µì ì¸ ìŠµê´€ì„\n",
            "     ê¸¸ëŸ¬ì£¼ëŠ” ê²ƒì´ ì¤‘ìš”í•˜ë©°, ì´ëŠ” ì¼ìƒìƒí™œ ê¸°ìˆ  ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤. ë°°ë³€ í›ˆë ¨ì´ë€ í™”ì¥ì‹¤ì—ì„œ ë°°ì„¤í•˜ëŠ” ìŠµê´€ì„ í˜•ì„±ì‹œì¼œ ëŒ€ì†Œë³€ì„ ê°€ë¦¬ë„ë¡\n",
            "     ì§€ë„í•˜ëŠ” ê²ƒì„ ë§í•©ë‹ˆë‹¤. ë°°ì„¤ ê¸°ê´€ì„ ì¡°ì ˆí•˜ëŠ” ê´„ì•½ê·¼ì€ ë‹¤ë¥¸ ê·¼ìœ¡ë“¤ë³´ë‹¤ í›¨ì”¬ ë” ì„¬ì„¸í•˜ê³  ëŠ¦ê²Œ ë°œë‹¬í•˜ë¯€ë¡œ, ì•„ì´ì˜ ì‹ ì²´ì  ë°œë‹¬ ê³¼ì •ì—\n",
            "     ë§ì¶”ì–´ ë°°ë³€ í›ˆë ¨ì„ ì‹œì‘í•´ì•¼ í•©ë‹ˆë‹¤.\n",
            "\n",
            "   ğŸ“š ì¶œì²˜: ã€Œì¥ì• ì˜ìœ ì•„ ì–‘ìœ¡ ê°€ì´ë“œë¶ 2ê¶Œ ë°œë‹¬ì¥ì• -ì–‘ìœ¡ê¸°ìˆ ã€, êµ­ë¦½íŠ¹ìˆ˜êµìœ¡ì›, ì±•í„° 5. ì¼ìƒìƒí™œ / 1. ë°°ë³€ìŠµê´€ ê¸°ë¥´ê¸°, 96ìª½\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "3. â“ Q: ë°œë‹¬ì¥ì•  ì•„ë™ì˜ ì¼ìƒìƒí™œì—ì„œ ì˜ì‚¬ì†Œí†µì„ ì–´ë–»ê²Œ ë„ì™€ì¤„ ìˆ˜ ìˆì„ê¹Œìš”?\n",
            "\n",
            "   ğŸ’¬ A:\n",
            "     ìœµíŒì´ë‚˜ ì—„ë§ˆ ì•ì¹˜ë§ˆì— ì–´ë¦°ì´ì§‘ ì‚¬ì§„(ë“±ì›ì°¨ëŸ‰ì´ë‚˜ êµì‚¬ì˜ ì–¼êµ´ ë“± ì•„ë™ì´ ì¸ì‹ ê°€ëŠ¥í•œ ê²ƒì— ì°ì°ì´ë¥¼ ë¶€ì°©)ì„ ì—„ë§ˆì™€ í•¨ê»˜ ë¶™ì´ê³  ë‚˜ì„œëŠ” ë°©ë²•,\n",
            "     ì‹ì‚¬ë‚˜ ë¬¼ì„ ë§ˆì‹œê¸° ì „ ì»µ(ì‚¬ì§„ì´ë‚˜ ì‚¬ë¬¼ ìƒì§•)ì„ ë³´ì´ê³  ìƒì§•íŒì— ë¶™ì¸ í›„ ë¨¹ê±°ë‚˜ ë§ˆì‹œëŠ” ë°©ë²• ë“±ì´ ìˆìŠµë‹ˆë‹¤. ìœ„í—˜í•œ í–‰ë™ì´ ë°˜ë³µë \n",
            "     ê²½ìš°ì—ëŠ” 'ì•ˆ ëœë‹¤'ëŠ” ì˜ë¯¸ì˜ ê°™ì€ ëª¨ì–‘ì˜ ì¹´ë“œë¥¼ í•­ìƒ ì œì‹œí•˜ê³  ëê¹Œì§€ í—ˆìš©í•˜ì§€ ì•ŠëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤. ë˜í•œ, ì´ ë‹¦ê¸°, ê¸°ì €ê·€ ê°ˆê¸°,\n",
            "     í™”ì¥ì‹¤ ìš©ë³€ë³´ê¸°, ì ì˜· ê°ˆì•„ì…ê¸° ë“± ì¼ìƒì—ì„œ ìì£¼ ë°˜ë³µë˜ëŠ” ì‚¬ê±´ì„ ì •í•´ ì•„ë™ê³¼ í•´ë‹¹ ìƒì§•ì„ ê°€ë¦¬í‚¤ê±°ë‚˜ ë–¼ê±°ë‚˜ ë¶™ì´ê¸° ë“± ì•„ë™ì´ í•  ìˆ˜\n",
            "     ìˆëŠ” ë™ì‘ìœ¼ë¡œ ë°œì „ì‹œì¼œ ë‚˜ê°€ë©´ ì˜ì‚¬ì†Œí†µì„ íš¨ê³¼ì ìœ¼ë¡œ ë„ìš¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
            "\n",
            "   ğŸ“š ì¶œì²˜: ã€Œì¥ì• ì˜ìœ ì•„ ì–‘ìœ¡ ê°€ì´ë“œë¶ 2ê¶Œ ë°œë‹¬ì¥ì• -ì–‘ìœ¡ê¸°ìˆ ã€, êµ­ë¦½íŠ¹ìˆ˜êµìœ¡ì›, ì±•í„° 2. ì˜ì‚¬ì†Œí†µ / 2. ëŒ€ì•ˆì  ì˜ì‚¬ì†Œí†µ ì§€ì›, 49ìª½\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "\n",
            "            \n",
            "â“ ë‹¤ìŒ ì¤‘ ì›í•˜ëŠ” ì˜µì…˜ì„ ì„ íƒí•´ì£¼ì„¸ìš”, \n",
            "1. ì˜ìƒ ë‚´ìš©ê³¼ ê´€ë ¨í•œ ì–‘ìœ¡ê¸°ìˆ  ì •ë³´ ë°›ê¸° \n",
            "2. ì˜ìƒ ì‹œì²­ í›„ ì•„ì´ì™€ í•  ë†€ì´ ì¶”ì²œë°›ê¸° \n",
            "(ì…ë ¥ ì–‘ì‹ ì˜ˆ: 1)\n",
            "ëŒ€í™”ì¢…ë£Œë¥¼ ì›í•˜ì‹œë©´ \"quit\", \"q\", \"exit\", \"ì¢…ë£Œ\" ì¤‘ í•˜ë‚˜ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.\n",
            "            \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            ">>>  2\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VideoStartRouterNode Invoke: Passing state through: {'video_url': 'https://www.youtube.com/watch?v=ukykOIv4doE', 'documents': [], 'option': 'play_reco'}\n",
            "VideoStartRouterNode: current_video_url=https://www.youtube.com/watch?v=ukykOIv4doE, last_processed_video_url=None, option=play_reco\n",
            "ìƒˆë¡œìš´ ì˜ìƒì´ê±°ë‚˜ ìš”ì•½ë³¸ ì—†ìŒ. Video Summarizer ë…¸ë“œë¡œ ì‹œì‘í•©ë‹ˆë‹¤.\n",
            "ğŸ§© ì˜ìƒ ìš”ì•½ ì¤‘: 1/2\n",
            "ğŸ§© ì˜ìƒ ìš”ì•½ ì¤‘: 2/2\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[792]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m kubot = KuBot(workflow)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mkubot\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[791]\u001b[39m\u001b[32m, line 35\u001b[39m, in \u001b[36mKuBot.start\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     32\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mê°ì‚¬í•©ë‹ˆë‹¤. ëŒ€í™”ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤. \u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     33\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moption\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[791]\u001b[39m\u001b[32m, line 11\u001b[39m, in \u001b[36mKuBot.get_response\u001b[39m\u001b[34m(self, user_input1, user_input2, config)\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_response\u001b[39m(\u001b[38;5;28mself\u001b[39m, user_input1: \u001b[38;5;28mstr\u001b[39m = \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m, user_input2: \u001b[38;5;28mstr\u001b[39m = \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m, config: Optional[RunnableConfig] = \u001b[38;5;28;01mNone\u001b[39;00m) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m     10\u001b[39m     option_dic = {\u001b[33m'\u001b[39m\u001b[33m1\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mparenting_skill\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m2\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mplay_reco\u001b[39m\u001b[33m'\u001b[39m}\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mworkflow\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mvideo_url\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_input1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43moption\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43moption_dic\u001b[49m\u001b[43m[\u001b[49m\u001b[43muser_input2\u001b[49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response[\u001b[33m'\u001b[39m\u001b[33manswer\u001b[39m\u001b[33m'\u001b[39m]\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langgraph/pregel/__init__.py:2719\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, **kwargs)\u001b[39m\n\u001b[32m   2716\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[Union[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any], Any]] = []\n\u001b[32m   2717\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m2719\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2720\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2721\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2722\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2723\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2724\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2725\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2726\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheckpoint_during\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheckpoint_during\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2727\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2728\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2729\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2730\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   2731\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2732\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   2733\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mints\u001b[49m\u001b[43m \u001b[49m\u001b[43m:=\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mINTERRUPT\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[32m   2734\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langgraph/pregel/__init__.py:2436\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[39m\n\u001b[32m   2434\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2435\u001b[39m             loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2436\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2437\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2438\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2439\u001b[39m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2440\u001b[39m \u001b[43m            \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2441\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2442\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2443\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2444\u001b[39m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langgraph/pregel/runner.py:161\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    159\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    175\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langgraph/pregel/retry.py:40\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     38\u001b[39m     task.writes.clear()\n\u001b[32m     39\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     42\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langgraph/utils/runnable.py:623\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    621\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    622\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m623\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    624\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    625\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langgraph/utils/runnable.py:377\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    375\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    376\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m377\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    379\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[768]\u001b[39m\u001b[32m, line 35\u001b[39m, in \u001b[36mDocumentReviewNode.__call__\u001b[39m\u001b[34m(self, state, config)\u001b[39m\n\u001b[32m     33\u001b[39m relevant_docs = []\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents:\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m     score = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__runnable\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mvideo_summary\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mvideo_summary\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdocument\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpage_content\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# (note) for a configurable model\u001b[39;49;00m\n\u001b[32m     38\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m     grade = score.relevance      \n\u001b[32m     40\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m grade == \u001b[33m'\u001b[39m\u001b[33mrelevant\u001b[39m\u001b[33m'\u001b[39m:  \u001b[38;5;66;03m# ë¬¸ì„œê°€ ê´€ë ¨ì„±ì´ ìˆìœ¼ë©´\u001b[39;00m\n\u001b[32m     41\u001b[39m         \u001b[38;5;66;03m# print(f'%> Evaluating: DOCUMENT RELEVANT')\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langchain_core/runnables/base.py:3047\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3045\u001b[39m                 input_ = context.run(step.invoke, input_, config, **kwargs)\n\u001b[32m   3046\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3047\u001b[39m                 input_ = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3048\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3049\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langchain_core/runnables/base.py:5430\u001b[39m, in \u001b[36mRunnableBindingBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5423\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5424\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5425\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5428\u001b[39m     **kwargs: Optional[Any],\n\u001b[32m   5429\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5430\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5431\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   5432\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5433\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5434\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:371\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    359\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    360\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    361\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    366\u001b[39m     **kwargs: Any,\n\u001b[32m    367\u001b[39m ) -> BaseMessage:\n\u001b[32m    368\u001b[39m     config = ensure_config(config)\n\u001b[32m    369\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    370\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    374\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    375\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    376\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    381\u001b[39m     ).message\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:956\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    947\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    948\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    949\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    953\u001b[39m     **kwargs: Any,\n\u001b[32m    954\u001b[39m ) -> LLMResult:\n\u001b[32m    955\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m956\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:775\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    772\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    773\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    774\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m775\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    776\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    777\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    778\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    779\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    780\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    781\u001b[39m         )\n\u001b[32m    782\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    783\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:1021\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1019\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1020\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1021\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1022\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1023\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1024\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1025\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langchain_openai/chat_models/base.py:935\u001b[39m, in \u001b[36mBaseChatOpenAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    933\u001b[39m payload.pop(\u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    934\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m935\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mroot_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    936\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m openai.BadRequestError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    937\u001b[39m     _handle_openai_bad_request(e)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/openai/resources/beta/chat/completions.py:158\u001b[39m, in \u001b[36mCompletions.parse\u001b[39m\u001b[34m(self, messages, model, audio, response_format, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, seed, service_tier, stop, store, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mparser\u001b[39m(raw_completion: ChatCompletion) -> ParsedChatCompletion[ResponseFormatT]:\n\u001b[32m    152\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _parse_chat_completion(\n\u001b[32m    153\u001b[39m         response_format=response_format,\n\u001b[32m    154\u001b[39m         chat_completion=raw_completion,\n\u001b[32m    155\u001b[39m         input_tools=tools,\n\u001b[32m    156\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m_type_to_response_format\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    181\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    183\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    185\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    186\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    187\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    189\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    190\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    196\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpost_parser\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# we turn the `ChatCompletion` instance into a `ParsedChatCompletion`\u001b[39;49;00m\n\u001b[32m    204\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# in the `parser` function above\u001b[39;49;00m\n\u001b[32m    205\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mType\u001b[49m\u001b[43m[\u001b[49m\u001b[43mParsedChatCompletion\u001b[49m\u001b[43m[\u001b[49m\u001b[43mResponseFormatT\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    207\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/openai/_base_client.py:1239\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1225\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1226\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1227\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1234\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1235\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1236\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1237\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1238\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1239\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/openai/_base_client.py:969\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m    967\u001b[39m response = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    968\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m969\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    970\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    974\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.TimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    975\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mEncountered httpx.TimeoutException\u001b[39m\u001b[33m\"\u001b[39m, exc_info=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/httpx/_client.py:914\u001b[39m, in \u001b[36mClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m    910\u001b[39m \u001b[38;5;28mself\u001b[39m._set_timeout(request)\n\u001b[32m    912\u001b[39m auth = \u001b[38;5;28mself\u001b[39m._build_request_auth(request, auth)\n\u001b[32m--> \u001b[39m\u001b[32m914\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    915\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    921\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/httpx/_client.py:942\u001b[39m, in \u001b[36mClient._send_handling_auth\u001b[39m\u001b[34m(self, request, auth, follow_redirects, history)\u001b[39m\n\u001b[32m    939\u001b[39m request = \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[32m    941\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    947\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    948\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/httpx/_client.py:979\u001b[39m, in \u001b[36mClient._send_handling_redirects\u001b[39m\u001b[34m(self, request, follow_redirects, history)\u001b[39m\n\u001b[32m    976\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mrequest\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    977\u001b[39m     hook(request)\n\u001b[32m--> \u001b[39m\u001b[32m979\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    981\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m]:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/httpx/_client.py:1014\u001b[39m, in \u001b[36mClient._send_single_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m   1009\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1010\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1011\u001b[39m     )\n\u001b[32m   1013\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=request):\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m     response = \u001b[43mtransport\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, SyncByteStream)\n\u001b[32m   1018\u001b[39m response.request = request\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/httpx/_transports/default.py:250\u001b[39m, in \u001b[36mHTTPTransport.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    237\u001b[39m req = httpcore.Request(\n\u001b[32m    238\u001b[39m     method=request.method,\n\u001b[32m    239\u001b[39m     url=httpcore.URL(\n\u001b[32m   (...)\u001b[39m\u001b[32m    247\u001b[39m     extensions=request.extensions,\n\u001b[32m    248\u001b[39m )\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.Iterable)\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[32m    255\u001b[39m     status_code=resp.status,\n\u001b[32m    256\u001b[39m     headers=resp.headers,\n\u001b[32m    257\u001b[39m     stream=ResponseStream(resp.stream),\n\u001b[32m    258\u001b[39m     extensions=resp.extensions,\n\u001b[32m    259\u001b[39m )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:256\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    253\u001b[39m         closing = \u001b[38;5;28mself\u001b[39m._assign_requests_to_connections()\n\u001b[32m    255\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_connections(closing)\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[32m    260\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, typing.Iterable)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:236\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    232\u001b[39m connection = pool_request.wait_for_connection(timeout=timeout)\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     response = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[32m    242\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    243\u001b[39m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[32m    244\u001b[39m     pool_request.clear_connection()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/httpcore/_sync/connection.py:103\u001b[39m, in \u001b[36mHTTPConnection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[38;5;28mself\u001b[39m._connect_failed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/httpcore/_sync/http11.py:136\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    134\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mresponse_closed\u001b[39m\u001b[33m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    135\u001b[39m         \u001b[38;5;28mself\u001b[39m._response_closed()\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/httpcore/_sync/http11.py:106\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[32m     98\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mreceive_response_headers\u001b[39m\u001b[33m\"\u001b[39m, logger, request, kwargs\n\u001b[32m     99\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    100\u001b[39m     (\n\u001b[32m    101\u001b[39m         http_version,\n\u001b[32m    102\u001b[39m         status,\n\u001b[32m    103\u001b[39m         reason_phrase,\n\u001b[32m    104\u001b[39m         headers,\n\u001b[32m    105\u001b[39m         trailing_data,\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m     trace.return_value = (\n\u001b[32m    108\u001b[39m         http_version,\n\u001b[32m    109\u001b[39m         status,\n\u001b[32m    110\u001b[39m         reason_phrase,\n\u001b[32m    111\u001b[39m         headers,\n\u001b[32m    112\u001b[39m     )\n\u001b[32m    114\u001b[39m network_stream = \u001b[38;5;28mself\u001b[39m._network_stream\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/httpcore/_sync/http11.py:177\u001b[39m, in \u001b[36mHTTP11Connection._receive_response_headers\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    174\u001b[39m timeout = timeouts.get(\u001b[33m\"\u001b[39m\u001b[33mread\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m     event = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11.Response):\n\u001b[32m    179\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/httpcore/_sync/http11.py:217\u001b[39m, in \u001b[36mHTTP11Connection._receive_event\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    214\u001b[39m     event = \u001b[38;5;28mself\u001b[39m._h11_state.next_event()\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11.NEED_DATA:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_network_stream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    227\u001b[39m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[32m    228\u001b[39m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[32m    229\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data == \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._h11_state.their_state == h11.SEND_RESPONSE:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/httpcore/_backends/sync.py:128\u001b[39m, in \u001b[36mSyncStream.read\u001b[39m\u001b[34m(self, max_bytes, timeout)\u001b[39m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[32m    127\u001b[39m     \u001b[38;5;28mself\u001b[39m._sock.settimeout(timeout)\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/ssl.py:1233\u001b[39m, in \u001b[36mSSLSocket.recv\u001b[39m\u001b[34m(self, buflen, flags)\u001b[39m\n\u001b[32m   1229\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1230\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1231\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1232\u001b[39m             \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1233\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1234\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1235\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv(buflen, flags)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/ssl.py:1106\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1104\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[32m   1105\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1106\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1107\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[32m   1108\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m x.args[\u001b[32m0\u001b[39m] == SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.suppress_ragged_eofs:\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "kubot = KuBot(workflow)\n",
        "kubot.start()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25e289de-268a-4143-8f12-4065bc08d3a4",
      "metadata": {
        "id": "25e289de-268a-4143-8f12-4065bc08d3a4",
        "outputId": "1e862543-3337-4fd5-a760-77e2055b8e78",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“Œ ì´ ì˜ìƒì€ 2-5ì„¸ ì•„ë™ë“¤ì´ ì¹œêµ¬ë“¤ê³¼ í•¨ê»˜ ë†€ì´ë¥¼ í•˜ë©° ìì‹ ì´ ì¢‹ì•„í•˜ëŠ” ê²ƒê³¼ ì‚¬ë‘í•˜ëŠ” ì‚¬ëŒì— ëŒ€í•´ ì´ì•¼ê¸°í•˜ëŠ” ëª¨ìŠµì„ ë‹´ê³  ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ê²½í—˜ì€ ì•„ì´ë“¤ì—ê²Œ ì¹œë°€ê°ê³¼ ì‚¬ë‘ì˜ ê°€ì¹˜ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ì „ë‹¬í•˜ë©°, ë†€ì´ì™€ ìƒí˜¸ì‘ìš©ì„ í†µí•´ ë°œë‹¬ì„ ì´‰ì§„í•˜ëŠ” ë° ì¤‘ìš”í•œ ì—­í• ì„ í•©ë‹ˆë‹¤. ì•„ë˜ì˜ ì§ˆë¬¸ê³¼ ë‹µë³€ì€ ì˜ìƒì—ì„œ ë‹¤ë£¬ ë†€ì´ì™€ ê´€ê³„ í˜•ì„±, ê·¸ë¦¬ê³  ë°œë‹¬ì¥ì•  ì•„ë™ì˜ ì–‘ìœ¡ì— ë„ì›€ì´ ë  ìˆ˜ ìˆëŠ” ì‹¤ì§ˆì ì¸ ë°©ë²•ë“¤ì„ ì•ˆë‚´í•©ë‹ˆë‹¤.\n",
            "\n",
            "ğŸ™‹â€â™€ï¸ ë” ì•Œê³  ì‹¶ì–´ìš”!\n",
            "1. â“ Q: ì•„ì´ì˜ ì–¸ì–´ë°œë‹¬ì„ ì´‰ì§„í•˜ê¸° ìœ„í•´ ì–´ë–¤ ë†€ì´ë¥¼ í•˜ë©´ ì¢‹ì„ê¹Œìš”?\n",
            "\n",
            "   ğŸ’¬ A:\n",
            "     ë§ê³¼ í–‰ë™ì„ ì£¼ê³ ë°›ì•„ ì£¼ì„¸ìš”. ì•„ì´ê°€ ì¦ê±°ìš´ ìƒí™©ì—ì„œ ë§ë¶™ì—¬ì§„ ë§ì´ ì•„ì´ì˜ ì–¸ì–´ë°œë‹¬ì— ë§¤ìš° ì´‰ì§„ì ì…ë‹ˆë‹¤. ì˜ìœ ì•„ë“¤ì´ ì¢‹ì•„í•˜ëŠ” ì¼ìƒì—ì„œ ë°˜ë³µí•˜ëŠ”\n",
            "     ëª¨ë“  ë†€ì´ê°€ ì–¸ì–´ë°œë‹¬ ì´‰ì§„ì  ë†€ì´ê°€ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì–¸ì–´ë¥¼ ì‹œë²”ë³´ì¼ ë•Œ ì•„ë™ì´ë‚˜ ë¶€ëª¨ì˜ í–‰ë™, ìƒí™©ê³¼ ë¶€ëª¨ì˜ ì–¸ì–´ ì‹œë²”ì˜ íƒ€ì´ë°ì„ ì˜\n",
            "     ë§ì¶”ë©´ í›¨ì”¬ íš¨ê³¼ì ì¸ ì–¸ì–´ ì´‰ì§„ì´ ë©ë‹ˆë‹¤.\n",
            "\n",
            "   ğŸ“š ì¶œì²˜: ã€Œì¥ì• ì˜ìœ ì•„ ì–‘ìœ¡ ê°€ì´ë“œë¶ 2ê¶Œ ë°œë‹¬ì¥ì• -ì–‘ìœ¡ê¸°ìˆ ã€, êµ­ë¦½íŠ¹ìˆ˜êµìœ¡ì›, ì±•í„° 2. ì˜ì‚¬ì†Œí†µ / 1. ì–´íœ˜ ë° ì˜ì‚¬ì†Œí†µ ë°œë‹¬ ì´‰ì§„, 38ìª½\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "2. â“ Q: ë°œë‹¬ì¥ì• ê°€ ìˆëŠ” ì•„ì´ì™€ ì–´ë–»ê²Œ ë†€ì•„ì£¼ë©´ ì¢‹ì„ê¹Œìš”?\n",
            "\n",
            "   ğŸ’¬ A:\n",
            "     ê¹Œê¿ë†€ì´, ì¡ê¸°ë†€ì´, ë¶€ì—Œì„¸íŠ¸ ë†€ì´ ë“± ì•„ì´ì˜ ìˆ˜ì¤€ì— ë§ëŠ” ë†€ì´ë¥¼ í•¨ê»˜ í•˜ë©°, í–‰ë™ì´ ì¼ì–´ë‚  ë•Œë§ˆë‹¤ ì ì ˆí•œ ë§ì„ ë§ë¶™ì—¬ ë“¤ë ¤ì£¼ì„¸ìš”. ì˜ˆë¥¼ ë“¤ì–´,\n",
            "     ê¹Œê¿ë†€ì´ì—ì„œëŠ” â€œ(ì•„ì´ ì´ë¦„) ì—†ë„¤â€, â€œì–´ë”¨ì§€?â€, â€œê¹Œê¿â€, â€œì—¬ê¹„ë„¤â€ì™€ ê°™ì´ ìƒí™©ì— ë§ëŠ” ë§ì„ ì‚¬ìš©í•˜ê³ , ì¡ê¸°ë†€ì´ì—ì„œëŠ” â€œì¡ìâ€,\n",
            "     â€œì¡ì•˜ë‹¤â€ ë“±ìœ¼ë¡œ ì•„ì´ì™€ ëˆˆì„ ë§ì¶”ë©° ëŒ€í™”í•´ ì£¼ì„¸ìš”. ë¶€ì—Œì„¸íŠ¸ ë†€ì´ì—ì„œëŠ” â€œì˜¤ì´â€, â€œì˜ë¼â€, â€œì˜ëë‹¤â€ ë“± í–‰ë™ì— ë§ëŠ” ì–¸ì–´ë¥¼\n",
            "     ë°˜ë³µì ìœ¼ë¡œ ë“¤ë ¤ì£¼ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.\n",
            "\n",
            "   ğŸ“š ì¶œì²˜: ã€Œì¥ì• ì˜ìœ ì•„ ì–‘ìœ¡ ê°€ì´ë“œë¶ 2ê¶Œ ë°œë‹¬ì¥ì• -ì–‘ìœ¡ê¸°ìˆ ã€, êµ­ë¦½íŠ¹ìˆ˜êµìœ¡ì›, ì±•í„° 2. ì˜ì‚¬ì†Œí†µ / 1. ì–´íœ˜ ë° ì˜ì‚¬ì†Œí†µ ë°œë‹¬ ì´‰ì§„, 39ìª½\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "3. â“ Q: ì•„ì´ì™€ì˜ ì˜ì‚¬ì†Œí†µì„ ì´‰ì§„í•  ìˆ˜ ìˆëŠ” ë†€ì´ ë°©ë²•ì´ ìˆì„ê¹Œìš”?\n",
            "\n",
            "   ğŸ’¬ A:\n",
            "     ê¹Œê¿ë†€ì´, ì¡ê¸°ë†€ì´, ë¶€ì—Œì„¸íŠ¸ ë†€ì´ ë“± ë‹¤ì–‘í•œ ë†€ì´ë¥¼ í†µí•´ ì•„ì´ì™€ ëˆˆì„ ë§ì¶”ê³ , í–‰ë™ì´ ì¼ì–´ë‚  ë•Œë§ˆë‹¤ ìƒí™©ì— ë§ëŠ” ë§ì„ ë§ë¶™ì—¬ ì£¼ì„¸ìš”. ì˜ˆë¥¼\n",
            "     ë“¤ì–´, ê¹Œê¿ë†€ì´ì—ì„œëŠ” â€œ(ì•„ì´ ì´ë¦„) ì—†ë„¤â€, â€œê¹Œê¿â€, â€œì—¬ê¹„ë„¤â€ì™€ ê°™ì´ ë§í•˜ê³ , ì¡ê¸°ë†€ì´ì—ì„œëŠ” â€œì¡ìâ€, â€œì¡ì•˜ë‹¤â€ ë“±ìœ¼ë¡œ\n",
            "     ëŒ€í™”í•˜ë©°, ë¶€ì—Œì„¸íŠ¸ ë†€ì´ì—ì„œëŠ” â€œì˜¤ì´â€, â€œì˜ë¼â€, â€œì˜ëë‹¤â€ ë“± í–‰ë™ì— ë§ëŠ” ì–¸ì–´ë¥¼ ë°˜ë³µì ìœ¼ë¡œ ì‚¬ìš©í•´ ì£¼ì„¸ìš”.\n",
            "\n",
            "   ğŸ“š ì¶œì²˜: ã€Œì¥ì• ì˜ìœ ì•„ ì–‘ìœ¡ ê°€ì´ë“œë¶ 2ê¶Œ ë°œë‹¬ì¥ì• -ì–‘ìœ¡ê¸°ìˆ ã€, êµ­ë¦½íŠ¹ìˆ˜êµìœ¡ì›, ì±•í„° 2. ì˜ì‚¬ì†Œí†µ / 1. ì–´íœ˜ ë° ì˜ì‚¬ì†Œí†µ ë°œë‹¬ ì´‰ì§„, 39ìª½\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "4. â“ Q: ì–´ë¦°ì´ì§‘ì´ë‚˜ ìœ ì¹˜ì›ì— ëŒ€í•œ ì •ë³´ë¥¼ ì–´ë””ì„œ ì°¾ì„ ìˆ˜ ìˆë‚˜ìš”?\n",
            "\n",
            "   ğŸ’¬ A:\n",
            "     ì–´ë¦°ì´ì§‘Â·ìœ ì¹˜ì› í†µí•© ì •ë³´ê³µê°œ ì‚¬ì´íŠ¸(http://info.childcare.go.kr)ì—ì„œëŠ” ì–´ë¦°ì´ì§‘Â·ìœ ì¹˜ì›ì˜ ì‹œì„¤, ì„¤ì¹˜, ìš´ì˜ì, ë³´ìœ¡ë£Œì™€\n",
            "     ê·¸ ë°–ì— í•„ìš”í•œ ê²½ë¹„, ì˜ìœ ì•„ì˜ ê±´ê°•Â·ì˜ì–‘ ë° ì•ˆì „ê´€ë¦¬, ì–´ë¦°ì´ì§‘ ìš´ì˜ì— ê´€í•œ ì‚¬í•­ ë“±ì— ëŒ€í•œ ìì„¸í•œ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.\n",
            "\n",
            "   ğŸ“š ì¶œì²˜: ã€Œì¥ì• ì˜ìœ ì•„ ì–‘ìœ¡ ê°€ì´ë“œë¶ 2ê¶Œ ë°œë‹¬ì¥ì• -ì–‘ìœ¡ê¸°ìˆ ã€, êµ­ë¦½íŠ¹ìˆ˜êµìœ¡ì›, ì±•í„° 3. êµìœ¡ì§€ì› / 2. ìœ ì•„êµìœ¡ê¸°ê´€ì—ì„œì˜ êµìœ¡í™œë™, 63ìª½\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "5. â“ Q: ìš°ë¦¬ ì•„ì´ê°€ ë†€ì´ë¥¼ í†µí•´ ì–´ë–¤ ë°œë‹¬ì„ ê¸°ëŒ€í•  ìˆ˜ ìˆì„ê¹Œìš”?\n",
            "\n",
            "   ğŸ’¬ A:\n",
            "     ë¬´ì—‡ì´ë“ ì§€ í˜¼ì í•´ë³´ë ¤ê³  ë…¸ë ¥í•˜ë©° ë†€ì´ê°€ ë” ë‹¤ì–‘í•´ì§€ë©° ì„±ì¥í•˜ê²Œ ë©ë‹ˆë‹¤. ë†€ì´ ìƒëŒ€ìì™€ ìƒí˜¸ì‘ìš©í•˜ë©° ì–¸ì–´ë¡œ ìƒê°ê³¼ ì˜ê²¬ì„ í‘œí˜„í•  ìˆ˜ ìˆê²Œ\n",
            "     ë©ë‹ˆë‹¤. ë³µì¡í•œ ì¡°ì‘ì´ í•„ìš”í•œ ë†€ì‡ê°ì´ í•„ìš”í•˜ë©° ì™„ì„±ì„ í†µí•´ ì„±ì·¨ê°ì„ ëŠë¼ê²Œ ë©ë‹ˆë‹¤. ì–´ë¥¸ì„ í‰ë‚´ë‚´ë©´ì„œ ì—­í• ë†€ì´ì— ê´€ì‹¬ì„ ê°–ê²Œ ë˜ë©°\n",
            "     ì¹œêµ¬ì™€ ì–´ìš¸ë ¤ ë…¸ëŠ” ì¦ê±°ì›€ì„ ì•Œê²Œ ë©ë‹ˆë‹¤. ì •í˜•í™”ë˜ì§€ ì•Šì€ ë¸”ë¡ìœ¼ë¡œ ìƒìƒ ì†ì˜ ëª¨ì–‘ì„ ë§Œë“¤ë©° ë†€ ìˆ˜ ìˆê²Œ ë˜ê³ , ë˜ë˜ì¹œêµ¬ë“¤ë¼ë¦¬ ê·œì¹™ì„\n",
            "     ìƒˆë¡­ê²Œ êµ¬ì„±í•˜ë©° ë†€ ìˆ˜ ìˆìœ¼ë©° ì¶”ìƒì ì¸ ê¸°í˜¸ì™€ ê¸€ìë¥¼ ì´í•´í•˜ê²Œ ë©ë‹ˆë‹¤.\n",
            "\n",
            "   ğŸ“š ì¶œì²˜: ã€Œì¥ì• ì˜ìœ ì•„ ì–‘ìœ¡ ê°€ì´ë“œë¶ 2ê¶Œ ë°œë‹¬ì¥ì• -ì–‘ìœ¡ê¸°ìˆ ã€, êµ­ë¦½íŠ¹ìˆ˜êµìœ¡ì›, ì±•í„° 5. ì¼ìƒìƒí™œ / 4. ë†€ì´í•  ë•Œ ë‹¤ë£¨ê¸° ì–´ë ¤ìš´ í–‰ë™, 112ìª½\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "6. â“ Q: ì•„ì´ë“¤ì´ ìœ ì¹˜ì›ì—ì„œ ì–´ë–¤ í™œë™ì„ í•˜ë©´ì„œ ë°°ìš°ë‚˜ìš”?\n",
            "\n",
            "   ğŸ’¬ A:\n",
            "     ì•„ì´ë“¤ì´ ì‹ ë‚˜ê²Œ ë…¸ëŠ” ëª¨ìŠµì„ ë¨¸ë¦¿ì†ì— ê·¸ë ¤ë³´ë©´ ì—¬ëŸ¬ ê°€ì§€ ë¸”ë¡ìœ¼ë¡œ ì£¼ì°¨ì¥ì„ ë§Œë“¤ê³  í™˜í˜¸í•˜ëŠ” ëª¨ìŠµ, ì¹œêµ¬ë“¤ê³¼ ì–´ìš¸ë ¤ ì—„ë§ˆ, ì•„ë¹  ì—­í• ê·¹ì„ í•˜ë©´ì„œ\n",
            "     ê·¹ ë†€ì´í•˜ëŠ” ëª¨ìŠµ, ì¶¤ì¶”ë©° ë…¸ë˜í•˜ëŠ” ëª¨ìŠµ ë“± ë‹¤ì–‘í•œ ì¥ë©´ì´ ë– ì˜¤ë¦…ë‹ˆë‹¤. ì•„ì´ë“¤ì—ê²Œ ìˆì–´ì„œ ë†€ì´ë€ ê¸°ëŒ€í•˜ê²Œ í•˜ê³ , ìë°œì ìœ¼ë¡œ ì°¸ì—¬í•˜ê²Œ\n",
            "     í•˜ëŠ” ì‹ ë‚˜ê³  ì¦ê±°ìš´ í™œë™ì…ë‹ˆë‹¤. ë˜í•œ ë†€ì´ë¥¼ í†µí•´ ì•„ì´ë“¤ì€ ìì—°ìŠ¤ëŸ¬ìš´ ë°©ë²•ìœ¼ë¡œ ìì‹ ê³¼ ì£¼ë³€ í™˜ê²½ì„ íƒìƒ‰í•˜ë©° ì ì‘í•´ ë‚˜ê°€ê³  ì—¬ëŸ¬ ê°€ì§€ë¥¼\n",
            "     ë°°ìš°ê³  ìµíˆê²Œ ë©ë‹ˆë‹¤.\n",
            "\n",
            "   ğŸ“š ì¶œì²˜: ã€Œì¥ì• ì˜ìœ ì•„ ì–‘ìœ¡ ê°€ì´ë“œë¶ 2ê¶Œ ë°œë‹¬ì¥ì• -ì–‘ìœ¡ê¸°ìˆ ã€, êµ­ë¦½íŠ¹ìˆ˜êµìœ¡ì›, ì±•í„° 3. êµìœ¡ì§€ì› / 2. ìœ ì•„êµìœ¡ê¸°ê´€ì—ì„œì˜ êµìœ¡í™œë™, 63ìª½\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "7. â“ Q: ì•„ì´ì™€ ë†€ì´í•  ë•Œ ì–¸ì–´ë°œë‹¬ì— ë„ì›€ì´ ë˜ëŠ” ë°©ë²•ì´ ìˆì„ê¹Œìš”?\n",
            "\n",
            "   ğŸ’¬ A:\n",
            "     ë§ê³¼ í–‰ë™ì„ ì£¼ê³ ë°›ì•„ ì£¼ì„¸ìš”. ì•„ì´ê°€ ì¦ê±°ìš´ ìƒí™©ì—ì„œ ë§ë¶™ì—¬ì§„ ë§ì´ ì•„ì´ì˜ ì–¸ì–´ë°œë‹¬ì— ë§¤ìš° ì´‰ì§„ì ì…ë‹ˆë‹¤. ì•„ì´ê°€ ì¢‹ì•„í•˜ëŠ” ì¼ìƒì—ì„œ ë°˜ë³µí•˜ëŠ” ëª¨ë“ \n",
            "     ë†€ì´ê°€ ì–¸ì–´ë°œë‹¬ ì´‰ì§„ì  ë†€ì´ê°€ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì–¸ì–´ë¥¼ ì‹œë²”ë³´ì¼ ë•Œ ì•„ë™ì´ë‚˜ ë¶€ëª¨ì˜ í–‰ë™, ìƒí™©ê³¼ ë¶€ëª¨ì˜ ì–¸ì–´ ì‹œë²”ì˜ íƒ€ì´ë°ì„ ì˜\n",
            "     ë§ì¶”ë©´ í›¨ì”¬ íš¨ê³¼ì ì¸ ì–¸ì–´ ì´‰ì§„ì´ ë©ë‹ˆë‹¤.\n",
            "\n",
            "   ğŸ“š ì¶œì²˜: ã€Œì¥ì• ì˜ìœ ì•„ ì–‘ìœ¡ ê°€ì´ë“œë¶ 2ê¶Œ ë°œë‹¬ì¥ì• -ì–‘ìœ¡ê¸°ìˆ ã€, êµ­ë¦½íŠ¹ìˆ˜êµìœ¡ì›, ì±•í„° 2. ì˜ì‚¬ì†Œí†µ / 1. ì–´íœ˜ ë° ì˜ì‚¬ì†Œí†µ ë°œë‹¬ ì´‰ì§„, 38ìª½\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "8. â“ Q: 0ì„¸ ì•„ë™ì—ê²Œ ì–´ë–¤ ë†€ì‡ê°ì„ ì„ íƒí•´ì•¼ í•˜ë‚˜ìš”?\n",
            "\n",
            "   ğŸ’¬ A:\n",
            "     0ì„¸ ì•„ë™ì„ ìœ„í•œ ë†€ì‡ê° ì„ íƒì˜ ê¸°ì¤€ì€ ì•ˆì „ì´ì–´ì•¼ í•©ë‹ˆë‹¤. í‘ê³¼ ë°±ì˜ ëª…ë£Œí•œ ì‹œê°ìê·¹ì„ ì£¼ëŠ” ëª¨ë¹Œ, ë¬¼ê³  ë¹¨ê±°ë‚˜ ë§Œì§€ì‘ê±°ë¦¬ë©° ë†€ê¸°ì— ì¢‹ì€ í—ê²Š\n",
            "     ì¸í˜•, ë¶€ë“œëŸ¬ìš´ ì²­ê° ìê·¹ì„ ì£¼ëŠ” ë”¸ë‘ì´, ë°©ìš¸ê³µ ë“±ì´ ì í•©í•©ë‹ˆë‹¤. ì•„ë™ì´ ë†€ì´ì˜ ì£¼ì¸ì´ ë˜ë„ë¡ ë„ì™€ì£¼ê³ , ì•„ë™ì´ ì„ íƒí•œ ë†€ì‡ê°ì—\n",
            "     ê´€ì‹¬ì„ ë³´ì—¬ì£¼ë©° ìì—°ìŠ¤ëŸ½ê²Œ ë§ˆì£¼ ë³´ê³  ì•‰ì•„ ëˆˆì„ ë§ì¶”ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.\n",
            "\n",
            "   ğŸ“š ì¶œì²˜: ã€Œì¥ì• ì˜ìœ ì•„ ì–‘ìœ¡ ê°€ì´ë“œë¶ 2ê¶Œ ë°œë‹¬ì¥ì• -ì–‘ìœ¡ê¸°ìˆ ã€, êµ­ë¦½íŠ¹ìˆ˜êµìœ¡ì›, ì±•í„° 5. ì¼ìƒìƒí™œ / 4. ë†€ì´í•  ë•Œ ë‹¤ë£¨ê¸° ì–´ë ¤ìš´ í–‰ë™, 111ìª½\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "9. â“ Q: ë°œë‹¬ì¥ì•  ì˜ìœ ì•„ë¥¼ ìœ„í•œ ì ì ˆí•œ ë†€ì‡ê°ì€ ë¬´ì—‡ì¸ê°€ìš”?\n",
            "\n",
            "   ğŸ’¬ A:\n",
            "     ì•„ë™ë“¤ì€ ì—°ë ¹ì´ë‚˜ ë°œë‹¬ ì •ë„ì— ë”°ë¼ í˜¸ê¸°ì‹¬ì„ ë³´ì´ëŠ” ë†€ì‡ê°ë„ ë‹¤ë¦…ë‹ˆë‹¤. íŠ¹íˆ ë°”ê¹¥ í™œë™ì´ë‚˜ ë˜ë˜ì™€ì˜ ì ‘ì´‰ ê²½í—˜ì´ ì•„ì§ ë¶€ì¡±í•œ ë°œë‹¬ì¥ì•  ì˜ìœ ì•„\n",
            "     ì•„ë™ë“¤ì—ê²Œ ë†€ì‡ê°ì€ ì‹¤ì œ ìƒí™œê³¼ ë‹¤ì–‘í•œ ìê·¹ì„ ì²´í—˜í•´ ë³¼ ìˆ˜ ìˆëŠ” ì¤‘ìš”í•œ ë§¤ê°œì²´ì…ë‹ˆë‹¤. ì•„ë™ì´ ë†€ì´ì˜ ì£¼ì¸ì´ ë˜ë„ë¡ ë„ì™€ì£¼ê³ , ì•„ë™ì´\n",
            "     ì„ íƒí•œ ë†€ì‡ê°ì— ê´€ì‹¬ì„ ë³´ì—¬ì£¼ë©° ìì—°ìŠ¤ëŸ½ê²Œ ë§ˆì£¼ ë³´ê³  ì•‰ì•„ ëˆˆì„ ë§ì¶”ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤. 0ì„¸ ì•„ë™ì—ê²ŒëŠ” ì•ˆì „ì„ ê¸°ì¤€ìœ¼ë¡œ ëª¨ë¹Œ, í—ê²Š\n",
            "     ì¸í˜•, ë”¸ë‘ì´, ë°©ìš¸ê³µ ë“±ì´ ì í•©í•©ë‹ˆë‹¤.\n",
            "\n",
            "   ğŸ“š ì¶œì²˜: ã€Œì¥ì• ì˜ìœ ì•„ ì–‘ìœ¡ ê°€ì´ë“œë¶ 2ê¶Œ ë°œë‹¬ì¥ì• -ì–‘ìœ¡ê¸°ìˆ ã€, êµ­ë¦½íŠ¹ìˆ˜êµìœ¡ì›, ì±•í„° 5. ì¼ìƒìƒí™œ / 4. ë†€ì´í•  ë•Œ ë‹¤ë£¨ê¸° ì–´ë ¤ìš´ í–‰ë™, 111ìª½\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "10. â“ Q: ì•„ì´ë“¤ì´ ìœ ì•„êµìœ¡ê¸°ê´€ì—ì„œ ì–´ë–¤ í™œë™ì„ í•˜ë‚˜ìš”?\n",
            "\n",
            "   ğŸ’¬ A:\n",
            "     ì„ ìƒë‹˜, ì¹œêµ¬ë“¤ê³¼ ì¸ì‚¬ë¥¼ ë‚˜ëˆ„ê³ , ê°€ë°©ê³¼ ê²‰ì˜·ì„ ì‚¬ë¬¼í•¨ì— ì •ë¦¬í•©ë‹ˆë‹¤(ë“±ì›). ë›°ê³  ì›€ì§ì´ëŠ” í™œë™ì„ í†µí•´ ì‹ ì²´ë¥¼ ë°œë‹¬ì‹œí‚¤ê³  ê¸´ì¥ì„ í•´ì†Œì‹œí‚¬ ìˆ˜\n",
            "     ìˆìŠµë‹ˆë‹¤(ë°”ê¹¥ë†€ì´). ì„ ìƒë‹˜, ì¹œêµ¬ë“¤ê³¼ ì›í•˜ëŠ” ë†€ì´ë‚˜ í™œë™ì„ í•©ë‹ˆë‹¤(ììœ ë†€ì´). í•¨ê»˜ ëª¨ì—¬ ì´ì•¼ê¸° ë‚˜ëˆ„ê¸°, ë™ì‹œ, ë™í™”, ë™ê·¹, ê²Œì„,\n",
            "     ìš”ë¦¬ í™œë™ ë“±ì„ í•©ë‹ˆë‹¤(ëŒ€Â·ì†Œì§‘ë‹¨ í™œë™).\n",
            "\n",
            "   ğŸ“š ì¶œì²˜: ã€Œì¥ì• ì˜ìœ ì•„ ì–‘ìœ¡ ê°€ì´ë“œë¶ 2ê¶Œ ë°œë‹¬ì¥ì• -ì–‘ìœ¡ê¸°ìˆ ã€, êµ­ë¦½íŠ¹ìˆ˜êµìœ¡ì›, ì±•í„° 3. êµìœ¡ì§€ì› / 2. ìœ ì•„êµìœ¡ê¸°ê´€ì—ì„œì˜ êµìœ¡í™œë™, 64ìª½\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "11. â“ Q: ë°œë‹¬ì¥ì• ê°€ ìˆëŠ” ì•„ì´ë¥¼ ë˜ë˜ ì¹œêµ¬ë“¤ê³¼ ìì—°ìŠ¤ëŸ½ê²Œ ì–´ìš¸ë¦¬ê²Œ í•˜ë ¤ë©´ ì–´ë–»ê²Œ í•´ì•¼ í•˜ë‚˜ìš”?\n",
            "\n",
            "   ğŸ’¬ A:\n",
            "     ë¬´ì¡°ê±´ ìœ ì˜ˆëŠ” ì˜³ì§€ ì•Šì•„ìš”. ì¥ì• í•™ìƒë“¤ë„ ì¥ì• ì˜ ì •ë„ì— ë”°ë¼ ìˆœíšŒêµìœ¡ ë“± ë³„ë„ì˜ êµìœ¡ì§€ì›ì´ ì œê³µë˜ê¸° ë•Œë¬¸ì— ì¥ì• ë¥¼ ì´ìœ ë¡œ ìœ ì˜ˆí•˜ê¸°ë³´ë‹¤ëŠ” ë˜ë˜ì™€\n",
            "     í•¨ê»˜ êµìœ¡ì„ ë°›ì„ ìˆ˜ ìˆë„ë¡ í•´ì£¼ì„¸ìš”. ë˜ë˜ ì¹œêµ¬ ë§Œë‚˜ê¸°ëŠ” ì•„ì´ê°€ ìì—°ìŠ¤ëŸ½ê²Œ ë˜ë˜ì™€ ë§Œë‚  ìˆ˜ ìˆëŠ” í™˜ê²½ì„ ë§Œë“¤ì–´ì£¼ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.\n",
            "     ì•„ì´ë“¤ì—ê²Œ ì¥ì• ì— ëŒ€í•œ ì´ì•¼ê¸°ë¥¼ í•´ì£¼ë©´, ì´ ë˜ë˜ì˜ ì•„ì´ë“¤ì€ ì•„ì§ ë‹¤ë¦„ì— ëŒ€í•œ ê±°ë¶€ê°ì´ ì ê¸° ë•Œë¬¸ì— ì •í™•í•œ ì„¤ëª…ì´ ë™ë°˜ëœë‹¤ë©´ í•¨ê»˜\n",
            "     ì–´ìš¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
            "\n",
            "   ğŸ“š ì¶œì²˜: ã€Œì¥ì• ì˜ìœ ì•„ ì–‘ìœ¡ ê°€ì´ë“œë¶ 2ê¶Œ ë°œë‹¬ì¥ì• -ì–‘ìœ¡ê¸°ìˆ ã€, êµ­ë¦½íŠ¹ìˆ˜êµìœ¡ì›, ì±•í„° 3. êµìœ¡ì§€ì› / 4. ë˜ë˜ì™€ í•¨ê»˜ ìƒí™œí•˜ê¸°, 69ìª½\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "12. â“ Q: ë°œë‹¬ì¥ì• ê°€ ìˆëŠ” ì•„ì´ë¥¼ ë‹¤ë¥¸ ì•„ì´ë“¤ê³¼ ì–´ë–»ê²Œ ì˜ ì–´ìš¸ë¦¬ê²Œ í•  ìˆ˜ ìˆì„ê¹Œìš”?\n",
            "\n",
            "   ğŸ’¬ A:\n",
            "     ë‚´ ì•„ì´ì˜ ì¥ì• ìœ í˜•ì— ë”°ë¥¸ í–‰ë™ë°©ì‹ì„ ì„¤ëª…í•˜ê³ , ë¹„ì¥ì• ì•„ë™ê³¼ ì¥ì• ì•„ë™ì˜ ë‹¤ë¥¸ì ê³¼ ê°™ì€ì , ì°¨ì´ì— ëŒ€í•´ ì„¤ëª…í•´ ì£¼ì„¸ìš”. ì¥ì• ì™€ ê´€ë ¨í•´ ì‚¬ìš©í•˜ë©´\n",
            "     ì•ˆë˜ëŠ” ë§ë“¤ì— ëŒ€í•´ ì´ì•¼ê¸°í•˜ëŠ” ê²ƒë„ ì¤‘ìš”í•©ë‹ˆë‹¤. ë˜ë˜ì•„ì´ë“¤ ë¶€ëª¨ì™€ì˜ ìœ ëŒ€ê´€ê³„ëŠ” ì•„ì´ì˜ ì¥ì• ì— ëŒ€í•œ í¸ê²¬ê³¼ ì„ ì…ê²¬ì„ í•´ì†Œí•˜ëŠ” ë° ë„ì›€ì´\n",
            "     ë©ë‹ˆë‹¤. í•¨ê»˜ ë†€ê¸°ì—ì„œëŠ” ì¥ì• ê°€ ìˆëŠ” ì¹œêµ¬ë¥¼ ê¸°ë‹¤ë ¤ì£¼ê³ , ì˜ ì„¤ëª…í•´ì£¼ë©°, í•˜ê¸° ì–´ë ¤ìš´ ê²ƒì— ëŒ€í•´ ì•Œê³  í•¨ê»˜í•˜ëŠ” ê²ƒì´ í•„ìš”í•©ë‹ˆë‹¤.\n",
            "     ë„ì™€ì£¼ê³  ì‹¶ì„ ë•ŒëŠ” ì¥ì• ê°€ ìˆëŠ” ì¹œêµ¬ì—ê²Œ ë¬¼ì–´ë³´ê³  ë„ì™€ì£¼ë©°, í•  ìˆ˜ ìˆëŠ” ì¼ì€ ìŠ¤ìŠ¤ë¡œ í•  ìˆ˜ ìˆë„ë¡ ë„ì™€ì£¼ê³ , ë„ì›€ì„ ìš”ì²­í•  ë•Œ\n",
            "     ë„ì™€ì£¼ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤. ë˜í•œ ì¥ì• ê°€ ìˆëŠ” ì¹œêµ¬ì™€ë„ ì‹¸ìš¸ ìˆ˜ ìˆë‹¤ëŠ” ê²ƒ, ê°™ì€ ì‹¤ìˆ˜ë¥¼ ì—¬ëŸ¬ ë²ˆ í•  ìˆ˜ ìˆë‹¤ëŠ” ê²ƒ, ë¹„ì¥ì• ì¸ ì¹œêµ¬ì˜\n",
            "     ì´ì•¼ê¸°ë¥¼ ì˜ ëª¨ë¥¼ ìˆ˜ë„ ìˆë‹¤ëŠ” ê²ƒì„ ì•Œë ¤ì£¼ì„¸ìš”.\n",
            "\n",
            "   ğŸ“š ì¶œì²˜: ã€Œì¥ì• ì˜ìœ ì•„ ì–‘ìœ¡ ê°€ì´ë“œë¶ 2ê¶Œ ë°œë‹¬ì¥ì• -ì–‘ìœ¡ê¸°ìˆ ã€, êµ­ë¦½íŠ¹ìˆ˜êµìœ¡ì›, ì±•í„° 3. êµìœ¡ì§€ì› / 4. ë˜ë˜ì™€ í•¨ê»˜ ìƒí™œí•˜ê¸°, 70ìª½\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "13. â“ Q: ìœ ì•„êµìœ¡ê¸°ê´€ì—ì„œ ì•„ì´ë“¤ì´ í•˜ë£¨ë¥¼ ì–´ë–»ê²Œ ë³´ë‚´ë‚˜ìš”?\n",
            "\n",
            "   ğŸ’¬ A:\n",
            "     ì„ ìƒë‹˜, ì¹œêµ¬ë“¤ê³¼ ì¸ì‚¬ë¥¼ ë‚˜ëˆ„ê³ , ê°€ë°©ê³¼ ê²‰ì˜·ì„ ì‚¬ë¬¼í•¨ì— ì •ë¦¬í•©ë‹ˆë‹¤(ë“±ì›). ë›°ê³  ì›€ì§ì´ëŠ” í™œë™ì„ í†µí•´ ì‹ ì²´ë¥¼ ë°œë‹¬ì‹œí‚¤ê³  ê¸´ì¥ì„ í•´ì†Œì‹œí‚¬ ìˆ˜\n",
            "     ìˆìŠµë‹ˆë‹¤(ë°”ê¹¥ë†€ì´). ì„ ìƒë‹˜, ì¹œêµ¬ë“¤ê³¼ ì›í•˜ëŠ” ë†€ì´ë‚˜ í™œë™ì„ í•©ë‹ˆë‹¤(ììœ ë†€ì´). í•¨ê»˜ ëª¨ì—¬ ì´ì•¼ê¸° ë‚˜ëˆ„ê¸°, ë™ì‹œ, ë™í™”, ë™ê·¹, ê²Œì„,\n",
            "     ìš”ë¦¬ í™œë™ ë“±ì„ í•©ë‹ˆë‹¤(ëŒ€Â·ì†Œì§‘ë‹¨ í™œë™).\n",
            "\n",
            "   ğŸ“š ì¶œì²˜: ã€Œì¥ì• ì˜ìœ ì•„ ì–‘ìœ¡ ê°€ì´ë“œë¶ 2ê¶Œ ë°œë‹¬ì¥ì• -ì–‘ìœ¡ê¸°ìˆ ã€, êµ­ë¦½íŠ¹ìˆ˜êµìœ¡ì›, ì±•í„° 3. êµìœ¡ì§€ì› / 2. ìœ ì•„êµìœ¡ê¸°ê´€ì—ì„œì˜ êµìœ¡í™œë™, 64ìª½\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "14. â“ Q: ë°œë‹¬ ì¥ì• ê°€ ìˆëŠ” ì•„ì´ì—ê²Œ ì í•©í•œ ë†€ì´ ë°©ë²•ì´ë‚˜ ì¥ë‚œê° ì¶”ì²œí•´ ì£¼ì‹¤ ìˆ˜ ìˆë‚˜ìš”?\n",
            "\n",
            "   ğŸ’¬ A:\n",
            "     ë¬´ì—‡ì´ë“ ì§€ í˜¼ì í•´ë³´ë ¤ê³  ë…¸ë ¥í•˜ë©° ë†€ì´ê°€ ë” ë‹¤ì–‘í•´ì§€ë©° ì„±ì¥í•˜ê²Œ ë©ë‹ˆë‹¤. ë†€ì´ ìƒëŒ€ìì™€ ìƒí˜¸ì‘ìš©í•˜ë©° ì–¸ì–´ë¡œ ìƒê°ê³¼ ì˜ê²¬ì„ í‘œí˜„í•  ìˆ˜ ìˆê²Œ\n",
            "     ë©ë‹ˆë‹¤. ë³µì¡í•œ ì¡°ì‘ì´ í•„ìš”í•œ ë†€ì‡ê°ì´ í•„ìš”í•˜ë©° ì™„ì„±ì„ í†µí•´ ì„±ì·¨ê°ì„ ëŠë¼ê²Œ ë©ë‹ˆë‹¤. ì–´ë¥¸ì„ í‰ë‚´ë‚´ë©´ì„œ ì—­í• ë†€ì´ì— ê´€ì‹¬ì„ ê°–ê²Œ ë˜ë©°\n",
            "     ì¹œêµ¬ì™€ ì–´ìš¸ë ¤ ë…¸ëŠ” ì¦ê±°ì›€ì„ ì•Œê²Œ ë©ë‹ˆë‹¤. ì´‰ê° ë†€ì‡ê°, ì†Œê¿‰ë†€ì´, ìš´ë™ ë†€ì‡ê°, ìºë¦­í„° ë†€ì‡ê°, ë³€ë³„í•˜ê¸° ë†€ì‡ê°, ì´ì•¼ê¸°ì±…, ë¸”ë¡,\n",
            "     ìŒ“ê¸° ë†€ì‡ê°, ì†Œê·¼ìœ¡ ë†€ì‡ê°, í•œê¸€ ì½ì„ê±°ë¦¬ ë“±ì´ ì¶”ì²œë©ë‹ˆë‹¤.\n",
            "\n",
            "   ğŸ“š ì¶œì²˜: ã€Œì¥ì• ì˜ìœ ì•„ ì–‘ìœ¡ ê°€ì´ë“œë¶ 2ê¶Œ ë°œë‹¬ì¥ì• -ì–‘ìœ¡ê¸°ìˆ ã€, êµ­ë¦½íŠ¹ìˆ˜êµìœ¡ì›, ì±•í„° 5. ì¼ìƒìƒí™œ / 4. ë†€ì´í•  ë•Œ ë‹¤ë£¨ê¸° ì–´ë ¤ìš´ í–‰ë™, 112ìª½\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "15. â“ Q: ì¥ì• ê°€ ìˆëŠ” ì•„ì´ì™€ ë¹„ì¥ì•  ì•„ì´ê°€ í•¨ê»˜ ë†€ ë•Œ ì£¼ì˜í•´ì•¼ í•  ì ì€ ë¬´ì—‡ì¸ê°€ìš”?\n",
            "\n",
            "   ğŸ’¬ A:\n",
            "     ë‚´ ì•„ì´ì˜ ì¥ì• ìœ í˜•ì— ë”°ë¥¸ í–‰ë™ë°©ì‹ì„ ì„¤ëª…í•˜ê³ , ë¹„ì¥ì• ì•„ë™ê³¼ ì¥ì• ì•„ë™ì˜ ë‹¤ë¥¸ì ê³¼ ê°™ì€ì , ì°¨ì´ì— ëŒ€í•´ ì„¤ëª…í•´ ì£¼ì„¸ìš”. ì¥ì• ì™€ ê´€ë ¨í•´ ì‚¬ìš©í•˜ë©´\n",
            "     ì•ˆë˜ëŠ” ë§ë“¤ì— ëŒ€í•´ ì´ì•¼ê¸°í•˜ëŠ” ê²ƒë„ ì¤‘ìš”í•©ë‹ˆë‹¤. ë˜ë˜ì•„ì´ë“¤ ë¶€ëª¨ì™€ì˜ ìœ ëŒ€ê´€ê³„ëŠ” ì•„ì´ì˜ ì¥ì• ì— ëŒ€í•œ í¸ê²¬ê³¼ ì„ ì…ê²¬ì„ í•´ì†Œí•˜ëŠ” ë° ë„ì›€ì´\n",
            "     ë©ë‹ˆë‹¤. í•¨ê»˜ ë†€ê¸°ì—ì„œëŠ” ì¥ì• ê°€ ìˆëŠ” ì¹œêµ¬ë¥¼ ê¸°ë‹¤ë ¤ì£¼ê³ , ì˜ ì„¤ëª…í•´ì£¼ë©°, í•˜ê¸° ì–´ë ¤ìš´ ê²ƒì— ëŒ€í•´ ì•Œê³  í•¨ê»˜í•˜ëŠ” ê²ƒì´ í•„ìš”í•©ë‹ˆë‹¤.\n",
            "     ë„ì™€ì£¼ê³  ì‹¶ì„ ë•ŒëŠ” ì¥ì• ê°€ ìˆëŠ” ì¹œêµ¬ì—ê²Œ ë¬¼ì–´ë³´ê³  ë„ì™€ì£¼ë©°, í•  ìˆ˜ ìˆëŠ” ì¼ì€ ìŠ¤ìŠ¤ë¡œ í•  ìˆ˜ ìˆë„ë¡ ë„ì™€ì£¼ê³ , ë„ì›€ì„ ìš”ì²­í•  ë•Œ\n",
            "     ë„ì™€ì£¼ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤. ë˜í•œ ì¥ì• ê°€ ìˆëŠ” ì¹œêµ¬ì™€ë„ ì‹¸ìš¸ ìˆ˜ ìˆë‹¤ëŠ” ê²ƒ, ê°™ì€ ì‹¤ìˆ˜ë¥¼ ì—¬ëŸ¬ ë²ˆ í•  ìˆ˜ ìˆë‹¤ëŠ” ê²ƒ, ë¹„ì¥ì• ì¸ ì¹œêµ¬ì˜\n",
            "     ì´ì•¼ê¸°ë¥¼ ì˜ ëª¨ë¥¼ ìˆ˜ë„ ìˆë‹¤ëŠ” ê²ƒì„ ì•Œë ¤ì£¼ì„¸ìš”.\n",
            "\n",
            "   ğŸ“š ì¶œì²˜: ã€Œì¥ì• ì˜ìœ ì•„ ì–‘ìœ¡ ê°€ì´ë“œë¶ 2ê¶Œ ë°œë‹¬ì¥ì• -ì–‘ìœ¡ê¸°ìˆ ã€, êµ­ë¦½íŠ¹ìˆ˜êµìœ¡ì›, ì±•í„° 3. êµìœ¡ì§€ì› / 4. ë˜ë˜ì™€ í•¨ê»˜ ìƒí™œí•˜ê¸°, 70ìª½\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n"
          ]
        }
      ],
      "source": [
        "import textwrap\n",
        "\n",
        "def extract_json_from_response_2(text: str) -> dict:\n",
        "    try:\n",
        "        # ê°€ì¥ ë°”ê¹¥ìª½ ì¤‘ê´„í˜¸ ì „ì²´ ì¶”ì¶œ (greedy)\n",
        "        json_string = re.search(r\"\\{[\\s\\S]+\\}\", text, re.DOTALL).group()\n",
        "        return json.loads(json_string)\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ JSON ì¶”ì¶œ ì‹¤íŒ¨: {e}\")\n",
        "        return {}\n",
        "\n",
        "def split_by_emoji_numbers(answer: str) -> list:\n",
        "    # ì´ëª¨ì§€ ë„˜ë²„ë§ì„ ê¸°ì¤€ìœ¼ë¡œ ë¶„í• í•˜ë˜, ê° ì´ëª¨ì§€ì™€ í…ìŠ¤íŠ¸ë¥¼ ë¬¶ì–´ì„œ ì¶œë ¥\n",
        "    pattern = r'(1ï¸âƒ£|2ï¸âƒ£|3ï¸âƒ£|4ï¸âƒ£|5ï¸âƒ£|6ï¸âƒ£|7ï¸âƒ£|8ï¸âƒ£|9ï¸âƒ£|ğŸ”Ÿ)'\n",
        "    parts = re.split(pattern, answer)\n",
        "\n",
        "    combined = []\n",
        "    i = 1\n",
        "    while i < len(parts):\n",
        "        emoji = parts[i]\n",
        "        text = parts[i+1] if i + 1 < len(parts) else ''\n",
        "        combined.append(f\"{emoji} {text.strip()}\")\n",
        "        i += 2\n",
        "    return combined\n",
        "\n",
        "parsed = extract_json_from_response_2(state['answer'])\n",
        "# intro ë¨¼ì € ì¶œë ¥\n",
        "print(f'ğŸ“Œ {parsed['intro']}')\n",
        "print()\n",
        "print(\"ğŸ™‹â€â™€ï¸ ë” ì•Œê³  ì‹¶ì–´ìš”!\")\n",
        "for i, qna in enumerate(parsed[\"qna\"], 1):\n",
        "    print(f\"{i}. â“ Q: {qna['question']}\\n\")\n",
        "    print(\"   ğŸ’¬ A:\")\n",
        "\n",
        "    # â–¶ ì´ëª¨ì§€ ë„˜ë²„ë§ì´ í¬í•¨ëœ í•­ëª©ì€ ì¤„ë°”ê¿ˆí•´ì„œ ì¶œë ¥\n",
        "    if '1ï¸âƒ£' in qna['answer']:\n",
        "        numbered_lines = split_by_emoji_numbers(qna['answer'])\n",
        "        for line in numbered_lines:\n",
        "            print(f\"     {textwrap.fill(line, width=80, subsequent_indent='     ')}\")\n",
        "    else:\n",
        "        print(f\"     {textwrap.fill(qna['answer'], width=80, subsequent_indent='     ')}\")\n",
        "\n",
        "    print(f\"\\n   ğŸ“š ì¶œì²˜: {qna['source']}\")\n",
        "    print(\"â”€\" * 90)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
